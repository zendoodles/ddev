{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Get Started with DDEV \u00b6 DDEV is an open source tool that makes it dead simple to get local PHP development environments up and running within minutes. It's powerful and flexible as a result of its per-project environment configurations, which can be extended, version controlled, and shared. In short, DDEV aims to allow development teams to use Docker in their workflow without the complexities of bespoke configuration. DDEV works great on macOS, Windows WSL2, traditional Windows, Linux and Gitpod.io. It works perfectly on amd64 and arm64 architectures, meaning it works fine natively on mac M1 systems and on Linux with both amd64 and arm64. It also works great on Gitpod, where you don't have to install anything at all. System Requirements \u00b6 macOS Windows WSL2 Traditional Windows Linux Gitpod.io macOS \u00b6 DDEV runs natively on arm64 (Mac M1) systems as well as amd64 machines. RAM: 8GB Storage: 256GB Colima or Docker Desktop is required. Docker Desktop requires macOS Catalina (macOS 10.15) or higher. Colima can even run on older systems. DDEV should run anywhere Docker Desktop or Colima runs. Windows WSL2 \u00b6 RAM: 8GB Storage: 256GB Systems that can run Docker Desktop on the Windows side or docker-ce inside WSL2 do fine. The preferred distro is Ubuntu or an Ubuntu-derived distro, but people use lots of different distros. Traditional Windows \u00b6 Any recent edition of Windows Home, Pro, and several others. RAM: 8GB Storage: 256GB Docker Desktop using the WSL2 back-end Linux \u00b6 Most distros and most versions work fine. RAM: 8GB Storage: 256GB Gitpod.io \u00b6 With gitpod.io all you need is a browser and an internet connection. You don't have to install anything at all. You can use any kind of computer that has a browser, or tablet, or whatever you like.","title":"Get Started with DDEV"},{"location":"#get-started-with-ddev","text":"DDEV is an open source tool that makes it dead simple to get local PHP development environments up and running within minutes. It's powerful and flexible as a result of its per-project environment configurations, which can be extended, version controlled, and shared. In short, DDEV aims to allow development teams to use Docker in their workflow without the complexities of bespoke configuration. DDEV works great on macOS, Windows WSL2, traditional Windows, Linux and Gitpod.io. It works perfectly on amd64 and arm64 architectures, meaning it works fine natively on mac M1 systems and on Linux with both amd64 and arm64. It also works great on Gitpod, where you don't have to install anything at all.","title":"Get Started with DDEV"},{"location":"#system-requirements","text":"macOS Windows WSL2 Traditional Windows Linux Gitpod.io","title":"System Requirements"},{"location":"#macos","text":"DDEV runs natively on arm64 (Mac M1) systems as well as amd64 machines. RAM: 8GB Storage: 256GB Colima or Docker Desktop is required. Docker Desktop requires macOS Catalina (macOS 10.15) or higher. Colima can even run on older systems. DDEV should run anywhere Docker Desktop or Colima runs.","title":"macOS"},{"location":"#windows-wsl2","text":"RAM: 8GB Storage: 256GB Systems that can run Docker Desktop on the Windows side or docker-ce inside WSL2 do fine. The preferred distro is Ubuntu or an Ubuntu-derived distro, but people use lots of different distros.","title":"Windows WSL2"},{"location":"#traditional-windows","text":"Any recent edition of Windows Home, Pro, and several others. RAM: 8GB Storage: 256GB Docker Desktop using the WSL2 back-end","title":"Traditional Windows"},{"location":"#linux","text":"Most distros and most versions work fine. RAM: 8GB Storage: 256GB","title":"Linux"},{"location":"#gitpodio","text":"With gitpod.io all you need is a browser and an internet connection. You don't have to install anything at all. You can use any kind of computer that has a browser, or tablet, or whatever you like.","title":"Gitpod.io"},{"location":"developers/","text":"Developing and Improving DDEV \u00b6 This section is for folks making contributions to DDEV itself, and covers how to build, release, build Docker images, and see docs.","title":"Developing and Improving DDEV"},{"location":"developers/#developing-and-improving-ddev","text":"This section is for folks making contributions to DDEV itself, and covers how to build, release, build Docker images, and see docs.","title":"Developing and Improving DDEV"},{"location":"developers/building-contributing/","text":"Building, Testing, and Contributing \u00b6 Testing latest commits \u00b6 You can download the latest artifacts from the master branch from link . On macOS and Linux you can brew unlink ddev && brew install drud/ddev/ddev --HEAD --fetch-HEAD to get the latest commit of ddev, even if it's not yet in a release. If you are using linux/WSL2, you will also likely need to install build-essential with the following command: sudo apt install -y build-essential . To download the latest version, you can visit the master-build workflow and choose the latest item (or the one that matches a commit you want to test). You'll see the artifacts for each OS there on the bottom of the page. And of course you can just see the latest build in action by visiting ddev on gitpod . Testing a PR \u00b6 Each build of a PR has artifacts created in github, so you can click the details of the PR Build test, choose the PR you want to work with, and download the artifacts you need there. After you download and unzip the appropriate binary, you can place it in your $PATH. The easiest way to do this if you're using homebrew is brew unlink ddev and then unzip ddev.zip && chmod +x ddev && mv ddev /usr/local/bin/ddev . You can verify that the replacement worked via ddev -v . The output should be something like ddev version v1.19.1-42-g5334d3c1 (instead of the regular ddev version v1.19.1 ). (On macOS Big Sur these downloaded binaries are not signed, so you will want to xattr -r -d com.apple.quarantine /path/to/ddev in order to use them. The binaries on the master branch and the final binaries in any release are signed, of course.) You do not typically have to install anything else other than the downloaded binary; when you run it it will access any docker images that it needs. After you're done, you can remove the downloaded binary and brew link ddev . Open in Gitpod \u00b6 Gitpod.io provides a quick preconfigured ddev experience in the browser, so you can test your PR (or someone else's) easily and without setting up an environment. In any PR you can use the URL https://gitpod.io/#https://github.com/drud/ddev/pulls/<YOURPR> to open that PR and build it in Gitpod. To just open and work on ddev you can use the button below. If you want to run a web project in there, you can just check it out into /workspace/<yourproject> and use it as usual. The things you're familiar with work as expected, except that ddev-router does not run, and A dummy project for gitpod is provided by default in /workspace/d9simple. You can just ddev poweroff and use your own. Making changes to ddev images \u00b6 If you need to make a change to one of the ddev images, you can make the change, but then it has to be built with a specific tag, and the tag has to be updated in pkg/versionconstants/versionconstants.go . So for example, make a change to containers/ddev-webserver/Dockerfile, then built it: cd containers/ddev-webserver make VERSION = 20210424_fix_dockerfile Then edit pkg/versionconstants/versionconstants.go to set var WebTag = \"20210424_fix_dockerfile\" and cd /workspace/ddev make ddev version should show you that you are using the correct webtag, and ddev start will show it. It's easiest to do this using gitpod (see above) because gitpod already has docker buildx all set up for you and the built ddev is in the $PATH. Pull Requests and PR Preparation \u00b6 When preparing your pull request, please use a branch name like \"2020_ _short_description\" so that it's easy to track to you. If you're doing a docs-only PR that does not require full testing, please add \"[skip ci][ci skip]\" to your commit messages; it saves a lot of testing resources. Docker Image changes \u00b6 If you make changes to a docker image (like ddev-webserver), it won't have any effect unless you: Push an image with a specific tag by going to the image directory (like containers/ddev-webserver) by just doing make container VERSION=<branchname> in the containers/ddev-webserver directory. Multi-arch images require you to have a buildx builder, so docker buildx create --name ddev-builder-multi --use You can't push until you docker login . Push a container to hub.docker.com. Push with the tag that matches your branch. Pushing to <yourorg>/ddev-webserver repo is easy to accomplish with make push DOCKER_ORG=<yourorg> VERSION=<branchname> in the container directory . You might have to use other techniques to push to another repo. Update pkg/versionconstants/versionconstants.go with the WebImg and WebTag that relate to the docker image you pushed. Local builds and pushes \u00b6 To use buildx successfully you have to have the buildx docker plugin which is in many environments by default. To build multi-platform images you must docker buildx create --use as a one-time initialization. If you just want to work locally and do a quick build for your own architecture, you can: make VERSION=<version> for ddev-dbserver : make mariadb_10.3 VERSION=<version> etc. To push manually: cd containers/ddev-webserver make push VERSION=<tag> If you're pushing to a repo other than the one wired into the Makefile (like drud/ddev-webserver ) then cd containers/ddev-webserver make push VERSION=<tag> DOCKER_REPO=your/dockerrepo Pushes using GitHub Actions \u00b6 To manually push using GitHub Actions, For most images \u00b6 Visit Actions->Push Tagged Image Click \"Run workflow\" in the blue band near the top. Choose the branch, usually master and then the image to be pushed, ddev-webserver , ddev-dbserver , etc. Also you can use all to build and push all of them. Include a tag for the pushed image and GitHub will do all the work. For ddev-dbserver \u00b6 Visit Actions->Push Tagged db Image Click \"Run workflow\" in the blue band near the top. Choose the branch, usually master . Include a tag for the pushed image and GitHub will do all the work. Building \u00b6 Build the project with make and your resulting executable will end up in .gotmp/bin/linux_amd64/ddev or .gotmp/bin/linux_arm64/ddev (for Linux) or .gotmp/bin/windows_amd64/ddev.exe (for Windows) or .gotmp/bin/darwin_amd64/ddev or .gotmp/bin/darwin_arm64/ddev (for macOS). Build/test/check static analysis with make # Builds on current os/architecture make linux_amd64 make linux_arm64 make darwin_amd64 make darwin_arm64 make windows_amd64 make test make clean make staticrequired Testing \u00b6 Normal test invocation is just make test . Run a single test with an invocation like go test -v -run TestDevAddSites ./pkg/... or make testpkg TESTARGS=\"-run TestDevAddSites\" . The easiest way to run tests is from inside the excellent golang IDE Goland. Just click the arrowhead to the left of the test name. To see which DDEV commands the tests are executing, set the environment variable DDEV_DEBUG=true. Use GOTEST_SHORT=true to run just one CMS in each test, or GOTEST_SHORT= to run exactly one project type from the list of project types in the TestSites array . For example, GOTEST_SHORT=5 will run many tests only against TYPO3. To run a test (in the cmd package) against a individually compiled ddev binary set the DDEV_BINARY_FULLPATH environment variable, for example DDEV_BINARY_FULLPATH=$PWD/.gotmp/bin/linux_amd64/ddev make testcmd . Automated testing \u00b6 Anybody can view the CircleCI automated tests, and they usually show up any problems that are not OS-specific. Just click through on the testing section of the PR to see them. The Buildkite automated tests require special access, which we typically grant to any PR contributor that asks for it. Docker image development \u00b6 The Docker images that DDEV uses are included in the containers/ directory: containers/ddev-webserver: Provides the web servers (the \"web\" container). containers/ddev-dbserver: Provides the \"db\" container. containers/ddev-router: The router image containers/ddev-ssh-agent When changes are made to an image, they have to be temporarily pushed to a tag that is preferably the same as the branch name of the PR, and the tag updated in pkg/versionconstants/versionconstants.go . Just ask if you need a container pushed to support a PR. Pull Request Pro Tips \u00b6 Fork the repository and clone it locally. Connect your local to the original \u2018upstream\u2019 repository by adding it as a remote. - Pull in changes from \u2018upstream\u2019 often so that you stay up to date so that when you submit your pull request, merge conflicts - will be less likely. See more detailed instructions here . Create a branch for your edits. Be clear about what problem is occurring and how someone can recreate that problem or why your feature will help. Then be equally as clear about the steps you took to make your changes. It\u2019s best to test . Run your changes against any existing tests if they exist and create new ones when needed. Whether tests exist or not, make sure your changes don\u2019t break the existing project. Open Pull Requests \u00b6 Once you\u2019ve opened a pull request, a discussion will start around your proposed changes. Other contributors and users may chime in, but ultimately the decision is made by the maintainer(s). You may be asked to make some changes to your pull request. If so, add more commits to your branch and push them \u2013 they\u2019ll automatically go into the existing pull request. If your pull request is merged \u2013 great! If it is not, no sweat, it may not be what the project maintainer had in mind, or they were already working on it. This happens, so our recommendation is to take any feedback you\u2019ve received and go forth and pull request again \u2013 or create your own open source project. Adapted from GitHub Guides Coding Style \u00b6 Unless explicitly stated, we follow all coding guidelines from the Go community. While some of these standards may seem arbitrary, they somehow seem to result in a solid, consistent codebase. It is possible that the code base does not currently comply with these guidelines. We are not looking for a massive PR that fixes this since that goes against the spirit of the guidelines. All new contributions should make a best effort to clean up and make the code base better than they left it. Obviously, apply your best judgment. Remember, the goal here is to make the code base easier for humans to navigate and understand. Always keep that in mind when nudging others to comply. Just use make staticrequired to ensure that your code can pass the required static analysis tests. The rules: All code should be formatted with gofmt -s . All code should pass the default levels of golint . All code should follow the guidelines covered in Effective Go and Go Code Review Comments . Comment the code. Tell us the why, the history and the context. Document all declarations and methods, even private ones. Declare expectations, caveats and anything else that may be important. If a type gets exported, having the comments already there will ensure it's ready. Variable name length should be proportional to its context and no longer. noCommaALongVariableNameLikeThisIsNotMoreClearWhenASimpleCommentWouldDo . In practice, short methods will have short variable names and globals will have longer names. No underscores in package names. If you need a compound name, step back, and re-examine why you need a compound name. If you still think you need a compound name, lose the underscore. All tests should run with go test and outside tooling should not be required. No, we don't need another unit testing framework. Assertion packages are acceptable if they provide real incremental value. Even though we call these \"rules\" above, they are actually just guidelines. Since you've read all the rules, you now know that. If you are having trouble getting into the mood of idiomatic Go, we recommend reading through Effective Go . The Go Blog is also a great resource. Drinking the kool-aid is a lot easier than going thirsty.","title":"Building, Testing, and Contributing"},{"location":"developers/building-contributing/#building-testing-and-contributing","text":"","title":"Building, Testing, and Contributing"},{"location":"developers/building-contributing/#testing-latest-commits","text":"You can download the latest artifacts from the master branch from link . On macOS and Linux you can brew unlink ddev && brew install drud/ddev/ddev --HEAD --fetch-HEAD to get the latest commit of ddev, even if it's not yet in a release. If you are using linux/WSL2, you will also likely need to install build-essential with the following command: sudo apt install -y build-essential . To download the latest version, you can visit the master-build workflow and choose the latest item (or the one that matches a commit you want to test). You'll see the artifacts for each OS there on the bottom of the page. And of course you can just see the latest build in action by visiting ddev on gitpod .","title":"Testing latest commits"},{"location":"developers/building-contributing/#testing-a-pr","text":"Each build of a PR has artifacts created in github, so you can click the details of the PR Build test, choose the PR you want to work with, and download the artifacts you need there. After you download and unzip the appropriate binary, you can place it in your $PATH. The easiest way to do this if you're using homebrew is brew unlink ddev and then unzip ddev.zip && chmod +x ddev && mv ddev /usr/local/bin/ddev . You can verify that the replacement worked via ddev -v . The output should be something like ddev version v1.19.1-42-g5334d3c1 (instead of the regular ddev version v1.19.1 ). (On macOS Big Sur these downloaded binaries are not signed, so you will want to xattr -r -d com.apple.quarantine /path/to/ddev in order to use them. The binaries on the master branch and the final binaries in any release are signed, of course.) You do not typically have to install anything else other than the downloaded binary; when you run it it will access any docker images that it needs. After you're done, you can remove the downloaded binary and brew link ddev .","title":"Testing a PR"},{"location":"developers/building-contributing/#open-in-gitpod","text":"Gitpod.io provides a quick preconfigured ddev experience in the browser, so you can test your PR (or someone else's) easily and without setting up an environment. In any PR you can use the URL https://gitpod.io/#https://github.com/drud/ddev/pulls/<YOURPR> to open that PR and build it in Gitpod. To just open and work on ddev you can use the button below. If you want to run a web project in there, you can just check it out into /workspace/<yourproject> and use it as usual. The things you're familiar with work as expected, except that ddev-router does not run, and A dummy project for gitpod is provided by default in /workspace/d9simple. You can just ddev poweroff and use your own.","title":"Open in Gitpod"},{"location":"developers/building-contributing/#making-changes-to-ddev-images","text":"If you need to make a change to one of the ddev images, you can make the change, but then it has to be built with a specific tag, and the tag has to be updated in pkg/versionconstants/versionconstants.go . So for example, make a change to containers/ddev-webserver/Dockerfile, then built it: cd containers/ddev-webserver make VERSION = 20210424_fix_dockerfile Then edit pkg/versionconstants/versionconstants.go to set var WebTag = \"20210424_fix_dockerfile\" and cd /workspace/ddev make ddev version should show you that you are using the correct webtag, and ddev start will show it. It's easiest to do this using gitpod (see above) because gitpod already has docker buildx all set up for you and the built ddev is in the $PATH.","title":"Making changes to ddev images"},{"location":"developers/building-contributing/#pull-requests-and-pr-preparation","text":"When preparing your pull request, please use a branch name like \"2020_ _short_description\" so that it's easy to track to you. If you're doing a docs-only PR that does not require full testing, please add \"[skip ci][ci skip]\" to your commit messages; it saves a lot of testing resources.","title":"Pull Requests and PR Preparation"},{"location":"developers/building-contributing/#docker-image-changes","text":"If you make changes to a docker image (like ddev-webserver), it won't have any effect unless you: Push an image with a specific tag by going to the image directory (like containers/ddev-webserver) by just doing make container VERSION=<branchname> in the containers/ddev-webserver directory. Multi-arch images require you to have a buildx builder, so docker buildx create --name ddev-builder-multi --use You can't push until you docker login . Push a container to hub.docker.com. Push with the tag that matches your branch. Pushing to <yourorg>/ddev-webserver repo is easy to accomplish with make push DOCKER_ORG=<yourorg> VERSION=<branchname> in the container directory . You might have to use other techniques to push to another repo. Update pkg/versionconstants/versionconstants.go with the WebImg and WebTag that relate to the docker image you pushed.","title":"Docker Image changes"},{"location":"developers/building-contributing/#local-builds-and-pushes","text":"To use buildx successfully you have to have the buildx docker plugin which is in many environments by default. To build multi-platform images you must docker buildx create --use as a one-time initialization. If you just want to work locally and do a quick build for your own architecture, you can: make VERSION=<version> for ddev-dbserver : make mariadb_10.3 VERSION=<version> etc. To push manually: cd containers/ddev-webserver make push VERSION=<tag> If you're pushing to a repo other than the one wired into the Makefile (like drud/ddev-webserver ) then cd containers/ddev-webserver make push VERSION=<tag> DOCKER_REPO=your/dockerrepo","title":"Local builds and pushes"},{"location":"developers/building-contributing/#pushes-using-github-actions","text":"To manually push using GitHub Actions,","title":"Pushes using GitHub Actions"},{"location":"developers/building-contributing/#for-most-images","text":"Visit Actions->Push Tagged Image Click \"Run workflow\" in the blue band near the top. Choose the branch, usually master and then the image to be pushed, ddev-webserver , ddev-dbserver , etc. Also you can use all to build and push all of them. Include a tag for the pushed image and GitHub will do all the work.","title":"For most images"},{"location":"developers/building-contributing/#for-ddev-dbserver","text":"Visit Actions->Push Tagged db Image Click \"Run workflow\" in the blue band near the top. Choose the branch, usually master . Include a tag for the pushed image and GitHub will do all the work.","title":"For ddev-dbserver"},{"location":"developers/building-contributing/#building","text":"Build the project with make and your resulting executable will end up in .gotmp/bin/linux_amd64/ddev or .gotmp/bin/linux_arm64/ddev (for Linux) or .gotmp/bin/windows_amd64/ddev.exe (for Windows) or .gotmp/bin/darwin_amd64/ddev or .gotmp/bin/darwin_arm64/ddev (for macOS). Build/test/check static analysis with make # Builds on current os/architecture make linux_amd64 make linux_arm64 make darwin_amd64 make darwin_arm64 make windows_amd64 make test make clean make staticrequired","title":"Building"},{"location":"developers/building-contributing/#testing","text":"Normal test invocation is just make test . Run a single test with an invocation like go test -v -run TestDevAddSites ./pkg/... or make testpkg TESTARGS=\"-run TestDevAddSites\" . The easiest way to run tests is from inside the excellent golang IDE Goland. Just click the arrowhead to the left of the test name. To see which DDEV commands the tests are executing, set the environment variable DDEV_DEBUG=true. Use GOTEST_SHORT=true to run just one CMS in each test, or GOTEST_SHORT= to run exactly one project type from the list of project types in the TestSites array . For example, GOTEST_SHORT=5 will run many tests only against TYPO3. To run a test (in the cmd package) against a individually compiled ddev binary set the DDEV_BINARY_FULLPATH environment variable, for example DDEV_BINARY_FULLPATH=$PWD/.gotmp/bin/linux_amd64/ddev make testcmd .","title":"Testing"},{"location":"developers/building-contributing/#automated-testing","text":"Anybody can view the CircleCI automated tests, and they usually show up any problems that are not OS-specific. Just click through on the testing section of the PR to see them. The Buildkite automated tests require special access, which we typically grant to any PR contributor that asks for it.","title":"Automated testing"},{"location":"developers/building-contributing/#docker-image-development","text":"The Docker images that DDEV uses are included in the containers/ directory: containers/ddev-webserver: Provides the web servers (the \"web\" container). containers/ddev-dbserver: Provides the \"db\" container. containers/ddev-router: The router image containers/ddev-ssh-agent When changes are made to an image, they have to be temporarily pushed to a tag that is preferably the same as the branch name of the PR, and the tag updated in pkg/versionconstants/versionconstants.go . Just ask if you need a container pushed to support a PR.","title":"Docker image development"},{"location":"developers/building-contributing/#pull-request-pro-tips","text":"Fork the repository and clone it locally. Connect your local to the original \u2018upstream\u2019 repository by adding it as a remote. - Pull in changes from \u2018upstream\u2019 often so that you stay up to date so that when you submit your pull request, merge conflicts - will be less likely. See more detailed instructions here . Create a branch for your edits. Be clear about what problem is occurring and how someone can recreate that problem or why your feature will help. Then be equally as clear about the steps you took to make your changes. It\u2019s best to test . Run your changes against any existing tests if they exist and create new ones when needed. Whether tests exist or not, make sure your changes don\u2019t break the existing project.","title":"Pull Request Pro Tips"},{"location":"developers/building-contributing/#open-pull-requests","text":"Once you\u2019ve opened a pull request, a discussion will start around your proposed changes. Other contributors and users may chime in, but ultimately the decision is made by the maintainer(s). You may be asked to make some changes to your pull request. If so, add more commits to your branch and push them \u2013 they\u2019ll automatically go into the existing pull request. If your pull request is merged \u2013 great! If it is not, no sweat, it may not be what the project maintainer had in mind, or they were already working on it. This happens, so our recommendation is to take any feedback you\u2019ve received and go forth and pull request again \u2013 or create your own open source project. Adapted from GitHub Guides","title":"Open Pull Requests"},{"location":"developers/building-contributing/#coding-style","text":"Unless explicitly stated, we follow all coding guidelines from the Go community. While some of these standards may seem arbitrary, they somehow seem to result in a solid, consistent codebase. It is possible that the code base does not currently comply with these guidelines. We are not looking for a massive PR that fixes this since that goes against the spirit of the guidelines. All new contributions should make a best effort to clean up and make the code base better than they left it. Obviously, apply your best judgment. Remember, the goal here is to make the code base easier for humans to navigate and understand. Always keep that in mind when nudging others to comply. Just use make staticrequired to ensure that your code can pass the required static analysis tests. The rules: All code should be formatted with gofmt -s . All code should pass the default levels of golint . All code should follow the guidelines covered in Effective Go and Go Code Review Comments . Comment the code. Tell us the why, the history and the context. Document all declarations and methods, even private ones. Declare expectations, caveats and anything else that may be important. If a type gets exported, having the comments already there will ensure it's ready. Variable name length should be proportional to its context and no longer. noCommaALongVariableNameLikeThisIsNotMoreClearWhenASimpleCommentWouldDo . In practice, short methods will have short variable names and globals will have longer names. No underscores in package names. If you need a compound name, step back, and re-examine why you need a compound name. If you still think you need a compound name, lose the underscore. All tests should run with go test and outside tooling should not be required. No, we don't need another unit testing framework. Assertion packages are acceptable if they provide real incremental value. Even though we call these \"rules\" above, they are actually just guidelines. Since you've read all the rules, you now know that. If you are having trouble getting into the mood of idiomatic Go, we recommend reading through Effective Go . The Go Blog is also a great resource. Drinking the kool-aid is a lot easier than going thirsty.","title":"Coding Style"},{"location":"developers/buildkite-testmachine-setup/","text":"Buildkite Test Agent Setup \u00b6 We are using Buildkite for Windows and macOS testing. The build machines and buildkite-agent must be set up before use. Windows Test Agent Setup \u00b6 Create the user \"testbot\" on the machine. The password should be the password of ddevtestbot@gmail.com (available in lastpass) In admin PowerShell, wsl --install In admin PowerShell, Set-ExecutionPolicy -Scope \"CurrentUser\" -ExecutionPolicy \"RemoteSigned\" In admin PowerShell, download and run windows_buildkite_start.ps1 (Use curl <url> -O windows_buildkite_start.ps1 ) After restart, in administrative git-bash window, Rename-Computer <testbot-win10(home|pro)-<description>-1 and then export BUILDKITE_AGENT_TOKEN=<token> Now download and run windows_buildkite-testmachine_setup.sh Download and run windows_postinstall.sh Launch Docker. It may require you to take further actions. Log into Chrome with the user ddevtestbot@gmail.com and enable Chrome Remote Desktop. Enable gd, fileinfo, and curl extensions in /c/tools/php*/php.ini If a laptop, set the \"lid closing\" setting in settings to do nothing. Set the \"Sleep after time\" setting in settings to never. Install winaero tweaker and \"Enable user autologin checkbox\". Set up the machine to automatically log in on boot . Then run netplwiz, provide the password for the main user, uncheck the \"require a password to log in\". The buildkite/hooks/environment.bat file must be updated to contain the docker pull credentials: @echo off set DOCKERHUB_PULL_USERNAME = druddockerpullaccount set DOCKERHUB_PULL_PASSWORD = Set the buildkite-agent service to run as the testbot user and use delayed start: Choose \"Automatic, delayed start\" and on the \"Log On\" tab in the services widget it must be set up to log in as the testbot user, so it inherits environment variables and home directory (and can access NFS, has testbot git config, etc). git config --global --add safe.directory '*' Manually run testbot_maintenance.sh , curl -sL -O https://raw.githubusercontent.com/drud/ddev/master/.buildkite/testbot_maintenance.sh && bash testbot_maintenance.sh Run .buildkite/sanetestbot.sh to check your work. Reboot the machine and do a test run. (On windows the machine name only takes effect on reboot. Verify that go, ddev, git-bash are in the path In \"Advanced Windows Update Settings\" enable \"Receive updates for other Microsoft products\" to make sure you get WSL2 kernel upgrades. Make sure to run Windows update to get latest kernel. Additional Windows setup for WSL2 testing \u00b6 Do not set up buildkite-agent on the Windows side, or disable it. Open WSL2 and check out ddev Install buildkite-agent in WSL2 and configure it. It needs the same changes as macOS, but tags tags=\"os=wsl2,architecture=amd64,dockertype=dockerforwindows\" and build-path should be in ~/tmp/buildkite-agent As root user, run .github/workflows/linux-setup.sh As root user, add sudo capability with echo \"ALL ALL=NOPASSWD: ALL\" >/etc/sudoers.d/all && chmod 440 /etc/sudoers.d/all Test from PowerShell that wsl -d Ubuntu buildkite-agent start succeeds and starts listening. Set up Windows to automatically start WSL2 buildkite-agent: Use task scheduler to create a simple task that runs C:\\Windows\\System32\\wsl.exe -d Ubuntu buildkite-agent start at login. Install homebrew, /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Manually run testbot_maintenance.sh , curl -sL -O https://raw.githubusercontent.com/drud/ddev/master/.buildkite/testbot_maintenance.sh && bash testbot_maintenance.sh git config --global --add safe.directory '*' The buildkite/hooks/environment file must be updated to contain the docker pull credentials: #!/bin/bash export DOCKERHUB_PULL_USERNAME = druddockerpullaccount export DOCKERHUB_PULL_PASSWORD = xxx set -e macOS Test Agent Setup (works for M1 as well) \u00b6 Create the user \"testbot\" on the machine. The password should be the password of ddevtestbot@gmail.com . Change the name of the machine to something in keeping with current style. Maybe testbot-macstadium-macos-3 . Install Homebrew /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" Install golang/git/docker with brew install buildkite/buildkite/buildkite-agent bats-core colima composer drud/ddev/ddev git golang jq mariadb mkcert netcat p7zip && brew install --cask docker iterm2 google-chrome nosleep ngrok Run ngrok config add-authtoken <token> with token for free account. mkcert -install Run Docker manually and go through its configuration routine. Run iTerm. On Mojave and higher it may prompt for requiring full disk access permissions, follow through with that. Set up nfsd by running macos_ddev_nfs_setup.sh git config --global --add safe.directory '*' Edit the buildkite-agent.cfg in /usr/local/etc/buildkite-agent/buildkite-agent.cfg or /opt/homebrew/etc/buildkite-agent/buildkite-agent.cfg to add the agent token Tags, like \"os=macos,architecture=arm64,osvariant=monterrey,dockertype=dockerformac\" build-path=\"~/tmp/buildkite-agent/builds\" The buildkite/hooks/environment file must be updated to contain the docker pull credentials #!/bin/bash export DOCKERHUB_PULL_USERNAME = druddockerpullaccount export DOCKERHUB_PULL_PASSWORD = xxx set -e brew services start buildkite-agent Manually run testbot_maintenance.sh , curl -sL -O https://raw.githubusercontent.com/drud/ddev/master/.buildkite/testbot_maintenance.sh && bash testbot_maintenance.sh Enable nosleep using its shortcut in the Mac status bar. In nosleep Preferences, enable \"Never sleep on AC Adapter\", \"Never sleep on Battery\", and \"Start nosleep utility on system startup\". sudo chown testbot /usr/local/bin Set up Mac to automatically log in on boot . Try checking out ddev and running .buildkite/sanetestbot.sh to check your work. Log into Chrome with the user ddevtestbot@gmail.com and enable Chrome Remote Desktop. Set the timezone properly (US MT) Start the agent with brew services start buildkite-agent","title":"Buildkite Test Agent Setup"},{"location":"developers/buildkite-testmachine-setup/#buildkite-test-agent-setup","text":"We are using Buildkite for Windows and macOS testing. The build machines and buildkite-agent must be set up before use.","title":"Buildkite Test Agent Setup"},{"location":"developers/buildkite-testmachine-setup/#windows-test-agent-setup","text":"Create the user \"testbot\" on the machine. The password should be the password of ddevtestbot@gmail.com (available in lastpass) In admin PowerShell, wsl --install In admin PowerShell, Set-ExecutionPolicy -Scope \"CurrentUser\" -ExecutionPolicy \"RemoteSigned\" In admin PowerShell, download and run windows_buildkite_start.ps1 (Use curl <url> -O windows_buildkite_start.ps1 ) After restart, in administrative git-bash window, Rename-Computer <testbot-win10(home|pro)-<description>-1 and then export BUILDKITE_AGENT_TOKEN=<token> Now download and run windows_buildkite-testmachine_setup.sh Download and run windows_postinstall.sh Launch Docker. It may require you to take further actions. Log into Chrome with the user ddevtestbot@gmail.com and enable Chrome Remote Desktop. Enable gd, fileinfo, and curl extensions in /c/tools/php*/php.ini If a laptop, set the \"lid closing\" setting in settings to do nothing. Set the \"Sleep after time\" setting in settings to never. Install winaero tweaker and \"Enable user autologin checkbox\". Set up the machine to automatically log in on boot . Then run netplwiz, provide the password for the main user, uncheck the \"require a password to log in\". The buildkite/hooks/environment.bat file must be updated to contain the docker pull credentials: @echo off set DOCKERHUB_PULL_USERNAME = druddockerpullaccount set DOCKERHUB_PULL_PASSWORD = Set the buildkite-agent service to run as the testbot user and use delayed start: Choose \"Automatic, delayed start\" and on the \"Log On\" tab in the services widget it must be set up to log in as the testbot user, so it inherits environment variables and home directory (and can access NFS, has testbot git config, etc). git config --global --add safe.directory '*' Manually run testbot_maintenance.sh , curl -sL -O https://raw.githubusercontent.com/drud/ddev/master/.buildkite/testbot_maintenance.sh && bash testbot_maintenance.sh Run .buildkite/sanetestbot.sh to check your work. Reboot the machine and do a test run. (On windows the machine name only takes effect on reboot. Verify that go, ddev, git-bash are in the path In \"Advanced Windows Update Settings\" enable \"Receive updates for other Microsoft products\" to make sure you get WSL2 kernel upgrades. Make sure to run Windows update to get latest kernel.","title":"Windows Test Agent Setup"},{"location":"developers/buildkite-testmachine-setup/#additional-windows-setup-for-wsl2-testing","text":"Do not set up buildkite-agent on the Windows side, or disable it. Open WSL2 and check out ddev Install buildkite-agent in WSL2 and configure it. It needs the same changes as macOS, but tags tags=\"os=wsl2,architecture=amd64,dockertype=dockerforwindows\" and build-path should be in ~/tmp/buildkite-agent As root user, run .github/workflows/linux-setup.sh As root user, add sudo capability with echo \"ALL ALL=NOPASSWD: ALL\" >/etc/sudoers.d/all && chmod 440 /etc/sudoers.d/all Test from PowerShell that wsl -d Ubuntu buildkite-agent start succeeds and starts listening. Set up Windows to automatically start WSL2 buildkite-agent: Use task scheduler to create a simple task that runs C:\\Windows\\System32\\wsl.exe -d Ubuntu buildkite-agent start at login. Install homebrew, /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Manually run testbot_maintenance.sh , curl -sL -O https://raw.githubusercontent.com/drud/ddev/master/.buildkite/testbot_maintenance.sh && bash testbot_maintenance.sh git config --global --add safe.directory '*' The buildkite/hooks/environment file must be updated to contain the docker pull credentials: #!/bin/bash export DOCKERHUB_PULL_USERNAME = druddockerpullaccount export DOCKERHUB_PULL_PASSWORD = xxx set -e","title":"Additional Windows setup for WSL2 testing"},{"location":"developers/buildkite-testmachine-setup/#macos-test-agent-setup-works-for-m1-as-well","text":"Create the user \"testbot\" on the machine. The password should be the password of ddevtestbot@gmail.com . Change the name of the machine to something in keeping with current style. Maybe testbot-macstadium-macos-3 . Install Homebrew /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" Install golang/git/docker with brew install buildkite/buildkite/buildkite-agent bats-core colima composer drud/ddev/ddev git golang jq mariadb mkcert netcat p7zip && brew install --cask docker iterm2 google-chrome nosleep ngrok Run ngrok config add-authtoken <token> with token for free account. mkcert -install Run Docker manually and go through its configuration routine. Run iTerm. On Mojave and higher it may prompt for requiring full disk access permissions, follow through with that. Set up nfsd by running macos_ddev_nfs_setup.sh git config --global --add safe.directory '*' Edit the buildkite-agent.cfg in /usr/local/etc/buildkite-agent/buildkite-agent.cfg or /opt/homebrew/etc/buildkite-agent/buildkite-agent.cfg to add the agent token Tags, like \"os=macos,architecture=arm64,osvariant=monterrey,dockertype=dockerformac\" build-path=\"~/tmp/buildkite-agent/builds\" The buildkite/hooks/environment file must be updated to contain the docker pull credentials #!/bin/bash export DOCKERHUB_PULL_USERNAME = druddockerpullaccount export DOCKERHUB_PULL_PASSWORD = xxx set -e brew services start buildkite-agent Manually run testbot_maintenance.sh , curl -sL -O https://raw.githubusercontent.com/drud/ddev/master/.buildkite/testbot_maintenance.sh && bash testbot_maintenance.sh Enable nosleep using its shortcut in the Mac status bar. In nosleep Preferences, enable \"Never sleep on AC Adapter\", \"Never sleep on Battery\", and \"Start nosleep utility on system startup\". sudo chown testbot /usr/local/bin Set up Mac to automatically log in on boot . Try checking out ddev and running .buildkite/sanetestbot.sh to check your work. Log into Chrome with the user ddevtestbot@gmail.com and enable Chrome Remote Desktop. Set the timezone properly (US MT) Start the agent with brew services start buildkite-agent","title":"macOS Test Agent Setup (works for M1 as well)"},{"location":"developers/github-selfhosted-setup/","text":"Github Self-Hosted Agent Setup \u00b6 We are using GitHub Self-Hosted Agents for Windows and macOS testing. The build machines and agents must be set up before use. Windows Agent Setup \u00b6 Create the user \"testbot\" on the machine. The password should be the password of testbot@drud.com (available in 1password) In admin PowerShell, Set-ExecutionPolicy -Scope \"CurrentUser\" -ExecutionPolicy \"RemoteSigned\" In admin Powershell, download and run windows_buildkite_start.ps1 (Use curl <url> -O windows_buildkite_start.ps1 ) After restart, in administrative git-bash window, Rename-Computer <testbot-win10(home|pro)-<description>-1 . Now download and run windows_github_agent_setup.sh Launch Docker. It may require you to take further actions. Log into Chrome with the user testbot@drud.com and enable Chrome Remote Desktop. Enable gd , fileinfo , and curl extensions in /c/tools/php*/php.ini If a laptop, set the \"lid closing\" setting in settings to do nothing. Set the \"Sleep after time\" setting in settings to never. Install winaero tweaker and \"Enable user autologin checkbox\". Set up the machine to automatically log in on boot . Then run netplwiz , provide the password for the main user, uncheck the \"require a password to log in\". Add the path C:\\Program Files\\git\\bin to the very front of the system environment variables. Otherwise Windows will try to use its own bash.exe or will try to use PowerShell. Install the github self-hosted runner software using the \"Add New\" instructions on https://github.com/organizations/drud/settings/actions . When it asks if you want it as a service... you do. Run .buildkite/sanetestbot.sh to check your work. Reboot the machine and do a test run. (On windows the machine name only takes effect on reboot.)","title":"Github Self-Hosted Agent Setup"},{"location":"developers/github-selfhosted-setup/#github-self-hosted-agent-setup","text":"We are using GitHub Self-Hosted Agents for Windows and macOS testing. The build machines and agents must be set up before use.","title":"Github Self-Hosted Agent Setup"},{"location":"developers/github-selfhosted-setup/#windows-agent-setup","text":"Create the user \"testbot\" on the machine. The password should be the password of testbot@drud.com (available in 1password) In admin PowerShell, Set-ExecutionPolicy -Scope \"CurrentUser\" -ExecutionPolicy \"RemoteSigned\" In admin Powershell, download and run windows_buildkite_start.ps1 (Use curl <url> -O windows_buildkite_start.ps1 ) After restart, in administrative git-bash window, Rename-Computer <testbot-win10(home|pro)-<description>-1 . Now download and run windows_github_agent_setup.sh Launch Docker. It may require you to take further actions. Log into Chrome with the user testbot@drud.com and enable Chrome Remote Desktop. Enable gd , fileinfo , and curl extensions in /c/tools/php*/php.ini If a laptop, set the \"lid closing\" setting in settings to do nothing. Set the \"Sleep after time\" setting in settings to never. Install winaero tweaker and \"Enable user autologin checkbox\". Set up the machine to automatically log in on boot . Then run netplwiz , provide the password for the main user, uncheck the \"require a password to log in\". Add the path C:\\Program Files\\git\\bin to the very front of the system environment variables. Otherwise Windows will try to use its own bash.exe or will try to use PowerShell. Install the github self-hosted runner software using the \"Add New\" instructions on https://github.com/organizations/drud/settings/actions . When it asks if you want it as a service... you do. Run .buildkite/sanetestbot.sh to check your work. Reboot the machine and do a test run. (On windows the machine name only takes effect on reboot.)","title":"Windows Agent Setup"},{"location":"developers/project-types/","text":"Adding New Project Types \u00b6 Adding and maintaining project types (like typo3 , magento2 , etc.) is not too hard. Please update and add to this doc when you find things that have been missed. To add a new project type: Add the new type to the list in nodeps.go Add to appTypeMatrix in apptypes.go Create a new go file for your project type, like django.go . Implement the functions that you think are needed for your project type and add references to them in your appTypeMatrix stanza. There are lots of examples that you can start with in places like drupal.go and typo3.go , shopware6.go , etc. The comments in the code in apptypes.go for the appTypeFuncs for each type of action tell what these are for, but here's a quick summary. settingsCreator is the function that will create a main settings file if none exists. uploadDir returns the filepath of the user-uploaded files directory for the project type, like sites/default/files for Drupal or pub/media for magento2. hookDefaultComments adds comments to config.yaml about hooks with an example for that project type. It's probably not useful at all. apptypeSettingsPaths returns the paths for the main settings file and the extra settings file that ddev may create (like settings.ddev.php for Drupal). appTypeDetect is a function that determines whether the project is of the type you're implementing. postImportDBAction can do something after db import. I don't see it implemented anywhere. configOverrideAction can change default config for your project type. For example, magento2 now requires php8.1 , so a configOverrideAction can change the php version. postConfigAction gives a chance to do something at the end of config... but it doesn't seem to be used anywhere. postStartAction adds actions at the end of ddev start . You'll see several implementations of this, for things like creating needed default directories, or setting permissions on files, etc. importFilesAction defines how ddev import-files works for this project type. defaultWorkingDirMap allows the project type to override the project's working_dir (where ddev ssh and ddev exec start by default). This is mostly not done any more, as the working_dir is typically the project root. You'll likely need templates for settings files, use the drupal or typo3 templates as examples, for example pkg/ddevapp/drupal and pkg/ddevapp/typo3 . Those templates have to be loaded at runtime as well. Once your project type starts working and behaving the way you want it to, you'll need to add test artifacts for it and try testing it (locally first). Add your project to TestSites in ddevapp_test.go. Create a DDEV project named testpkg<projectype> somewhere and get it going and working with a database and files you can export. Export the database, files, and (optionally) code to tarballs or .sql.gz . Put them somewhere on the internet- they'll end up in drud/ddev_test_tarballs - I can give you permissions on that if you like. The magento2 project has descriptions explaining how each tarball gets created. Do that for yours as well. Run the test and get it working. I usually use the trick of setting GOTEST_SHORT=<element_in_TestSites> , like GOTEST_SHORT=7 . Then set that environment variable in the Goland profile or your environment. export GOTEST_SHORT=7 && make testpkg TEST_ARGS=\"-run TestDdevFullsiteSetup\"","title":"Adding New Project Types"},{"location":"developers/project-types/#adding-new-project-types","text":"Adding and maintaining project types (like typo3 , magento2 , etc.) is not too hard. Please update and add to this doc when you find things that have been missed. To add a new project type: Add the new type to the list in nodeps.go Add to appTypeMatrix in apptypes.go Create a new go file for your project type, like django.go . Implement the functions that you think are needed for your project type and add references to them in your appTypeMatrix stanza. There are lots of examples that you can start with in places like drupal.go and typo3.go , shopware6.go , etc. The comments in the code in apptypes.go for the appTypeFuncs for each type of action tell what these are for, but here's a quick summary. settingsCreator is the function that will create a main settings file if none exists. uploadDir returns the filepath of the user-uploaded files directory for the project type, like sites/default/files for Drupal or pub/media for magento2. hookDefaultComments adds comments to config.yaml about hooks with an example for that project type. It's probably not useful at all. apptypeSettingsPaths returns the paths for the main settings file and the extra settings file that ddev may create (like settings.ddev.php for Drupal). appTypeDetect is a function that determines whether the project is of the type you're implementing. postImportDBAction can do something after db import. I don't see it implemented anywhere. configOverrideAction can change default config for your project type. For example, magento2 now requires php8.1 , so a configOverrideAction can change the php version. postConfigAction gives a chance to do something at the end of config... but it doesn't seem to be used anywhere. postStartAction adds actions at the end of ddev start . You'll see several implementations of this, for things like creating needed default directories, or setting permissions on files, etc. importFilesAction defines how ddev import-files works for this project type. defaultWorkingDirMap allows the project type to override the project's working_dir (where ddev ssh and ddev exec start by default). This is mostly not done any more, as the working_dir is typically the project root. You'll likely need templates for settings files, use the drupal or typo3 templates as examples, for example pkg/ddevapp/drupal and pkg/ddevapp/typo3 . Those templates have to be loaded at runtime as well. Once your project type starts working and behaving the way you want it to, you'll need to add test artifacts for it and try testing it (locally first). Add your project to TestSites in ddevapp_test.go. Create a DDEV project named testpkg<projectype> somewhere and get it going and working with a database and files you can export. Export the database, files, and (optionally) code to tarballs or .sql.gz . Put them somewhere on the internet- they'll end up in drud/ddev_test_tarballs - I can give you permissions on that if you like. The magento2 project has descriptions explaining how each tarball gets created. Do that for yours as well. Run the test and get it working. I usually use the trick of setting GOTEST_SHORT=<element_in_TestSites> , like GOTEST_SHORT=7 . Then set that environment variable in the Goland profile or your environment. export GOTEST_SHORT=7 && make testpkg TEST_ARGS=\"-run TestDdevFullsiteSetup\"","title":"Adding New Project Types"},{"location":"developers/release-management/","text":"DDEV Release Management and Docker Images \u00b6 GitHub Actions Required Secrets \u00b6 The following \"Repository secret\" environment variables must be added to https://github.com/drud/ddev/settings/secrets/actions AUR_SSH_PRIVATE_KEY : The private ssh key for the ddev-releaser user. This must be processed into a single line, for example, perl -p -e 's/\\n/<SPLIT>/' ~/.ssh/id_rsa_ddev_releaser| pbcopy . CHOCOLATEY_API_KEY : API key for chocolatey. DDEV_GITHUB_TOKEN : The GitHub token that gives access to create releases and push to the homebrew repositories. DDEV_MACOS_APP_PASSWORD : The password used for notarization, see signing_tools DDEV_MACOS_SIGNING_PASSWORD : The password the access the signing key on macOS, see signing_tools DDEV_WINDOWS_SIGNING_PASSWORD : The windows signing password. SegmentKey : The key that enabled the Segment reporting. FURY_ACCOUNT : The account at fury.io to push the packages to. FURY_TOKEN : The push token assigned to the fury account above. Creating a release (almost everything is now automated) \u00b6 Prerelease tasks \u00b6 Make sure the version-history.md file is up to date. Make sure the docker images are all tagged and pushed. Make sure the pkg/version/version.go is all set to point to the new images (and tests have been run) Actual release creation \u00b6 Create a release for the new version using the GitHub UI. It should be \"prerelease\" if it's an edge release. Use the \"Auto-generate release notes\" option to get the commit list, then edit to add all the other necessary info. Verify that homebrew (linux and macOS) and Chocolatey and AUR are working correctly with the right versions Pushing docker images with the GitHub Actions workflow \u00b6 The easiest way to push docker images is to use the GitHub Actions workflow, especially if the code for the image is already in the ddev repo. You can push an image at https://github.com/drud/ddev/actions/workflows/push-tagged-image.yml If you need to push from a forked PR, you'll have to do this from your fork (for example, https://github.com/drud/rfay/actions/workflows/push-tagged-image.yml ), and you'll have to specify the branch on the fork. This requires that the DOCKERHUB_TOKEN and DOCKERHUB_USERNAME secrets be set on the forked PR, for example https://github.com/rfay/ddev/settings/secrets/actions . Visit https://github.com/drud/ddev/actions/workflows/push-tagged-image.yml Click the \"Push tagged image\" workflow on the left side of the page. Click the \"Run workflow\" button in the blue section above the workflow runs. Choose the branch to build from (usually master) Enter the image (ddev-webserver, ddev-dbserver, ddev-php-base, etc) Enter the tag that will be used in pkg/version/version.go. Pushing docker images manually \u00b6 It's more error-prone, but images can be pushed from the command-line. docker login with a user that has privileges to push. docker buildx create --name ddev-builder-multi --use or if it already exists, docker buildx use ddev-builder-multi cd containers/<image> Before pushing ddev-webserver, make sure you've pushed a version of ddev-php-base and updated ddev-webserver's Dockerfile to use that as a base. make push VERSION=<release_version> DOCKER_ARGS=--no-cache for most of the images. For ddev-dbserver it's make PUSH=true VERSION=<release_version> DOCKER_ARGS=--no-cache . There is a push-all.sh script to update all. But it takes forever. Maintaining ddev-dbserver mysql:5.7 and mysql:8.0 ARM64 images \u00b6 Sadly, there are no arm64 Docker images for mysql:5.7 and mysql:8.0, so we have a whole process to maintain our own for ddev. We maintain drud/mysql-arm64-images and drud/xtrabackup-build for this reason. drud/mysql:5.7 uses Ubuntu 18.04 as the base image, and Ubuntu 18.04 arm64 has mysql-server 5.7 in it, so we can install. drud/mysql:8.0 uses Ubuntu 20.04 as the base image, and Ubuntu 20.04 arm64 has mysql-server 8.0 in it, so we can install it from packages. Unfortunately, the ddev snapshot feature depends on xtrabackup 8.0 being installed for mysql:8.0. And there are no arm64 packages or binaries provided by percona for xtrabackup. So we build it from source with drud/xtrabackup-build . BUT... xtrabackup's development cycle lags behind mysql:8.0's development cycle, so you can't build a usable drud/mysql:8.0 image until there's an xtrabackup version released. Also unfortunately, when Ubuntu bumps mysql-server-8.0 to a new version, there's no way to use the old one. So the only time that you can maintain drud/mysql:8.0 is when Ubuntu 20.04 has the same version that's released for percona-xtrabackup. (In the case at this writeup, I was finally able to build percona-xtrabackup 8.0.28... and the same day Ubuntu bumped its packages to 8.0.29, meaning that it was unusable.) To build percona-xtrabackup, follow the instructions on drud/xtrabackup-build . You just create a release with the release of Percona xtrabackup, for example 8.0.29-21 . When that succeeds, then there is an upstream xtrabackup to be used in the drud/mysql:8.0 build. To build drud/mysql (both 5.7 and 8.0) arm64 images, follow the instructions on drud/mysql-arm64-images After the various files are updated, you can just push a new release and the proper images will be pushed. After building a new set of drud/mysql images, you'll need to push drud/ddev-dbserver with new tags. Make sure to update the drud/ddev-dbserver Makefile to set the explicit version of the upstream mysql:8.0 (for example, 8.0.29, if you've succeed in getting 8.0.29 for percona-xtrabackup and mysql:8.0). Actual release docker image updates \u00b6 I don't actually build every image for every point release. If there have been no changes to ddev-router or ddev-ssh-agent, for example, I only usually push those (and update pkg/version/version.go) on major releases. But here are the steps for building: The drud/ddev-php-base image must be updated as necessary with a new tag before pushing ddev-webserver . You can do this using the process above The drud/ddev-webserver Dockerfile must FROM drud/ddev-php-base:<tag> before building/pushing ddev-webserver . But then it can be pushed using either the Github Actions or the manual technique. If you're bumping ddev-dbserver 8.0 minor release, follow the upstream instructions here . Push images using the process above . Update pkg/version/version.go with the correct versions for the new images, and run a full test run. Manually updating homebrew formulas \u00b6 Homebrew formulas are normally updated just fine by the release process, so nothing needs to be done. If you have to temporarily update the homebrew formulas, you can do that with a commit to https://github.com/drud/homebrew-ddev and https://github.com/drud/homebrew-ddev-edge . The bottles and checksums for macOS (high sierra) and x86_64_linux are built and pushed to the release page automatically by the release build process (see bump_homebrew.sh . Test brew upgrade ddev both on macOS and Linux and make sure ddev is the right version and behaves well. Manually updating Chocolatey \u00b6 Normallly the release process does OK with pushing to Chocolatey, but at times a failure can happen and it's not worth doing the whole release process again. Open up gitpod, https://gitpod.io/#https://github.com/drud/ddev and cd /workspace/ddev sudo apt-get update && sudo apt-get install -y nsis sudo .ci-scripts/nsis_setup.sh /usr/share/nsis make chocolatey cd .gotmp/bin/windows_amd64/chocolatey ```` * edit the checksum in tools/chocolateyinstall.ps1 to match the released checksum of the ddev-windows-installer ( not the choco package. For v1.19.2 this was <https://github.com/drud/ddev/releases/download/v1.19.2/ddev_windows_installer.v1.19.2.exe.sha256.txt> ) ``` bash rm .gotmp/bin/windows_amd64/chocolatey/*.nupkg export CHOCOLATEY_API_KEY = key33333 docker run --rm -v \"/ $PWD :/tmp/chocolatey\" -w \"//tmp/chocolatey\" linuturk/mono-choco pack ddev.nuspec ; docker run --rm -v $PWD :/tmp/chocolatey -w /tmp/chocolatey linuturk/mono-choco push -s [ https://push.chocolatey.org/ ]( https://push.chocolatey.org/ ) --api-key \" ${ CHOCOLATEY_API_KEY } \" Manually updating AUR repository \u00b6 The AUR repository is normally updated just fine by the release process, so nothing needs to be done. However, you can manually publish the release to the ddev AUR repository . The README.md in the AUR git repo ( ssh://aur@aur.archlinux.org/ddev-bin.git or https://aur.archlinux.org/ddev-bin.git ) has instructions on how to update, including how to do it with a Docker container, so it doesn't have to be done on an ArchLinux or Manjaro VM. Manually Signing the Windows installer \u00b6 (This is done by the release process, but the manual process documented here.) Note that this is done automatically by the release build, on a dedicated Windows test runner (GitHub Actions runner) named testbot-asus-win10pro. If it is to be done manually it has to be done on that machine or the fob has to be installed on another machine. After a reboot of this machine, sometimes an automated reboot, the password for the security fob has to be re-entered and Windows signing will fail until it is. I do this by opening up testbot-asus-win10pro using Chrome Remote Desktop (or manually physically opening it) and opening git-bash and cd ~/tmp && signtool sign gsudo.exe . There just happens to be a gsudo.exe there but it doesn't matter what you sign, the idea is to pop up the gui where you enter the password (which is in lastpass). Basic instructions \u00b6 Install the suggested Windows SDK Install Visual Studio Community 2015 Run the Developer Command Prompt The keyfob and Safenet Authentication Client must be installed. The best documentation for the Safenet software is at https://support.globalsign.com/ssl/ssl-certificates-installation/safenet-drivers . After make windows_install the ddev-windows-installer.exe will be in .ddev/bin/windows_amd64/ddev_windows_installer.exe and you can sign it with signtool sign ddev-windows-installer.exe . I do not believe that we should use this keyfob high-security approach to signing on the next go-around with the certs. It is way too difficult to manage, and the Safenet software is atrocious.","title":"DDEV Release Management and Docker Images"},{"location":"developers/release-management/#ddev-release-management-and-docker-images","text":"","title":"DDEV Release Management and Docker Images"},{"location":"developers/release-management/#github-actions-required-secrets","text":"The following \"Repository secret\" environment variables must be added to https://github.com/drud/ddev/settings/secrets/actions AUR_SSH_PRIVATE_KEY : The private ssh key for the ddev-releaser user. This must be processed into a single line, for example, perl -p -e 's/\\n/<SPLIT>/' ~/.ssh/id_rsa_ddev_releaser| pbcopy . CHOCOLATEY_API_KEY : API key for chocolatey. DDEV_GITHUB_TOKEN : The GitHub token that gives access to create releases and push to the homebrew repositories. DDEV_MACOS_APP_PASSWORD : The password used for notarization, see signing_tools DDEV_MACOS_SIGNING_PASSWORD : The password the access the signing key on macOS, see signing_tools DDEV_WINDOWS_SIGNING_PASSWORD : The windows signing password. SegmentKey : The key that enabled the Segment reporting. FURY_ACCOUNT : The account at fury.io to push the packages to. FURY_TOKEN : The push token assigned to the fury account above.","title":"GitHub Actions Required Secrets"},{"location":"developers/release-management/#creating-a-release-almost-everything-is-now-automated","text":"","title":"Creating a release (almost everything is now automated)"},{"location":"developers/release-management/#prerelease-tasks","text":"Make sure the version-history.md file is up to date. Make sure the docker images are all tagged and pushed. Make sure the pkg/version/version.go is all set to point to the new images (and tests have been run)","title":"Prerelease tasks"},{"location":"developers/release-management/#actual-release-creation","text":"Create a release for the new version using the GitHub UI. It should be \"prerelease\" if it's an edge release. Use the \"Auto-generate release notes\" option to get the commit list, then edit to add all the other necessary info. Verify that homebrew (linux and macOS) and Chocolatey and AUR are working correctly with the right versions","title":"Actual release creation"},{"location":"developers/release-management/#pushing-docker-images-with-the-github-actions-workflow","text":"The easiest way to push docker images is to use the GitHub Actions workflow, especially if the code for the image is already in the ddev repo. You can push an image at https://github.com/drud/ddev/actions/workflows/push-tagged-image.yml If you need to push from a forked PR, you'll have to do this from your fork (for example, https://github.com/drud/rfay/actions/workflows/push-tagged-image.yml ), and you'll have to specify the branch on the fork. This requires that the DOCKERHUB_TOKEN and DOCKERHUB_USERNAME secrets be set on the forked PR, for example https://github.com/rfay/ddev/settings/secrets/actions . Visit https://github.com/drud/ddev/actions/workflows/push-tagged-image.yml Click the \"Push tagged image\" workflow on the left side of the page. Click the \"Run workflow\" button in the blue section above the workflow runs. Choose the branch to build from (usually master) Enter the image (ddev-webserver, ddev-dbserver, ddev-php-base, etc) Enter the tag that will be used in pkg/version/version.go.","title":"Pushing docker images with the GitHub Actions workflow"},{"location":"developers/release-management/#pushing-docker-images-manually","text":"It's more error-prone, but images can be pushed from the command-line. docker login with a user that has privileges to push. docker buildx create --name ddev-builder-multi --use or if it already exists, docker buildx use ddev-builder-multi cd containers/<image> Before pushing ddev-webserver, make sure you've pushed a version of ddev-php-base and updated ddev-webserver's Dockerfile to use that as a base. make push VERSION=<release_version> DOCKER_ARGS=--no-cache for most of the images. For ddev-dbserver it's make PUSH=true VERSION=<release_version> DOCKER_ARGS=--no-cache . There is a push-all.sh script to update all. But it takes forever.","title":"Pushing docker images manually"},{"location":"developers/release-management/#maintaining-ddev-dbserver-mysql57-and-mysql80-arm64-images","text":"Sadly, there are no arm64 Docker images for mysql:5.7 and mysql:8.0, so we have a whole process to maintain our own for ddev. We maintain drud/mysql-arm64-images and drud/xtrabackup-build for this reason. drud/mysql:5.7 uses Ubuntu 18.04 as the base image, and Ubuntu 18.04 arm64 has mysql-server 5.7 in it, so we can install. drud/mysql:8.0 uses Ubuntu 20.04 as the base image, and Ubuntu 20.04 arm64 has mysql-server 8.0 in it, so we can install it from packages. Unfortunately, the ddev snapshot feature depends on xtrabackup 8.0 being installed for mysql:8.0. And there are no arm64 packages or binaries provided by percona for xtrabackup. So we build it from source with drud/xtrabackup-build . BUT... xtrabackup's development cycle lags behind mysql:8.0's development cycle, so you can't build a usable drud/mysql:8.0 image until there's an xtrabackup version released. Also unfortunately, when Ubuntu bumps mysql-server-8.0 to a new version, there's no way to use the old one. So the only time that you can maintain drud/mysql:8.0 is when Ubuntu 20.04 has the same version that's released for percona-xtrabackup. (In the case at this writeup, I was finally able to build percona-xtrabackup 8.0.28... and the same day Ubuntu bumped its packages to 8.0.29, meaning that it was unusable.) To build percona-xtrabackup, follow the instructions on drud/xtrabackup-build . You just create a release with the release of Percona xtrabackup, for example 8.0.29-21 . When that succeeds, then there is an upstream xtrabackup to be used in the drud/mysql:8.0 build. To build drud/mysql (both 5.7 and 8.0) arm64 images, follow the instructions on drud/mysql-arm64-images After the various files are updated, you can just push a new release and the proper images will be pushed. After building a new set of drud/mysql images, you'll need to push drud/ddev-dbserver with new tags. Make sure to update the drud/ddev-dbserver Makefile to set the explicit version of the upstream mysql:8.0 (for example, 8.0.29, if you've succeed in getting 8.0.29 for percona-xtrabackup and mysql:8.0).","title":"Maintaining ddev-dbserver mysql:5.7 and mysql:8.0 ARM64 images"},{"location":"developers/release-management/#actual-release-docker-image-updates","text":"I don't actually build every image for every point release. If there have been no changes to ddev-router or ddev-ssh-agent, for example, I only usually push those (and update pkg/version/version.go) on major releases. But here are the steps for building: The drud/ddev-php-base image must be updated as necessary with a new tag before pushing ddev-webserver . You can do this using the process above The drud/ddev-webserver Dockerfile must FROM drud/ddev-php-base:<tag> before building/pushing ddev-webserver . But then it can be pushed using either the Github Actions or the manual technique. If you're bumping ddev-dbserver 8.0 minor release, follow the upstream instructions here . Push images using the process above . Update pkg/version/version.go with the correct versions for the new images, and run a full test run.","title":"Actual release docker image updates"},{"location":"developers/release-management/#manually-updating-homebrew-formulas","text":"Homebrew formulas are normally updated just fine by the release process, so nothing needs to be done. If you have to temporarily update the homebrew formulas, you can do that with a commit to https://github.com/drud/homebrew-ddev and https://github.com/drud/homebrew-ddev-edge . The bottles and checksums for macOS (high sierra) and x86_64_linux are built and pushed to the release page automatically by the release build process (see bump_homebrew.sh . Test brew upgrade ddev both on macOS and Linux and make sure ddev is the right version and behaves well.","title":"Manually updating homebrew formulas"},{"location":"developers/release-management/#manually-updating-chocolatey","text":"Normallly the release process does OK with pushing to Chocolatey, but at times a failure can happen and it's not worth doing the whole release process again. Open up gitpod, https://gitpod.io/#https://github.com/drud/ddev and cd /workspace/ddev sudo apt-get update && sudo apt-get install -y nsis sudo .ci-scripts/nsis_setup.sh /usr/share/nsis make chocolatey cd .gotmp/bin/windows_amd64/chocolatey ```` * edit the checksum in tools/chocolateyinstall.ps1 to match the released checksum of the ddev-windows-installer ( not the choco package. For v1.19.2 this was <https://github.com/drud/ddev/releases/download/v1.19.2/ddev_windows_installer.v1.19.2.exe.sha256.txt> ) ``` bash rm .gotmp/bin/windows_amd64/chocolatey/*.nupkg export CHOCOLATEY_API_KEY = key33333 docker run --rm -v \"/ $PWD :/tmp/chocolatey\" -w \"//tmp/chocolatey\" linuturk/mono-choco pack ddev.nuspec ; docker run --rm -v $PWD :/tmp/chocolatey -w /tmp/chocolatey linuturk/mono-choco push -s [ https://push.chocolatey.org/ ]( https://push.chocolatey.org/ ) --api-key \" ${ CHOCOLATEY_API_KEY } \"","title":"Manually updating Chocolatey"},{"location":"developers/release-management/#manually-updating-aur-repository","text":"The AUR repository is normally updated just fine by the release process, so nothing needs to be done. However, you can manually publish the release to the ddev AUR repository . The README.md in the AUR git repo ( ssh://aur@aur.archlinux.org/ddev-bin.git or https://aur.archlinux.org/ddev-bin.git ) has instructions on how to update, including how to do it with a Docker container, so it doesn't have to be done on an ArchLinux or Manjaro VM.","title":"Manually updating AUR repository"},{"location":"developers/release-management/#manually-signing-the-windows-installer","text":"(This is done by the release process, but the manual process documented here.) Note that this is done automatically by the release build, on a dedicated Windows test runner (GitHub Actions runner) named testbot-asus-win10pro. If it is to be done manually it has to be done on that machine or the fob has to be installed on another machine. After a reboot of this machine, sometimes an automated reboot, the password for the security fob has to be re-entered and Windows signing will fail until it is. I do this by opening up testbot-asus-win10pro using Chrome Remote Desktop (or manually physically opening it) and opening git-bash and cd ~/tmp && signtool sign gsudo.exe . There just happens to be a gsudo.exe there but it doesn't matter what you sign, the idea is to pop up the gui where you enter the password (which is in lastpass).","title":"Manually Signing the Windows installer"},{"location":"developers/release-management/#basic-instructions","text":"Install the suggested Windows SDK Install Visual Studio Community 2015 Run the Developer Command Prompt The keyfob and Safenet Authentication Client must be installed. The best documentation for the Safenet software is at https://support.globalsign.com/ssl/ssl-certificates-installation/safenet-drivers . After make windows_install the ddev-windows-installer.exe will be in .ddev/bin/windows_amd64/ddev_windows_installer.exe and you can sign it with signtool sign ddev-windows-installer.exe . I do not believe that we should use this keyfob high-security approach to signing on the next go-around with the certs. It is way too difficult to manage, and the Safenet software is atrocious.","title":"Basic instructions"},{"location":"developers/styleguide/","text":"Styleguide \u00b6 Logos \u00b6 Figurative Mark Word/Figurative Mark You can find a set of DDEV logos here . If possible, use the SVG version of the logo, as a vector graphic is independent of the resolution and gives the best results regardless of the pixel density of the display. If the SVG format is not supported, you can use the exported PNG versions of the logo. Use @2x , @3x , and @4x for high pixel density displays. Many applications support @2x annotations in the image path and automatically choose the correct image for the display in use. Currently there is no prepared version for dark backgrounds of the word/figurative mark. Color Plate \u00b6 DDEV Blue DDEV Black #02a8e2 #1e2127 Use of the word mark DDEV \u00b6 The product DDEV is always referenced in capital letters. When referring to the binary ddev, lowercase letters are preferred.","title":"Styleguide"},{"location":"developers/styleguide/#styleguide","text":"","title":"Styleguide"},{"location":"developers/styleguide/#logos","text":"Figurative Mark Word/Figurative Mark You can find a set of DDEV logos here . If possible, use the SVG version of the logo, as a vector graphic is independent of the resolution and gives the best results regardless of the pixel density of the display. If the SVG format is not supported, you can use the exported PNG versions of the logo. Use @2x , @3x , and @4x for high pixel density displays. Many applications support @2x annotations in the image path and automatically choose the correct image for the display in use. Currently there is no prepared version for dark backgrounds of the word/figurative mark.","title":"Logos"},{"location":"developers/styleguide/#color-plate","text":"DDEV Blue DDEV Black #02a8e2 #1e2127","title":"Color Plate"},{"location":"developers/styleguide/#use-of-the-word-mark-ddev","text":"The product DDEV is always referenced in capital letters. When referring to the binary ddev, lowercase letters are preferred.","title":"Use of the word mark DDEV"},{"location":"developers/testing-docs/","text":"Working on the docs \u00b6 This section is designed for people who want to contribute to the DDEV documentation. When you are going to make any changes to the documentation it is recommended that you test them locally to see what your changes look like. Fork / clone the DDEV repository \u00b6 To start making changes you'll need a local copy of the DDEV documentation, so fork the DDEV repository as that's where the documentation lives. After forking the repository you can clone it to your local machine. Make your changes \u00b6 Now that you've got a local copy you can make your changes; Action Path Changing Documentation ./docs/content/users/* ./docs/content/developers/* Changing MkDocs Configuration ./mkdocs.yml Changing the front-end ./docs/content/assets/extra.css ./docs/content/assets/extra.js Preview your changes \u00b6 You should see how your changes look before making a pull request, you can do so by running make mkdocs-serve . It will launch a webserver on port 8000 so you can see what the docs will look like when they land on readthedocs.io. Please note: While it's easiest to install mkdocs locally it is not required, make mkdocs-serve will look for MkDocs but when it is not found it will run a docker command to serve the documentation on http://localhost:8000 . If you don't have make on your system, you can easily install it, but alternatively you can also just run the docker command that make mkdocs-serve runs: docker run -it -p 8000:8000 -v \"${PWD}:/docs\" -e \"ADD_MODULES=mkdocs-material mkdocs-redirects mkdocs-minify-plugin mdx_truly_sane_lists mkdocs-git-revision-date-localized-plugin\" -e \"LIVE_RELOAD_SUPPORT=true\" -e \"FAST_MODE=true\" -e \"DOCS_DIRECTORY=./docs\" polinux/mkdocs; Check changed markdown files for potential errors \u00b6 Before you publish your changes it is recommended to use markdownlint to check your files for any errors or inconsistencies. You can do so by running make markdownlint . Please note: The command make markdownlint requires you to have markdownlint-cli installed, which you can do by executing npm install -g markdownlint-cli Publish your changes \u00b6 If all looks good it's time to commit your changes and make a pull request back into the official DDEV repository. Please note: When you make a pull requests several tests/tasks will be ran. One task named 'docs/readthedocs.org:ddev' will build a version of the docs containing all the changes from your pull request which you can use to check the final result.","title":"Working on the docs"},{"location":"developers/testing-docs/#working-on-the-docs","text":"This section is designed for people who want to contribute to the DDEV documentation. When you are going to make any changes to the documentation it is recommended that you test them locally to see what your changes look like.","title":"Working on the docs"},{"location":"developers/testing-docs/#fork-clone-the-ddev-repository","text":"To start making changes you'll need a local copy of the DDEV documentation, so fork the DDEV repository as that's where the documentation lives. After forking the repository you can clone it to your local machine.","title":"Fork / clone the DDEV repository"},{"location":"developers/testing-docs/#make-your-changes","text":"Now that you've got a local copy you can make your changes; Action Path Changing Documentation ./docs/content/users/* ./docs/content/developers/* Changing MkDocs Configuration ./mkdocs.yml Changing the front-end ./docs/content/assets/extra.css ./docs/content/assets/extra.js","title":"Make your changes"},{"location":"developers/testing-docs/#preview-your-changes","text":"You should see how your changes look before making a pull request, you can do so by running make mkdocs-serve . It will launch a webserver on port 8000 so you can see what the docs will look like when they land on readthedocs.io. Please note: While it's easiest to install mkdocs locally it is not required, make mkdocs-serve will look for MkDocs but when it is not found it will run a docker command to serve the documentation on http://localhost:8000 . If you don't have make on your system, you can easily install it, but alternatively you can also just run the docker command that make mkdocs-serve runs: docker run -it -p 8000:8000 -v \"${PWD}:/docs\" -e \"ADD_MODULES=mkdocs-material mkdocs-redirects mkdocs-minify-plugin mdx_truly_sane_lists mkdocs-git-revision-date-localized-plugin\" -e \"LIVE_RELOAD_SUPPORT=true\" -e \"FAST_MODE=true\" -e \"DOCS_DIRECTORY=./docs\" polinux/mkdocs;","title":"Preview your changes"},{"location":"developers/testing-docs/#check-changed-markdown-files-for-potential-errors","text":"Before you publish your changes it is recommended to use markdownlint to check your files for any errors or inconsistencies. You can do so by running make markdownlint . Please note: The command make markdownlint requires you to have markdownlint-cli installed, which you can do by executing npm install -g markdownlint-cli","title":"Check changed markdown files for potential errors"},{"location":"developers/testing-docs/#publish-your-changes","text":"If all looks good it's time to commit your changes and make a pull request back into the official DDEV repository. Please note: When you make a pull requests several tests/tasks will be ran. One task named 'docs/readthedocs.org:ddev' will build a version of the docs containing all the changes from your pull request which you can use to check the final result.","title":"Publish your changes"},{"location":"users/quickstart/","text":"Quickstart for many CMSs \u00b6 Once you have DDEV installed, getting a project going is just these steps: Clone or create the code for your project. cd into the project and ddev config to configure it and turn it into a DDEV project. In most cases DDEV will autodetect the project type and docroot, but you may have to provide them in others. ddev start and if your project needs it, ddev composer install ddev launch to launch a browser with your project, or visit the URL given by ddev start . Import an upstream database with ddev import-db . Import user-files from upstream with ddev import-files Here's a quickstart instructions for a number of different environments: Any (generic) WordPress Drupal OpenMage/Magento 1 Magento 2 Laravel Shopware 6 Backdrop Any PHP or HTML/JS environment \u00b6 DDEV works happily with most any PHP or static HTML/JS project, although it has special additional support for several CMSs. But you don't need special support if you already know how to configure your project. Create a directory ( mkdir my-new-project ) or clone your project ( git clone <your_project> ) Change to the new directory ( cd my-new-project ) Run ddev config and set the project type and docroot, which are usually auto-detected, but may not be if there's no code in there yet. Run ddev start If a composer build, ddev composer install Configure any database settings; host='db', user='db', password='db', database='db' If needed, import a database with ddev import-db --src=/path/to/db.sql.gz . Visit the project and continue on. WordPress \u00b6 There are several easy ways to use DDEV with WordPress: wp-cli roots/bedrock git clone wp-cli \u00b6 DDEV has built-in support for WP-CLI , the command-line interface for WordPress. mkdir my-wp-site cd my-wp-site/ # create a new DDEV project inside the newly created folder # (the primary URL is automatically set to https://<folder>.ddev.site) ddev config --project-type = wordpress ddev start # download latest WordPress (via WP-CLI) ddev wp core download # finish the installation in your browser: ddev launch # optional: you can use the following installation command # (we need to use single quotes to get the primary site URL from .ddev/config.yaml as variable) ddev wp core install --url = '$DDEV_PRIMARY_URL' --title = 'New-WordPress' --admin_user = admin --admin_email = admin@example.com --prompt = admin_password # open WordPress admin dashboard in your browser: ddev launch wp-admin/ roots/bedrock \u00b6 roots/bedrock is a modern composer-based installation if WordPress: mkdir my-wp-bedrock-site cd my-wp-bedrock-site ddev config --project-type = wordpress --docroot = web --create-docroot ddev start ddev composer create roots/bedrock Now, since Bedrock uses a configuration technique which is unusual for WordPress, edit the .env file which has been created in the project root, and set: DB_NAME=db DB_USER=db DB_PASSWORD=db DB_HOST=db WP_HOME=${DDEV_PRIMARY_URL} WP_SITEURL=${WP_HOME}/wp WP_ENV=development You can then ddev start and ddev launch . For more details see Bedrock installation . git clone \u00b6 To get started using DDEV with an existing WordPress project, clone the project's repository. Note that the git URL shown here is just an example. git clone https://github.com/example/example-site.git cd example-site ddev config You'll see a message like: An existing user-managed wp-config.php file has been detected! Project ddev settings have been written to: /Users/rfay/workspace/bedrock/web/wp-config-ddev.php Please comment out any database connection settings in your wp-config.php and add the following snippet to your wp-config.php, near the bottom of the file and before the include of wp-settings.php: // Include for ddev-managed settings in wp-config-ddev.php. $ddev_settings = dirname(__FILE__) . '/wp-config-ddev.php'; if (is_readable($ddev_settings) && !defined('DB_USER')) { require_once($ddev_settings); } If you don't care about those settings, or config is managed in a .env file, etc, then you can eliminate this message by putting a line that says // wp-config-ddev.php not needed in your wp-config.php So just add the suggested include into your wp-config.php, or take the workaround shown. Now start your project with ddev start Quickstart instructions regarding database imports can be found under Importing a database . Drupal \u00b6 Drupal 9 Composer TYPO3 Drupal 9 composer build \u00b6 mkdir my-drupal9-site cd my-drupal9-site ddev config --project-type = drupal9 --docroot = web --create-docroot ddev start ddev composer create \"drupal/recommended-project\" --no-install ddev composer require drush/drush --no-install ddev composer install ddev drush site:install -y ddev drush uli ddev launch Drupal 10 Drupal 10 composer build \u00b6 Drupal 10 is not yet released, but lots of people want to test and contribute to it. It's easy to set it up in DDEV: mkdir my-drupal10-site cd my-drupal10-site ddev config --project-type = drupal10 --docroot = web --create-docroot ddev start ddev composer create --no-install drupal/recommended-project:^10@alpha ddev composer require drush/drush --no-install ddev composer install ddev drush site:install -y ddev drush uli ddev launch Note that as Drupal 10 moves from alpha to beta and then release, you'll want to change the tag from ^10@alpha to ^10@beta and then ^10 . Drupal 6/7 Drupal 6/7 install \u00b6 Using DDEV with a Drupal 6 or 7 project is as simple as cloning the project's repository and checking out its directory. git clone https://github.com/user/my-drupal-site cd my-drupal-site ddev config # Follow the prompts to select type and docroot ddev start ddev launch /install.php (Drupal 7 doesn't know how to redirect from the front page to the /install.php if the database is not set up but the settings files are set up, so launching with /install.php gets you started with an installation. You can also drush site-install , ddev exec drush site-install --yes ) Quickstart instructions for database imports can be found under Importing a database . Git clone Git clone build \u00b6 Note that the git URL shown below is an example only, you'll need to use your own project. git clone https://github.com/example/example-site cd example-site ddev config # Follow the prompts to set drupal version and docroot ddev composer install # If a composer build ddev launch TYPO3 \u00b6 Composer build Git clone TYPO3 composer build \u00b6 mkdir my-typo3-site cd my-typo3-site ddev config --project-type = typo3 --docroot = public --create-docroot ddev start ddev composer create \"typo3/cms-base-distribution\" --no-install ddev composer install ddev exec touch public/FIRST_INSTALL ddev launch TYPO3 git clone \u00b6 git clone https://github.com/example/example-site cd example-site ddev config ddev composer install ddev launch OpenMage/Magento 1 \u00b6 Download OpenMage from release page . Make a directory for it, for example mkdir ~/workspace/OpenMage and change to the new directory cd ~/workspace/OpenMage . ddev config and accept the defaults. (Install sample data - see below) Run ddev start Follow the URL to the base site. You may want the Magento 1 Sample Data for experimentation: Download Magento 1.9.1.0 Sample Data . Extract the download, for example tar -zxf ~/Downloads/compressed-magento-sample-data-1.9.1.0.tgz --strip-components=1 Import the example database \"magento_sample_data_for_1.9.1.0.sql\" with ddev import-db --src=magento_sample_data_for_1.9.1.0.sql to database before running OpenMage install. Note that OpenMage is a huge codebase and using mutagen_enabled: true is recommended for performance on macOS and traditional Windows, see docs . Magento 2 \u00b6 Normal details of a composer build for Magento 2 are on Magento 2 site You must have a public and private key to install from Magento's repository; when prompted for \"username\" and \"password\" in the composer create it's asking for your public and private keys. mkdir ddev-magento2 && cd ddev-magento2 ddev config --project-type = magento2 --php-version = 8 .1 --docroot = pub --create-docroot --disable-settings-management ddev get drud/ddev-elasticsearch ddev start ddev composer create --no-install --repository = https://repo.magento.com/ magento/project-community-edition -y ddev composer install rm -f app/etc/env.php # Change the base-url below to your project's URL ddev magento setup:install --base-url = 'https://ddev-magento2.ddev.site/' --cleanup-database --db-host = db --db-name = db --db-user = db --db-password = db --elasticsearch-host = elasticsearch --admin-firstname = Magento --admin-lastname = User --admin-email = user@example.com --admin-user = admin --admin-password = admin123 --language = en_US ddev magento deploy:mode:set developer ddev magento module:disable Magento_TwoFactorAuth ddev config --disable-settings-management = false Of course, change the admin name and related information is needed. You may want to add the Magento 2 Sample Data with ddev magento sampledata:deploy && ddev magento setup:upgrade . Note that Magento 2 is a huge codebase and using mutagen_enabled: true is recommended for performance on macOS and traditional Windows, see docs . Laravel \u00b6 Get started with Laravel projects on ddev either using a new or existing composer project or by cloning a git repository. The Laravel project type can be used for Lumen just as it can for Laravel. mkdir my-laravel-app cd my-laravel-app ddev config --project-type = laravel --docroot = public --create-docroot ddev start ddev composer create --prefer-dist laravel/laravel ddev exec \"cat .env.example | sed -E 's/DB_(HOST|DATABASE|USERNAME|PASSWORD)=(.*)/DB_\\1=db/g' > .env\" ddev exec 'sed -i \"s#APP_URL=.*#APP_URL=${DDEV_PRIMARY_URL}#g\" .env' ddev exec \"php artisan key:generate\" ddev launch In the examples above we used a one liner to copy .env.example as env and set the DB_HOST , DB_DATABASE , DB_USERNAME and DB_PASSWORD environment variables to the value of db . These values are DDEV's default settings for the Database connection. Instead of setting each connection variable we can add a ddev to the connections array in config/database.php like this: <?php return [ ... 'connections' => [ ... 'ddev' => [ 'driver' => 'mysql' , 'host' => 'db' , 'port' => 3306 , 'database' => 'db' , 'username' => 'db' , 'password' => 'db' , 'unix_socket' => '' , 'charset' => 'utf8mb4' , 'collation' => 'utf8mb4_unicode_ci' , 'prefix' => '' , 'strict' => true , 'engine' => null , ], ], ... ]; This way we only need to change the value of DB_CONNECTION to ddev in the .env to work with the db service. This is very handy if you have a local database installed and you want to switch between the connections faster by changing only one variable in .env Shopware 6 \u00b6 You can set up a Shopware 6 environment many ways, but this shows you one recommended technique: git clone --branch = 6 .4 https://github.com/shopware/production my-shopware6 cd my-shopware6 ddev config --project-type = shopware6 --docroot = public ddev start ddev composer install ddev exec bin/console system:setup --database-url = mysql://db:db@db:3306/db --app-url = '${DDEV_PRIMARY_URL}' ddev exec bin/console system:install --create-database --basic-setup ddev launch /admin Now log into the admin site (/admin) using the web browser. The default credentials are username=admin, password=shopware. You can use the web UI to install sample data or accomplish many other tasks. For more advanced tasks like adding elasticsearch, building and watching storefront and administration, see susi.dev . Backdrop \u00b6 To get started with Backdrop, clone the project repository and navigate to the project directory. git clone https://github.com/example/example-site cd example-site ddev config ddev start ddev launch Configuration files \u00b6 Note: If you're providing the settings.php or wp-config.php and DDEV is creating the settings.ddev.php (or wp-config-local.php , AdditionalConfig.php , or similar), the main settings file must explicitly include the appropriate DDEV-generated settings file. Any changes you need should be included somewhere that loads after DDEV's settings file, for example in Drupal's settings.php after settings.ddev.php is included. (see Adding Configuration below). Turning off settings management completely If you do not want DDEV-Local to create or manage settings files, set disable_settings_management: true in your .ddev/config.yaml or ddev config --disable-settings-management and you will be the only one that edits or updates settings files. The ddev config command attempts to create a CMS-specific settings file with DDEV credentials pre-populated. For Drupal and Backdrop , DDEV settings are written to a DDEV-managed file, settings.ddev.php. The ddev config command will ensure that these settings are included in your settings.php through the following steps: Write DDEV settings to settings.ddev.php If no settings.php file exists, create one that includes settings.ddev.php If a settings.php file already exists, ensure that it includes settings.ddev.php , modifying settings.php to write the include if necessary. For Magento 1 , DDEV settings go into app/etc/local.xml In Magento 2 , DDEV settings go into app/etc/env.php For TYPO3 , DDEV settings are written to AdditionalConfiguration.php . If AdditionalConfiguration.php exists and is not managed by DDEV, it will not be modified. For WordPress , DDEV settings are written to a DDEV-managed file, wp-config-ddev.php . The ddev config command will attempt to write settings through the following steps: Write DDEV settings to wp-config-ddev.php If no wp-config.php exists, create one that include wp-config-ddev.php If a DDEV-managed wp-config.php exists, create one that includes wp-config.php If a user-managed wp-config.php exists, instruct the user on how to modify it to include DDEV settings How do you know if DDEV manages a settings file? You will see the following comment. Remove the comment and DDEV will not attempt to overwrite it! If you are letting DDEV create its settings file, it is recommended that you leave this comment so DDEV can continue to manage it, and make any needed changes in another settings file. /** #ddev-generated: Automatically generated Drupal settings.php file. ddev manages this file and may delete or overwrite the file unless this comment is removed. */ Adding configuration \u00b6 Drupal and Backdrop : In settings.php , enable loading settings.local.php after settings.ddev.php is included (create a new one if it doesn't already exist), and make changes there (wrapping with if (getenv('IS_DDEV_PROJECT') == 'true') as needed). WordPress : Load a wp-config-local.php after wp-config-ddev.php , and make changes there (wrapping with if (getenv('IS_DDEV_PROJECT') == 'true') as needed). Listing project information \u00b6 ddev list or ddev list --active-only current projects. \u279c ddev list NAME TYPE LOCATION URL(s) STATUS d8git drupal8 ~/workspace/d8git <https://d8git.ddev.local> running <http://d8git.ddev.local> hobobiker drupal6 ~/workspace/hobobiker.com stopped \u279c ddev list --active-only NAME TYPE LOCATION URL(s) STATUS drupal8 drupal8 ~/workspace/drupal8 <http://drupal8.ddev.site> running <https://drupal8.ddev.site> You can also see more detailed information about a project by running ddev describe from its working directory. You can also run ddev describe [project-name] from any location to see the detailed information for a running project. NAME TYPE LOCATION URL STATUS d9composer drupal8 ~/workspace/d9composer https://d9composer.ddev.site running Project Information ------------------- PHP version: 7.4 MariaDB version 10.3 URLs ---- https://d9composer.ddev.site https://127.0.0.1:33232 http://d9composer.ddev.site http://127.0.0.1:33233 MySQL/MariaDB Credentials ------------------------- Username: \"db\", Password: \"db\", Default database: \"db\" or use root credentials when needed: Username: \"root\", Password: \"root\" Database hostname and port INSIDE container: ddev-d9-db:3306 To connect to db server inside container or in project settings files: mysql --host=ddev-d9-dbcomposer --user=db --password=db --database=db Database hostname and port from HOST: 127.0.0.1:33231 To connect to mysql from your host machine, mysql --host=127.0.0.1 --port=33231 --user=db --password=db --database=db Other Services -------------- MailHog (https): https://d9composer.ddev.site:8026 MailHog: http://d9composer.ddev.site:8025 phpMyAdmin (https): https://d9composer.ddev.site:8037 phpMyAdmin: http://d9composer.ddev.site:8036 DDEV ROUTER STATUS: healthy ssh-auth status: healthy Removing projects from DDEV-Local \u00b6 To remove a project from DDEV-Local's listing you can use the destructive option (deletes database, removes item from ddev's list, removes hostname entry in hosts file): ddev delete <projectname> or ddev delete --omit-snapshot <projectname> Or if you just don't want it to show up in ddev list any more, use ddev stop --unlist <projectname> to unlist it until the next time you ddev start or ddev config the project. Importing assets for an existing project \u00b6 An important aspect of local web development is the ability to have a precise recreation of the project you are working on locally, including up-to-date database contents and static assets such as uploaded images and files. ddev provides functionality to help with importing assets to your local environment with two commands. Importing a database \u00b6 The ddev import-db command is provided for importing the database for a project. Running this command will provide a prompt for you to specify the location of your database import. By default ddev import-db empties the default \"db\" database and then loads the provided dumpfile. Most people use it with command flags, like ddev import-db --src=.tarballs/db.sql.gz but it can also prompt for the location of the dumpfile if you just use ddev import-db : ddev import-db Provide the path to the database you wish to import. Import path: ~/Downloads/db.sql Importing database... Successfully imported database for drupal8 Supported file types \u00b6 Database import supports the following file types: Raw SQL Dump (.sql) Gzipped SQL Dump (.sql.gz) (Gzipped) Tarball Archive (.tar, .tar.gz, .tgz) Zip Archive (.zip) stdin If a Tarball Archive or Zip Archive is provided for the import, you will be provided an additional prompt, allowing you to specify a path within the archive to use for the import asset. The specified path should provide a Raw SQL Dump (.sql). In the following example, the database we want to import is named data.sql and resides at the top-level of the archive: ddev import-db Provide the path to the database you wish to import. Import path: ~/Downloads/site-backup.tar.gz You provided an archive. Do you want to extract from a specific path in your archive? You may leave this blank if you wish to use the full archive contents Archive extraction path: data.sql Importing database... A settings file already exists for your application, so ddev did not generate one. Run 'ddev describe' to find the database credentials for this application. Successfully imported database for drupal8 Non-interactive usage \u00b6 If you want to use import-db without answering prompts, you can use the --src flag to provide the path to the import asset. If you are importing an archive, and wish to specify the path within the archive to extract, you can use the --extract-path flag in conjunction with the --src flag. Examples: ddev import-db --src = /tmp/mydb.sql.gz gzip -dc /tmp/mydb.sql.gz | ddev import-db ddev import-db <mydb.sql Database import notes \u00b6 Importing from a dumpfile via stdin will not show progress because there's no way the import can know how far along through the import it has progressed. Use ddev import-db --target-db <some_database> to import to a non-default database (other than the default \"db\" database). This will create the database if it doesn't exist already. Use ddev import-db --no-drop to import without first emptying the database. If a database already exists and the import does not specify dropping tables, the contents of the imported dumpfile will be added to the database. Most full database dumps do a table drop and create before loading, but if yours does not, you can drop all tables with ddev stop --remove-data before importing.","title":"Quickstart for many CMSs"},{"location":"users/quickstart/#quickstart-for-many-cmss","text":"Once you have DDEV installed, getting a project going is just these steps: Clone or create the code for your project. cd into the project and ddev config to configure it and turn it into a DDEV project. In most cases DDEV will autodetect the project type and docroot, but you may have to provide them in others. ddev start and if your project needs it, ddev composer install ddev launch to launch a browser with your project, or visit the URL given by ddev start . Import an upstream database with ddev import-db . Import user-files from upstream with ddev import-files Here's a quickstart instructions for a number of different environments: Any (generic) WordPress Drupal OpenMage/Magento 1 Magento 2 Laravel Shopware 6 Backdrop","title":"Quickstart for many CMSs"},{"location":"users/quickstart/#any-php-or-htmljs-environment","text":"DDEV works happily with most any PHP or static HTML/JS project, although it has special additional support for several CMSs. But you don't need special support if you already know how to configure your project. Create a directory ( mkdir my-new-project ) or clone your project ( git clone <your_project> ) Change to the new directory ( cd my-new-project ) Run ddev config and set the project type and docroot, which are usually auto-detected, but may not be if there's no code in there yet. Run ddev start If a composer build, ddev composer install Configure any database settings; host='db', user='db', password='db', database='db' If needed, import a database with ddev import-db --src=/path/to/db.sql.gz . Visit the project and continue on.","title":"Any PHP or HTML/JS environment"},{"location":"users/quickstart/#wordpress","text":"There are several easy ways to use DDEV with WordPress: wp-cli roots/bedrock git clone","title":"WordPress"},{"location":"users/quickstart/#wp-cli","text":"DDEV has built-in support for WP-CLI , the command-line interface for WordPress. mkdir my-wp-site cd my-wp-site/ # create a new DDEV project inside the newly created folder # (the primary URL is automatically set to https://<folder>.ddev.site) ddev config --project-type = wordpress ddev start # download latest WordPress (via WP-CLI) ddev wp core download # finish the installation in your browser: ddev launch # optional: you can use the following installation command # (we need to use single quotes to get the primary site URL from .ddev/config.yaml as variable) ddev wp core install --url = '$DDEV_PRIMARY_URL' --title = 'New-WordPress' --admin_user = admin --admin_email = admin@example.com --prompt = admin_password # open WordPress admin dashboard in your browser: ddev launch wp-admin/","title":"wp-cli"},{"location":"users/quickstart/#rootsbedrock","text":"roots/bedrock is a modern composer-based installation if WordPress: mkdir my-wp-bedrock-site cd my-wp-bedrock-site ddev config --project-type = wordpress --docroot = web --create-docroot ddev start ddev composer create roots/bedrock Now, since Bedrock uses a configuration technique which is unusual for WordPress, edit the .env file which has been created in the project root, and set: DB_NAME=db DB_USER=db DB_PASSWORD=db DB_HOST=db WP_HOME=${DDEV_PRIMARY_URL} WP_SITEURL=${WP_HOME}/wp WP_ENV=development You can then ddev start and ddev launch . For more details see Bedrock installation .","title":"roots/bedrock"},{"location":"users/quickstart/#git-clone","text":"To get started using DDEV with an existing WordPress project, clone the project's repository. Note that the git URL shown here is just an example. git clone https://github.com/example/example-site.git cd example-site ddev config You'll see a message like: An existing user-managed wp-config.php file has been detected! Project ddev settings have been written to: /Users/rfay/workspace/bedrock/web/wp-config-ddev.php Please comment out any database connection settings in your wp-config.php and add the following snippet to your wp-config.php, near the bottom of the file and before the include of wp-settings.php: // Include for ddev-managed settings in wp-config-ddev.php. $ddev_settings = dirname(__FILE__) . '/wp-config-ddev.php'; if (is_readable($ddev_settings) && !defined('DB_USER')) { require_once($ddev_settings); } If you don't care about those settings, or config is managed in a .env file, etc, then you can eliminate this message by putting a line that says // wp-config-ddev.php not needed in your wp-config.php So just add the suggested include into your wp-config.php, or take the workaround shown. Now start your project with ddev start Quickstart instructions regarding database imports can be found under Importing a database .","title":"git clone"},{"location":"users/quickstart/#drupal","text":"Drupal 9 Composer TYPO3","title":"Drupal"},{"location":"users/quickstart/#drupal-9-composer-build","text":"mkdir my-drupal9-site cd my-drupal9-site ddev config --project-type = drupal9 --docroot = web --create-docroot ddev start ddev composer create \"drupal/recommended-project\" --no-install ddev composer require drush/drush --no-install ddev composer install ddev drush site:install -y ddev drush uli ddev launch Drupal 10","title":"Drupal 9 composer build"},{"location":"users/quickstart/#drupal-10-composer-build","text":"Drupal 10 is not yet released, but lots of people want to test and contribute to it. It's easy to set it up in DDEV: mkdir my-drupal10-site cd my-drupal10-site ddev config --project-type = drupal10 --docroot = web --create-docroot ddev start ddev composer create --no-install drupal/recommended-project:^10@alpha ddev composer require drush/drush --no-install ddev composer install ddev drush site:install -y ddev drush uli ddev launch Note that as Drupal 10 moves from alpha to beta and then release, you'll want to change the tag from ^10@alpha to ^10@beta and then ^10 . Drupal 6/7","title":"Drupal 10 composer build"},{"location":"users/quickstart/#drupal-67-install","text":"Using DDEV with a Drupal 6 or 7 project is as simple as cloning the project's repository and checking out its directory. git clone https://github.com/user/my-drupal-site cd my-drupal-site ddev config # Follow the prompts to select type and docroot ddev start ddev launch /install.php (Drupal 7 doesn't know how to redirect from the front page to the /install.php if the database is not set up but the settings files are set up, so launching with /install.php gets you started with an installation. You can also drush site-install , ddev exec drush site-install --yes ) Quickstart instructions for database imports can be found under Importing a database . Git clone","title":"Drupal 6/7 install"},{"location":"users/quickstart/#git-clone-build","text":"Note that the git URL shown below is an example only, you'll need to use your own project. git clone https://github.com/example/example-site cd example-site ddev config # Follow the prompts to set drupal version and docroot ddev composer install # If a composer build ddev launch","title":"Git clone build"},{"location":"users/quickstart/#typo3","text":"Composer build Git clone","title":"TYPO3"},{"location":"users/quickstart/#typo3-composer-build","text":"mkdir my-typo3-site cd my-typo3-site ddev config --project-type = typo3 --docroot = public --create-docroot ddev start ddev composer create \"typo3/cms-base-distribution\" --no-install ddev composer install ddev exec touch public/FIRST_INSTALL ddev launch","title":"TYPO3 composer build"},{"location":"users/quickstart/#typo3-git-clone","text":"git clone https://github.com/example/example-site cd example-site ddev config ddev composer install ddev launch","title":"TYPO3 git clone"},{"location":"users/quickstart/#openmagemagento-1","text":"Download OpenMage from release page . Make a directory for it, for example mkdir ~/workspace/OpenMage and change to the new directory cd ~/workspace/OpenMage . ddev config and accept the defaults. (Install sample data - see below) Run ddev start Follow the URL to the base site. You may want the Magento 1 Sample Data for experimentation: Download Magento 1.9.1.0 Sample Data . Extract the download, for example tar -zxf ~/Downloads/compressed-magento-sample-data-1.9.1.0.tgz --strip-components=1 Import the example database \"magento_sample_data_for_1.9.1.0.sql\" with ddev import-db --src=magento_sample_data_for_1.9.1.0.sql to database before running OpenMage install. Note that OpenMage is a huge codebase and using mutagen_enabled: true is recommended for performance on macOS and traditional Windows, see docs .","title":"OpenMage/Magento 1"},{"location":"users/quickstart/#magento-2","text":"Normal details of a composer build for Magento 2 are on Magento 2 site You must have a public and private key to install from Magento's repository; when prompted for \"username\" and \"password\" in the composer create it's asking for your public and private keys. mkdir ddev-magento2 && cd ddev-magento2 ddev config --project-type = magento2 --php-version = 8 .1 --docroot = pub --create-docroot --disable-settings-management ddev get drud/ddev-elasticsearch ddev start ddev composer create --no-install --repository = https://repo.magento.com/ magento/project-community-edition -y ddev composer install rm -f app/etc/env.php # Change the base-url below to your project's URL ddev magento setup:install --base-url = 'https://ddev-magento2.ddev.site/' --cleanup-database --db-host = db --db-name = db --db-user = db --db-password = db --elasticsearch-host = elasticsearch --admin-firstname = Magento --admin-lastname = User --admin-email = user@example.com --admin-user = admin --admin-password = admin123 --language = en_US ddev magento deploy:mode:set developer ddev magento module:disable Magento_TwoFactorAuth ddev config --disable-settings-management = false Of course, change the admin name and related information is needed. You may want to add the Magento 2 Sample Data with ddev magento sampledata:deploy && ddev magento setup:upgrade . Note that Magento 2 is a huge codebase and using mutagen_enabled: true is recommended for performance on macOS and traditional Windows, see docs .","title":"Magento 2"},{"location":"users/quickstart/#laravel","text":"Get started with Laravel projects on ddev either using a new or existing composer project or by cloning a git repository. The Laravel project type can be used for Lumen just as it can for Laravel. mkdir my-laravel-app cd my-laravel-app ddev config --project-type = laravel --docroot = public --create-docroot ddev start ddev composer create --prefer-dist laravel/laravel ddev exec \"cat .env.example | sed -E 's/DB_(HOST|DATABASE|USERNAME|PASSWORD)=(.*)/DB_\\1=db/g' > .env\" ddev exec 'sed -i \"s#APP_URL=.*#APP_URL=${DDEV_PRIMARY_URL}#g\" .env' ddev exec \"php artisan key:generate\" ddev launch In the examples above we used a one liner to copy .env.example as env and set the DB_HOST , DB_DATABASE , DB_USERNAME and DB_PASSWORD environment variables to the value of db . These values are DDEV's default settings for the Database connection. Instead of setting each connection variable we can add a ddev to the connections array in config/database.php like this: <?php return [ ... 'connections' => [ ... 'ddev' => [ 'driver' => 'mysql' , 'host' => 'db' , 'port' => 3306 , 'database' => 'db' , 'username' => 'db' , 'password' => 'db' , 'unix_socket' => '' , 'charset' => 'utf8mb4' , 'collation' => 'utf8mb4_unicode_ci' , 'prefix' => '' , 'strict' => true , 'engine' => null , ], ], ... ]; This way we only need to change the value of DB_CONNECTION to ddev in the .env to work with the db service. This is very handy if you have a local database installed and you want to switch between the connections faster by changing only one variable in .env","title":"Laravel"},{"location":"users/quickstart/#shopware-6","text":"You can set up a Shopware 6 environment many ways, but this shows you one recommended technique: git clone --branch = 6 .4 https://github.com/shopware/production my-shopware6 cd my-shopware6 ddev config --project-type = shopware6 --docroot = public ddev start ddev composer install ddev exec bin/console system:setup --database-url = mysql://db:db@db:3306/db --app-url = '${DDEV_PRIMARY_URL}' ddev exec bin/console system:install --create-database --basic-setup ddev launch /admin Now log into the admin site (/admin) using the web browser. The default credentials are username=admin, password=shopware. You can use the web UI to install sample data or accomplish many other tasks. For more advanced tasks like adding elasticsearch, building and watching storefront and administration, see susi.dev .","title":"Shopware 6"},{"location":"users/quickstart/#backdrop","text":"To get started with Backdrop, clone the project repository and navigate to the project directory. git clone https://github.com/example/example-site cd example-site ddev config ddev start ddev launch","title":"Backdrop"},{"location":"users/quickstart/#configuration-files","text":"Note: If you're providing the settings.php or wp-config.php and DDEV is creating the settings.ddev.php (or wp-config-local.php , AdditionalConfig.php , or similar), the main settings file must explicitly include the appropriate DDEV-generated settings file. Any changes you need should be included somewhere that loads after DDEV's settings file, for example in Drupal's settings.php after settings.ddev.php is included. (see Adding Configuration below). Turning off settings management completely If you do not want DDEV-Local to create or manage settings files, set disable_settings_management: true in your .ddev/config.yaml or ddev config --disable-settings-management and you will be the only one that edits or updates settings files. The ddev config command attempts to create a CMS-specific settings file with DDEV credentials pre-populated. For Drupal and Backdrop , DDEV settings are written to a DDEV-managed file, settings.ddev.php. The ddev config command will ensure that these settings are included in your settings.php through the following steps: Write DDEV settings to settings.ddev.php If no settings.php file exists, create one that includes settings.ddev.php If a settings.php file already exists, ensure that it includes settings.ddev.php , modifying settings.php to write the include if necessary. For Magento 1 , DDEV settings go into app/etc/local.xml In Magento 2 , DDEV settings go into app/etc/env.php For TYPO3 , DDEV settings are written to AdditionalConfiguration.php . If AdditionalConfiguration.php exists and is not managed by DDEV, it will not be modified. For WordPress , DDEV settings are written to a DDEV-managed file, wp-config-ddev.php . The ddev config command will attempt to write settings through the following steps: Write DDEV settings to wp-config-ddev.php If no wp-config.php exists, create one that include wp-config-ddev.php If a DDEV-managed wp-config.php exists, create one that includes wp-config.php If a user-managed wp-config.php exists, instruct the user on how to modify it to include DDEV settings How do you know if DDEV manages a settings file? You will see the following comment. Remove the comment and DDEV will not attempt to overwrite it! If you are letting DDEV create its settings file, it is recommended that you leave this comment so DDEV can continue to manage it, and make any needed changes in another settings file. /** #ddev-generated: Automatically generated Drupal settings.php file. ddev manages this file and may delete or overwrite the file unless this comment is removed. */","title":"Configuration files"},{"location":"users/quickstart/#adding-configuration","text":"Drupal and Backdrop : In settings.php , enable loading settings.local.php after settings.ddev.php is included (create a new one if it doesn't already exist), and make changes there (wrapping with if (getenv('IS_DDEV_PROJECT') == 'true') as needed). WordPress : Load a wp-config-local.php after wp-config-ddev.php , and make changes there (wrapping with if (getenv('IS_DDEV_PROJECT') == 'true') as needed).","title":"Adding configuration"},{"location":"users/quickstart/#listing-project-information","text":"ddev list or ddev list --active-only current projects. \u279c ddev list NAME TYPE LOCATION URL(s) STATUS d8git drupal8 ~/workspace/d8git <https://d8git.ddev.local> running <http://d8git.ddev.local> hobobiker drupal6 ~/workspace/hobobiker.com stopped \u279c ddev list --active-only NAME TYPE LOCATION URL(s) STATUS drupal8 drupal8 ~/workspace/drupal8 <http://drupal8.ddev.site> running <https://drupal8.ddev.site> You can also see more detailed information about a project by running ddev describe from its working directory. You can also run ddev describe [project-name] from any location to see the detailed information for a running project. NAME TYPE LOCATION URL STATUS d9composer drupal8 ~/workspace/d9composer https://d9composer.ddev.site running Project Information ------------------- PHP version: 7.4 MariaDB version 10.3 URLs ---- https://d9composer.ddev.site https://127.0.0.1:33232 http://d9composer.ddev.site http://127.0.0.1:33233 MySQL/MariaDB Credentials ------------------------- Username: \"db\", Password: \"db\", Default database: \"db\" or use root credentials when needed: Username: \"root\", Password: \"root\" Database hostname and port INSIDE container: ddev-d9-db:3306 To connect to db server inside container or in project settings files: mysql --host=ddev-d9-dbcomposer --user=db --password=db --database=db Database hostname and port from HOST: 127.0.0.1:33231 To connect to mysql from your host machine, mysql --host=127.0.0.1 --port=33231 --user=db --password=db --database=db Other Services -------------- MailHog (https): https://d9composer.ddev.site:8026 MailHog: http://d9composer.ddev.site:8025 phpMyAdmin (https): https://d9composer.ddev.site:8037 phpMyAdmin: http://d9composer.ddev.site:8036 DDEV ROUTER STATUS: healthy ssh-auth status: healthy","title":"Listing project information"},{"location":"users/quickstart/#removing-projects-from-ddev-local","text":"To remove a project from DDEV-Local's listing you can use the destructive option (deletes database, removes item from ddev's list, removes hostname entry in hosts file): ddev delete <projectname> or ddev delete --omit-snapshot <projectname> Or if you just don't want it to show up in ddev list any more, use ddev stop --unlist <projectname> to unlist it until the next time you ddev start or ddev config the project.","title":"Removing projects from DDEV-Local"},{"location":"users/quickstart/#importing-assets-for-an-existing-project","text":"An important aspect of local web development is the ability to have a precise recreation of the project you are working on locally, including up-to-date database contents and static assets such as uploaded images and files. ddev provides functionality to help with importing assets to your local environment with two commands.","title":"Importing assets for an existing project"},{"location":"users/quickstart/#importing-a-database","text":"The ddev import-db command is provided for importing the database for a project. Running this command will provide a prompt for you to specify the location of your database import. By default ddev import-db empties the default \"db\" database and then loads the provided dumpfile. Most people use it with command flags, like ddev import-db --src=.tarballs/db.sql.gz but it can also prompt for the location of the dumpfile if you just use ddev import-db : ddev import-db Provide the path to the database you wish to import. Import path: ~/Downloads/db.sql Importing database... Successfully imported database for drupal8","title":"Importing a database"},{"location":"users/quickstart/#supported-file-types","text":"Database import supports the following file types: Raw SQL Dump (.sql) Gzipped SQL Dump (.sql.gz) (Gzipped) Tarball Archive (.tar, .tar.gz, .tgz) Zip Archive (.zip) stdin If a Tarball Archive or Zip Archive is provided for the import, you will be provided an additional prompt, allowing you to specify a path within the archive to use for the import asset. The specified path should provide a Raw SQL Dump (.sql). In the following example, the database we want to import is named data.sql and resides at the top-level of the archive: ddev import-db Provide the path to the database you wish to import. Import path: ~/Downloads/site-backup.tar.gz You provided an archive. Do you want to extract from a specific path in your archive? You may leave this blank if you wish to use the full archive contents Archive extraction path: data.sql Importing database... A settings file already exists for your application, so ddev did not generate one. Run 'ddev describe' to find the database credentials for this application. Successfully imported database for drupal8","title":"Supported file types"},{"location":"users/quickstart/#non-interactive-usage","text":"If you want to use import-db without answering prompts, you can use the --src flag to provide the path to the import asset. If you are importing an archive, and wish to specify the path within the archive to extract, you can use the --extract-path flag in conjunction with the --src flag. Examples: ddev import-db --src = /tmp/mydb.sql.gz gzip -dc /tmp/mydb.sql.gz | ddev import-db ddev import-db <mydb.sql","title":"Non-interactive usage"},{"location":"users/quickstart/#database-import-notes","text":"Importing from a dumpfile via stdin will not show progress because there's no way the import can know how far along through the import it has progressed. Use ddev import-db --target-db <some_database> to import to a non-default database (other than the default \"db\" database). This will create the database if it doesn't exist already. Use ddev import-db --no-drop to import without first emptying the database. If a database already exists and the import does not specify dropping tables, the contents of the imported dumpfile will be added to the database. Most full database dumps do a table drop and create before loading, but if yours does not, you can drop all tables with ddev stop --remove-data before importing.","title":"Database import notes"},{"location":"users/support/","text":"Support \u00b6 We love to hear from you and want you to be successful with DDEV! See the built-in help: ddev help and ddev help <command> . You'll find plenty of examples. FAQ Discord interactive community support. DDEV issue queue for bugs and feature requests Twitter with tag #ddev will get to us, but it's not as good for interactive support, but we'll answer anywhere. Additional docs sources on the Internet \u00b6 DDEV Stack Overflow for support and frequently asked questions. We respond quite quickly here and the results provide quite a library of user-curated solutions. ddev-contrib repo provides a number of vetted user-contributed recipes for extending and using DDEV. Your contributions are welcome. awesome-ddev repo has loads of external resources, blog posts, recipes, screencasts, and the like. Your contributions are welcome.","title":"Support"},{"location":"users/support/#support","text":"We love to hear from you and want you to be successful with DDEV! See the built-in help: ddev help and ddev help <command> . You'll find plenty of examples. FAQ Discord interactive community support. DDEV issue queue for bugs and feature requests Twitter with tag #ddev will get to us, but it's not as good for interactive support, but we'll answer anywhere.","title":"Support"},{"location":"users/support/#additional-docs-sources-on-the-internet","text":"DDEV Stack Overflow for support and frequently asked questions. We respond quite quickly here and the results provide quite a library of user-curated solutions. ddev-contrib repo provides a number of vetted user-contributed recipes for extending and using DDEV. Your contributions are welcome. awesome-ddev repo has loads of external resources, blog posts, recipes, screencasts, and the like. Your contributions are welcome.","title":"Additional docs sources on the Internet"},{"location":"users/basics/","text":"Basics \u00b6 Learn How DDEV works Using the ddev command Database Management Troubleshooting Frequently-Asked Questions Built-in Developer Tools Uninstalling DDEV","title":"Basics"},{"location":"users/basics/#basics","text":"Learn How DDEV works Using the ddev command Database Management Troubleshooting Frequently-Asked Questions Built-in Developer Tools Uninstalling DDEV","title":"Basics"},{"location":"users/basics/cli-usage/","text":"Using the ddev command \u00b6 Type ddev or ddev -h in a terminal window to see the available ddev commands. There are commands to configure a project, start, stop, describe, etc. Each command also has help using ddev help <command> or ddev command -h . For example, ddev help snapshot will show help and examples for the snapshot command. ddev config configures a project's type and docroot. ddev start starts up a project. ddev launch opens a web browser showing the project. ddev list shows current projects and their state. ddev describe gives all the info about the current project. ddev ssh takes you into the web container. ddev exec <command> lets you execute any command inside the web container. ddev stop stops a project and removes its memory usage (but does not throw away any data). ddev poweroff stops all resources that DDEV is using. ddev delete will destroy the database and DDEV's knowledge of the project, but does nothing to your code. Lots of other commands \u00b6 ddev mysql gives direct access to the mysql client and ddev psql to the PostgreSQL psql client. ddev sequelpro , ddev sequelace , and ddev tableplus (macOS only, if the app is installed) give access to the Sequel Pro, Sequel Ace, or TablePlus database browser GUIs. ddev heidisql (Windows/WSL2 only, if installed) gives access to the HeidiSQL database browser GUI. ddev import-db and ddev export-db let you import or export a sql or compressed sql file. ddev composer lets you run composer (inside the container), for example ddev composer install will do a full composer install for you without even needing composer on your computer. See developer tools . ddev snapshot makes a very fast snapshot of your database that can be easily and quickly restored with ddev snapshot restore . ddev share requires ngrok and at least a free account on ngrok.com so you can let someone in the next office or on the other side of the planet see your project and what you're working on. ddev share -h gives more info about how to set up ngrok. ddev xdebug enables xdebug, ddev xdebug off disables it, ddev xdebug status shows status ddev xhprof enables xhprof, ddev xhprof off disables it, ddev xhprof status shows status ddev drush (Drupal and Backdrop only) gives direct access to the drush CLI ddev artisan (Laravel only) gives direct access to the Laravel artisan CLI ddev magento (Magento2 only) gives access to the magento CLI ddev yarn and ddev npm give direct access to the yarn/npm CLIs Node.js, npm, nvm, and yarn \u00b6 nodejs , npm , nvm and yarn are preinstalled in the web container. You can configure the default value of the installed nodejs version with the nodejs_version option in .ddev/config.yaml or with ddev config --nodejs_version . You can also override that with any value using the built-in nvm in the web container or with ddev nvm , for example ddev nvm install 6 . There is also a ddev yarn command. More bundled tools \u00b6 In addition to the commands listed above, there are loads and loads of tools included inside the containers: ddev describe tells how to access MailHog , which captures email in your development environment. ddev describe tells how to use the built-in phpMyAdmin and ddev launch -p gives direct access to it. Composer, git, node, npm, nvm, and dozens of other tools are installed in the web container, and you can access them via ddev ssh or ddev exec . ddev logs gets you webserver logs; ddev logs -s db gets dbserver logs. sqlite3 and the mysql and psql clients are inside the web container (and mysql or psql client is also in the db container). Exporting a Database \u00b6 You can export a database with ddev export-db , which outputs to stdout or with options to a file: ddev export-db --file = /tmp/db.sql.gz ddev export-db --gzip = false --file = /tmp/db.sql ddev export-db >/tmp/db.sql.gz ddev import-files \u00b6 To import static file assets for a project, such as uploaded images and documents, use the command ddev import-files . This command will prompt you to specify the location of your import asset, then import the assets into the project's upload directory. To define a custom upload directory, set the upload_dir key in your project's config.yaml . If no custom upload directory is defined, the default will be used: For Drupal projects, this is the sites/default/files directory. For WordPress projects, this is the wp-content/uploads directory. For TYPO3 projects, this is the fileadmin directory. For Backdrop projects, this is the files . For Magento 1 projects, this is the media directory. For Magento 2 projects, this is the pub/media directory. ddev import-files Provide the path to the directory or archive you wish to import. Please note, if the destination directory exists, it will be replaced with the import assets specified here. Import path: ~/Downloads/files.tar.gz Successfully imported files for drupal8 ddev import-files supports the following file types: .tar , .tar.gz , .tar.xz , .tar.bz2 , .tgz , or .zip . It can also import directory containing static assets. If you want to use import-files without answering prompts, you can use the --src flag to provide the path to the import asset. If you are importing an archive, and wish to specify the path within the archive to extract, you can use the --extract-path flag in conjunction with the --src flag. Example: ddev import-files --src=/tmp/files.tgz See ddev help import-files for more examples. Snapshotting and restoring a database \u00b6 The project database is stored in a docker volume, but can be snapshotted (and later restored) with the ddev snapshot command. A snapshot is automatically taken when you do a ddev stop --remove-data . For example: ddev snapshot Creating database snapshot d9_20220107124831-mariadb_10.3.gz Created database snapshot d9_20220107124831-mariadb_10.3.gz ddev snapshot restore d9_20220107124831-mariadb_10.3.gz Stopping db container for snapshot restore of 'd9_20220107124831-mariadb_10.3.gz' ... Restored database snapshot d9_20220107124831-mariadb_10.3.gz Snapshots are stored as gzipped files in the project's .ddev/db_snapshots directory, and the file created for a snapshot can be renamed as necessary. For example, if you rename the above d9_20220107124831-mariadb_10.3.gz file to \"working-before-migration-mariadb_10.3.gz\", then you can use ddev snapshot restore working-before-migration-mariadb_10.3.gz . (Note that the description of the database type and version ( mariadb_10.3 for example) must remain intact.) To restore the latest snapshot add the --latest flag ( ddev snapshot restore --latest ). All snapshots of a project can be removed with ddev snapshot --cleanup . A single snapshot can be removed by ddev snapshot --cleanup --name <snapshot-name> . To see all existing snapshots of a project use ddev snapshot --list . All existing snapshots of all projects can be listed by adding the --all option to the command ( ddev snapshot --list --all ). Note that with very large snapshots or perhaps with slower systems, the default timeout to wait for the snapshot restore to complete may not be adequate. In these cases you can increase the timeout by setting default_container_timeout to a higher value. Also, if it does time out on you, that doesn't mean it has actually failed. You can watch the snapshot restore complete with ddev logs -s db . Interacting with your project \u00b6 DDEV provides several commands to facilitate interacting with your project in the development environment. These commands can be run within the working directory of your project while the project is running in ddev. Executing Commands in Containers \u00b6 The ddev exec command allows you to run shell commands in the container for a ddev service. By default, commands are executed on the web service container, in the docroot path of your project. This allows you to use the developer tools included in the web container . For example, to run the \"ls\" in the web container, you would run ddev exec ls or ddev . ls . To run a shell command in the container for a different service, use the --service (or -s ) flag at the beginning of your exec command to specify the service the command should be run against. For example, to run the mysql client in the database, container, you would run ddev exec --service db mysql . To specify the directory in which a shell command will be run, use the --dir flag. For example, to see the contents of the /usr/bin directory, you would run ddev exec --dir /usr/bin ls . To run privileged commands, sudo can be passed into ddev exec . For example, to update the container's apt package lists, use ddev exec sudo apt-get update . Commands can also be executed using the shorter ddev . <cmd> alias. Normally, ddev exec commands are executed in the container using bash, which means that environment variables and redirection and pipes can be used. For example, a complex command like ddev exec 'ls -l ${DDEV_FILES_DIR} | grep x >/tmp/junk.out' will be interpreted by bash and will work. However, there are cases where bash introduces too much complexity and it's best to just run the command directly. In those cases, something like ddev exec --raw ls -l \"dir1\" \"dir2\" may be useful. with --raw the ls command is executed directly instead of the full command being interpreted by bash. But you cannot use environment variables, pipes, redirection, etc. SSH Into Containers \u00b6 The ddev ssh command will open an interactive bash or sh shell session to the container for a ddev service. The web service is connected to by default. The session can be ended by typing exit . To connect to another service, use the --service flag to specify the service you want to connect to. For example, to connect to the database container, you would run ddev ssh --service db . To specify the destination directory, use the --dir flag. For example, to connect to the database container and be placed into the /home directory, you would run ddev ssh --service db --dir /home . If you want to use your personal ssh keys within the web container, that's possible. Use ddev auth ssh to add the keys from your ~/.ssh directory and provide a passphrase, and then those keys will be usable from within the web container. You generally only have to ddev auth ssh one time per computer reboot. This is a very popular approach for accessing private composer repositories, or for using drush aliases against remote servers. ddev logs \u00b6 The ddev logs command allows you to easily view error logs from the web container (both nginx/apache and php-fpm logs are concatenated). To follow the log (watch the lines in real time), run ddev logs -f . When you are done, press CTRL+C to exit from the log trail. Similarly, ddev logs -s db will show logs from a running or stopped db container. Stopping a project \u00b6 To remove a project's containers run ddev stop in the working directory of the project. To remove any running project's containers, providing the project name as an argument, e.g. ddev stop <projectname> . ddev stop is not destructive. It removes the docker containers but does not remove the database for the project, and does nothing to your codebase. This allows you to have many configured projects with databases loaded without wasting docker containers on unused projects. ddev stop does not affect the project code base and files. To remove the imported database for a project, use the flag --remove-data , as in ddev stop --remove-data . This command will destroy both the containers and the imported database contents.","title":"Using the `ddev` command"},{"location":"users/basics/cli-usage/#using-the-ddev-command","text":"Type ddev or ddev -h in a terminal window to see the available ddev commands. There are commands to configure a project, start, stop, describe, etc. Each command also has help using ddev help <command> or ddev command -h . For example, ddev help snapshot will show help and examples for the snapshot command. ddev config configures a project's type and docroot. ddev start starts up a project. ddev launch opens a web browser showing the project. ddev list shows current projects and their state. ddev describe gives all the info about the current project. ddev ssh takes you into the web container. ddev exec <command> lets you execute any command inside the web container. ddev stop stops a project and removes its memory usage (but does not throw away any data). ddev poweroff stops all resources that DDEV is using. ddev delete will destroy the database and DDEV's knowledge of the project, but does nothing to your code.","title":"Using the ddev command"},{"location":"users/basics/cli-usage/#lots-of-other-commands","text":"ddev mysql gives direct access to the mysql client and ddev psql to the PostgreSQL psql client. ddev sequelpro , ddev sequelace , and ddev tableplus (macOS only, if the app is installed) give access to the Sequel Pro, Sequel Ace, or TablePlus database browser GUIs. ddev heidisql (Windows/WSL2 only, if installed) gives access to the HeidiSQL database browser GUI. ddev import-db and ddev export-db let you import or export a sql or compressed sql file. ddev composer lets you run composer (inside the container), for example ddev composer install will do a full composer install for you without even needing composer on your computer. See developer tools . ddev snapshot makes a very fast snapshot of your database that can be easily and quickly restored with ddev snapshot restore . ddev share requires ngrok and at least a free account on ngrok.com so you can let someone in the next office or on the other side of the planet see your project and what you're working on. ddev share -h gives more info about how to set up ngrok. ddev xdebug enables xdebug, ddev xdebug off disables it, ddev xdebug status shows status ddev xhprof enables xhprof, ddev xhprof off disables it, ddev xhprof status shows status ddev drush (Drupal and Backdrop only) gives direct access to the drush CLI ddev artisan (Laravel only) gives direct access to the Laravel artisan CLI ddev magento (Magento2 only) gives access to the magento CLI ddev yarn and ddev npm give direct access to the yarn/npm CLIs","title":"Lots of other commands"},{"location":"users/basics/cli-usage/#nodejs-npm-nvm-and-yarn","text":"nodejs , npm , nvm and yarn are preinstalled in the web container. You can configure the default value of the installed nodejs version with the nodejs_version option in .ddev/config.yaml or with ddev config --nodejs_version . You can also override that with any value using the built-in nvm in the web container or with ddev nvm , for example ddev nvm install 6 . There is also a ddev yarn command.","title":"Node.js, npm, nvm, and yarn"},{"location":"users/basics/cli-usage/#more-bundled-tools","text":"In addition to the commands listed above, there are loads and loads of tools included inside the containers: ddev describe tells how to access MailHog , which captures email in your development environment. ddev describe tells how to use the built-in phpMyAdmin and ddev launch -p gives direct access to it. Composer, git, node, npm, nvm, and dozens of other tools are installed in the web container, and you can access them via ddev ssh or ddev exec . ddev logs gets you webserver logs; ddev logs -s db gets dbserver logs. sqlite3 and the mysql and psql clients are inside the web container (and mysql or psql client is also in the db container).","title":"More bundled tools"},{"location":"users/basics/cli-usage/#exporting-a-database","text":"You can export a database with ddev export-db , which outputs to stdout or with options to a file: ddev export-db --file = /tmp/db.sql.gz ddev export-db --gzip = false --file = /tmp/db.sql ddev export-db >/tmp/db.sql.gz","title":"Exporting a Database"},{"location":"users/basics/cli-usage/#ddev-import-files","text":"To import static file assets for a project, such as uploaded images and documents, use the command ddev import-files . This command will prompt you to specify the location of your import asset, then import the assets into the project's upload directory. To define a custom upload directory, set the upload_dir key in your project's config.yaml . If no custom upload directory is defined, the default will be used: For Drupal projects, this is the sites/default/files directory. For WordPress projects, this is the wp-content/uploads directory. For TYPO3 projects, this is the fileadmin directory. For Backdrop projects, this is the files . For Magento 1 projects, this is the media directory. For Magento 2 projects, this is the pub/media directory. ddev import-files Provide the path to the directory or archive you wish to import. Please note, if the destination directory exists, it will be replaced with the import assets specified here. Import path: ~/Downloads/files.tar.gz Successfully imported files for drupal8 ddev import-files supports the following file types: .tar , .tar.gz , .tar.xz , .tar.bz2 , .tgz , or .zip . It can also import directory containing static assets. If you want to use import-files without answering prompts, you can use the --src flag to provide the path to the import asset. If you are importing an archive, and wish to specify the path within the archive to extract, you can use the --extract-path flag in conjunction with the --src flag. Example: ddev import-files --src=/tmp/files.tgz See ddev help import-files for more examples.","title":"ddev import-files"},{"location":"users/basics/cli-usage/#snapshotting-and-restoring-a-database","text":"The project database is stored in a docker volume, but can be snapshotted (and later restored) with the ddev snapshot command. A snapshot is automatically taken when you do a ddev stop --remove-data . For example: ddev snapshot Creating database snapshot d9_20220107124831-mariadb_10.3.gz Created database snapshot d9_20220107124831-mariadb_10.3.gz ddev snapshot restore d9_20220107124831-mariadb_10.3.gz Stopping db container for snapshot restore of 'd9_20220107124831-mariadb_10.3.gz' ... Restored database snapshot d9_20220107124831-mariadb_10.3.gz Snapshots are stored as gzipped files in the project's .ddev/db_snapshots directory, and the file created for a snapshot can be renamed as necessary. For example, if you rename the above d9_20220107124831-mariadb_10.3.gz file to \"working-before-migration-mariadb_10.3.gz\", then you can use ddev snapshot restore working-before-migration-mariadb_10.3.gz . (Note that the description of the database type and version ( mariadb_10.3 for example) must remain intact.) To restore the latest snapshot add the --latest flag ( ddev snapshot restore --latest ). All snapshots of a project can be removed with ddev snapshot --cleanup . A single snapshot can be removed by ddev snapshot --cleanup --name <snapshot-name> . To see all existing snapshots of a project use ddev snapshot --list . All existing snapshots of all projects can be listed by adding the --all option to the command ( ddev snapshot --list --all ). Note that with very large snapshots or perhaps with slower systems, the default timeout to wait for the snapshot restore to complete may not be adequate. In these cases you can increase the timeout by setting default_container_timeout to a higher value. Also, if it does time out on you, that doesn't mean it has actually failed. You can watch the snapshot restore complete with ddev logs -s db .","title":"Snapshotting and restoring a database"},{"location":"users/basics/cli-usage/#interacting-with-your-project","text":"DDEV provides several commands to facilitate interacting with your project in the development environment. These commands can be run within the working directory of your project while the project is running in ddev.","title":"Interacting with your project"},{"location":"users/basics/cli-usage/#executing-commands-in-containers","text":"The ddev exec command allows you to run shell commands in the container for a ddev service. By default, commands are executed on the web service container, in the docroot path of your project. This allows you to use the developer tools included in the web container . For example, to run the \"ls\" in the web container, you would run ddev exec ls or ddev . ls . To run a shell command in the container for a different service, use the --service (or -s ) flag at the beginning of your exec command to specify the service the command should be run against. For example, to run the mysql client in the database, container, you would run ddev exec --service db mysql . To specify the directory in which a shell command will be run, use the --dir flag. For example, to see the contents of the /usr/bin directory, you would run ddev exec --dir /usr/bin ls . To run privileged commands, sudo can be passed into ddev exec . For example, to update the container's apt package lists, use ddev exec sudo apt-get update . Commands can also be executed using the shorter ddev . <cmd> alias. Normally, ddev exec commands are executed in the container using bash, which means that environment variables and redirection and pipes can be used. For example, a complex command like ddev exec 'ls -l ${DDEV_FILES_DIR} | grep x >/tmp/junk.out' will be interpreted by bash and will work. However, there are cases where bash introduces too much complexity and it's best to just run the command directly. In those cases, something like ddev exec --raw ls -l \"dir1\" \"dir2\" may be useful. with --raw the ls command is executed directly instead of the full command being interpreted by bash. But you cannot use environment variables, pipes, redirection, etc.","title":"Executing Commands in Containers"},{"location":"users/basics/cli-usage/#ssh-into-containers","text":"The ddev ssh command will open an interactive bash or sh shell session to the container for a ddev service. The web service is connected to by default. The session can be ended by typing exit . To connect to another service, use the --service flag to specify the service you want to connect to. For example, to connect to the database container, you would run ddev ssh --service db . To specify the destination directory, use the --dir flag. For example, to connect to the database container and be placed into the /home directory, you would run ddev ssh --service db --dir /home . If you want to use your personal ssh keys within the web container, that's possible. Use ddev auth ssh to add the keys from your ~/.ssh directory and provide a passphrase, and then those keys will be usable from within the web container. You generally only have to ddev auth ssh one time per computer reboot. This is a very popular approach for accessing private composer repositories, or for using drush aliases against remote servers.","title":"SSH Into Containers"},{"location":"users/basics/cli-usage/#ddev-logs","text":"The ddev logs command allows you to easily view error logs from the web container (both nginx/apache and php-fpm logs are concatenated). To follow the log (watch the lines in real time), run ddev logs -f . When you are done, press CTRL+C to exit from the log trail. Similarly, ddev logs -s db will show logs from a running or stopped db container.","title":"ddev logs"},{"location":"users/basics/cli-usage/#stopping-a-project","text":"To remove a project's containers run ddev stop in the working directory of the project. To remove any running project's containers, providing the project name as an argument, e.g. ddev stop <projectname> . ddev stop is not destructive. It removes the docker containers but does not remove the database for the project, and does nothing to your codebase. This allows you to have many configured projects with databases loaded without wasting docker containers on unused projects. ddev stop does not affect the project code base and files. To remove the imported database for a project, use the flag --remove-data , as in ddev stop --remove-data . This command will destroy both the containers and the imported database contents.","title":"Stopping a project"},{"location":"users/basics/database_management/","text":"Database Management \u00b6 DDEV provides lots and lots of flexibility for you in managing your databases between your local development, staging and production environments. Most people know about ddev import-db and ddev export-db but those tools now have more flexibility and there are plenty of other adaptable ways to work with your databases. Remember, you can run ddev [command] --help for more info on many of the topics below. Database Imports \u00b6 Import a database with just one command; There is support for several file formats, including: .sql, sql.gz, mysql, mysql.gz, tar, tar.gz, and zip . Here's an example of a database import using ddev: ddev import-db --src = dumpfile.sql.gz You can also: Use ddev mysql or ddev psql or the mysql and psql commands inside the web and db containers. Use phpMyAdmin for database imports, but that approach is much slower. Discussion \u00b6 Many database backends : You can use a vast array of different database types, including MariaDB (5.5-10.7) and MySQL (5.5-8.0) Postgresql (9-14), see ( docs ). Note that if you want to change database type, you need to export your database and then ddev delete the project (to kill off the existing database), make the change to a new db type, start again, and import. Default database : DDEV creates a default database named db and default permissions for the db user with password db , and it's on the (inside Docker) hostname db . Extra databases : In DDEV you can easily create and populate other databases as well. For example, ddev import-db --target-db=backend --src=backend.sql.gz will create the database named backend with permissions for that same db user and import from the backend.sql.gz dumpfile . Exporting extra databases : You can export in the same way: ddev export-db -f mysite.sql.gz will export your default database ( db ). ddev export-db --target-db=backend -f backend-export.sql.gz will dump the database named backend . Database snapshots : With snapshots you can easily save the entire status of all of your databases. It's great for when you're working incrementally on migrations or updates and want to save state so you can start right back where you were. I like to name my snapshots so I can find them later, so ddev snapshot --name=two-dbs would make a snapshot named two-dbs in the .ddev/db_snapshots directory. It includes the entire state of the db server, so in the case of our two databases above, both databases and the system level mysql or postgres database will all be snapshotted. Then if you want to delete everything with ddev delete -O (omitting the snapshot since we have one already), and then ddev start again, we can ddev snapshot restore two-dbs and we'll be right back where we were. Don't forget about ddev snapshot restore --latest and that ddev snapshot restore will interactively let you choose among snapshots. ddev mysql and ddev psql : ddev mysql gives you direct access to the mysql client in the db container. I like to use it for lots of things because I like the command line. I might just ddev mysql and give an interactive command like DROP DATABASE backend; . Or SHOW TABLES; . You can also do things like echo \"SHOW TABLES;\" | ddev mysql or `ddev mysql -uroot -proot` to get root privileges. mysql/psql clients in containers : Both the web and db containers have the mysql/psql clients all set up and configured, so you can just ddev ssh or ddev ssh -s db and then use mysql or psql however you choose to. mysqldump : The web and db containers also have mysqldump so you can use it any way you want inside there. I like to ddev ssh (into the web container) and then mkdir /var/www/html/.tarballs and mysqldump db >/var/www/html/.tarballs/db.sql or mysqldump db | gzip >/var/www/html/.tarballs/db.sql.gz (Because /var/www/html is mounted into the container from your project root, the .tarballs folder will also show up in the root of the project on the host.) pgdump and related commands : The postgres db container has all the normal pg commands like pgdump . Other database explorers : There are lots of alternatives for GUI database explorers: macOS users love ddev sequelpro , which launches the free Sequelpro database browser. However, it's gotten little love in recent years, so ddev now supports TablePlus and SequelAce if they're installed. ddev tableplus and ddev sequelace . ddev describe tells you the URL for the built-in PHPMyAdmin database browser (Hint: It's http://<yourproject>.ddev.site:8036 ). PHPStorm (and all JetBrains tools) have a nice database browser: Choose a static host_db_port for your project. For example host_db_port: 59002 (each project's db port should be different if you're running more than one project at a time). ( ddev start to make it take effect) Use the \"database\" tool to create a source from \"localhost\", with the proper type \"mysql\" or \"postgresql\" and the port you chose, credentials username: db and password: db Explore away! There's a sample custom command that will run the free mysqlworkbench GUI database explorer on macOS, Windows or Linux. You just have to: cp ~.ddev/commands/host/mysqlworkbench.example ~.ddev/commands/host/mysqlworkbench and then ddev mysqlworkbench","title":"Database Management"},{"location":"users/basics/database_management/#database-management","text":"DDEV provides lots and lots of flexibility for you in managing your databases between your local development, staging and production environments. Most people know about ddev import-db and ddev export-db but those tools now have more flexibility and there are plenty of other adaptable ways to work with your databases. Remember, you can run ddev [command] --help for more info on many of the topics below.","title":"Database Management"},{"location":"users/basics/database_management/#database-imports","text":"Import a database with just one command; There is support for several file formats, including: .sql, sql.gz, mysql, mysql.gz, tar, tar.gz, and zip . Here's an example of a database import using ddev: ddev import-db --src = dumpfile.sql.gz You can also: Use ddev mysql or ddev psql or the mysql and psql commands inside the web and db containers. Use phpMyAdmin for database imports, but that approach is much slower.","title":"Database Imports"},{"location":"users/basics/database_management/#discussion","text":"Many database backends : You can use a vast array of different database types, including MariaDB (5.5-10.7) and MySQL (5.5-8.0) Postgresql (9-14), see ( docs ). Note that if you want to change database type, you need to export your database and then ddev delete the project (to kill off the existing database), make the change to a new db type, start again, and import. Default database : DDEV creates a default database named db and default permissions for the db user with password db , and it's on the (inside Docker) hostname db . Extra databases : In DDEV you can easily create and populate other databases as well. For example, ddev import-db --target-db=backend --src=backend.sql.gz will create the database named backend with permissions for that same db user and import from the backend.sql.gz dumpfile . Exporting extra databases : You can export in the same way: ddev export-db -f mysite.sql.gz will export your default database ( db ). ddev export-db --target-db=backend -f backend-export.sql.gz will dump the database named backend . Database snapshots : With snapshots you can easily save the entire status of all of your databases. It's great for when you're working incrementally on migrations or updates and want to save state so you can start right back where you were. I like to name my snapshots so I can find them later, so ddev snapshot --name=two-dbs would make a snapshot named two-dbs in the .ddev/db_snapshots directory. It includes the entire state of the db server, so in the case of our two databases above, both databases and the system level mysql or postgres database will all be snapshotted. Then if you want to delete everything with ddev delete -O (omitting the snapshot since we have one already), and then ddev start again, we can ddev snapshot restore two-dbs and we'll be right back where we were. Don't forget about ddev snapshot restore --latest and that ddev snapshot restore will interactively let you choose among snapshots. ddev mysql and ddev psql : ddev mysql gives you direct access to the mysql client in the db container. I like to use it for lots of things because I like the command line. I might just ddev mysql and give an interactive command like DROP DATABASE backend; . Or SHOW TABLES; . You can also do things like echo \"SHOW TABLES;\" | ddev mysql or `ddev mysql -uroot -proot` to get root privileges. mysql/psql clients in containers : Both the web and db containers have the mysql/psql clients all set up and configured, so you can just ddev ssh or ddev ssh -s db and then use mysql or psql however you choose to. mysqldump : The web and db containers also have mysqldump so you can use it any way you want inside there. I like to ddev ssh (into the web container) and then mkdir /var/www/html/.tarballs and mysqldump db >/var/www/html/.tarballs/db.sql or mysqldump db | gzip >/var/www/html/.tarballs/db.sql.gz (Because /var/www/html is mounted into the container from your project root, the .tarballs folder will also show up in the root of the project on the host.) pgdump and related commands : The postgres db container has all the normal pg commands like pgdump . Other database explorers : There are lots of alternatives for GUI database explorers: macOS users love ddev sequelpro , which launches the free Sequelpro database browser. However, it's gotten little love in recent years, so ddev now supports TablePlus and SequelAce if they're installed. ddev tableplus and ddev sequelace . ddev describe tells you the URL for the built-in PHPMyAdmin database browser (Hint: It's http://<yourproject>.ddev.site:8036 ). PHPStorm (and all JetBrains tools) have a nice database browser: Choose a static host_db_port for your project. For example host_db_port: 59002 (each project's db port should be different if you're running more than one project at a time). ( ddev start to make it take effect) Use the \"database\" tool to create a source from \"localhost\", with the proper type \"mysql\" or \"postgresql\" and the port you chose, credentials username: db and password: db Explore away! There's a sample custom command that will run the free mysqlworkbench GUI database explorer on macOS, Windows or Linux. You just have to: cp ~.ddev/commands/host/mysqlworkbench.example ~.ddev/commands/host/mysqlworkbench and then ddev mysqlworkbench","title":"Discussion"},{"location":"users/basics/developer-tools/","text":"Built-in Developer Tools \u00b6 Run ddev describe to see the project information and services available for your project and how to access them. Command-line Tools in the Containers \u00b6 Hundreds of useful developer tools are included inside the containers. Any of these tools can be used via ddev exec or ddev ssh . A short listing is: MySQL client ( mysql ) - Command-line interface for interacting with MySQL/MariaDB. Postgresql client ( psql ) - Command-line tool for Postgresql. Drush - Command-line shell and Unix scripting interface for Drupal. PHIVE - Command line tool for \"PHAR Installation and Verification Environment\" WP-CLI - Command-line tools for managing WordPress installations, available both as \"wp\" and as \"wp-cli\". npm and yarn (and the ddev yarn command will run yarn for you, ddev help yarn ) node sqlite3 These tools can be accessed for single commands using ddev exec <command> or ddev ssh for an interactive bash or sh session. You can also add tools that are not provided by default using webimage_extra_packages or a custom Dockerfile . DDEV and Composer \u00b6 ddev provides a built-in command to simplify use of Composer , the dependency manager for PHP, that allows a user to create and manage projects without having Composer installed on the host machine. Generally, executing any Composer command through DDEV is as simple as prepending the command with ddev . DDEV will execute the command at the project root in the web container, passing (almost) all arguments and flags to Composer. To execute Composer in other directories within the container, use ddev ssh or ddev exec -d <dir> . For example: ddev composer help ddev composer require <package> Additionally, Composer can be used to initialize new projects with ddev composer create . This command supports limited argument and flag options, and will install a new project to the project root in /var/www/html . The package and version arguments are required: ddev composer create [<flags>] \"<package>:<version>\" For example: ddev composer create --no-dev \"typo3/cms-base-distribution:^9\" To execute a fully-featured composer create-project command, you can execute the command from within the container after executing ddev ssh , or pass the full command to ddev exec , like so: ddev exec composer create-project ... DDEV-Local uses composer version 2 by default. If you want to roll back to version 1, ddev config --composer-version=1 && ddev start composer.json Location : The most common situation is for the composer.json to be in the project root, but if your composer.json is not in the project root, use the composer_root option in .ddev/config.yaml or ddev config --composer-root <dir> . The composer_root value is the relative path from the project root to the directory where the composer.json file is. So if the composer.json is docroot/composer.json , the composer_root value should be docroot . Note: if you run ddev composer global require , (or run composer global require inside the web container) the global packages will be installed in the in-container user's home directory ( ~/.composer) and will disappear on the next container restart, requiring rerun of the command. You may need an additional step of synchronizing created composer configuration and installed packages with the DDEV's homeadditions folder on the host. Windows OS and ddev composer \u00b6 Both composer and some configurations of Docker Desktop for Windows introduce quite complex filesystem workarounds. DDEV attempts to help you with each of them. You generally don't have to worry about any of this, but it does keep things cleaner. Mostly just a few of the more complex TYPO3 projects have been affected. On some older configurations of Docker Desktop for Windows, symlinks are created in the container as \"simulated symlinks\", or XSym files. These are special text files that behave as symlinks inside the container (on CIFS filesystem), but appear as simple text files on the Windows host. (on the CIFS filesystem used by Docker for Windows inside the container there is no capability to create real symlinks, even though Windows now has this capability.) DDEV-Local attempts to clean up for this situation. Since Windows 10/11+ (in developer mode) can create real symlinks, DDEV-Local scans your repository after a ddev composer command and attempts to convert XSym files into real symlinks. On older versions of Windows 10, it can only do this if your Windows 10 workstation is set to \"Developer Mode\". On Windows 10/11+, to set your computer to developer mode, search for \"developer\" in settings. Screenshots are below. Limitations with ddev composer \u00b6 Using ddev composer --version or ddev composer -V will not work, since ddev tries to utilize the command for itself. Use ddev composer -- --version instead. Email Capture and Review (MailHog) \u00b6 MailHog is a mail catcher which is configured to capture and display emails sent by PHP in the development environment. After your project is started, access the MailHog web interface at its default port like this: http://mysite.ddev.site:8025 or just use ddev launch -m to get to it. Please note this will not intercept emails if your application is configured to use SMTP or a 3 rd -party ESP integration. If you are using SMTP for outgoing mail handling ( Swift Mailer or SMTP modules for example), update your application configuration to use localhost on port 1025 as the SMTP server locally in order to use MailHog. For Laravel projects, Mailhog will capture Swift messages via SMTP. Update your .env to use Mailhog with the following settings: MAIL_MAILER=smtp MAIL_HOST=localhost MAIL_PORT=1025 MAIL_USERNAME=null MAIL_PASSWORD=null MAIL_ENCRYPTION=null Using Development Tools on the Host Machine \u00b6 It is possible in many cases to use development tools installed on your host machine on a project provisioned by ddev. Tools that interact with files and require no database connection, such as Git or Composer, can be run from the host machine against the code base for a ddev project with no additional configuration necessary. Database Connections from the Host \u00b6 If you need to connect to the database of your project from the host machine, run ddev describe to show the database connection information, like Host: localhost:49156 . The port referenced is unique per running project, and randomly chosen from available ports on your system when you run ddev start . You can force this port to be the same on every ddev start by setting host_db_port in the project .ddev/config.yaml. For example, host_db_port: \"49156\" or ddev config --host-db-port=49156 . This value needs to be different on each running DDEV project, and unless it is set, the database port will change on every ddev start . You can use this port with various tools that need a direct port, like mysql or psql clients, but it's usually easiest to use ddev mysql , ddev psql , ddev sequelace , ddev tableplus , etc, which set everything up for you. Using Drush 8 installed Installation on the Host Computer \u00b6 Warning: Using drush on the host is discouraged, and you'll have some trouble with it. It's also mostly irrelevant for Drupal8, as you should be using composer-installed project-level drush. If you have PHP and Drush installed on your host system and the environment variable IS_DDEV_PROJECT=true, you can use drush to interact with a ddev project. On the host system the extra include host-side configuration for the database and port are derived in the settings.ddev.php file to allow drush to access the database server. This may not work for all drush commands because of course the actual webserver environment is not available. Note that on Drupal 8+ if you want to use drush uli on the host (or other drush commands that require a default URI), you'll need to set DRUSH_OPTIONS_URI on the host. For example, export DRUSH_OPTIONS_URI=https://mysite.ddev.site . DDEV and Terminus \u00b6 Terminus is a command line tool providing advanced interaction with Pantheon services. As of version 1.13.0 , terminus is available inside the project's container, allowing users to get information from, or issue commands to their Pantheon-hosted sites. This is an especially helpful feature for Windows users as terminus is only officially supported on unix-based systems. To use terminus, you'll first need to: Use a machine token, more discussion in Pantheon provider discussion . Use ddev ssh to tunnel into your container Issue a command using the keyword terminus . For help using terminus try terminus list to get a list of possible commands. Terminus also allows you to issue drush , WP-CLI , and composer commands to your pantheon server. These are all usable from within the container as well, but will require authentication via either your Pantheon password or an SSH key. To use your host machine's SSH key, you can use the ddev auth ssh command described here .","title":"Built-in Developer Tools"},{"location":"users/basics/developer-tools/#built-in-developer-tools","text":"Run ddev describe to see the project information and services available for your project and how to access them.","title":"Built-in Developer Tools"},{"location":"users/basics/developer-tools/#command-line-tools-in-the-containers","text":"Hundreds of useful developer tools are included inside the containers. Any of these tools can be used via ddev exec or ddev ssh . A short listing is: MySQL client ( mysql ) - Command-line interface for interacting with MySQL/MariaDB. Postgresql client ( psql ) - Command-line tool for Postgresql. Drush - Command-line shell and Unix scripting interface for Drupal. PHIVE - Command line tool for \"PHAR Installation and Verification Environment\" WP-CLI - Command-line tools for managing WordPress installations, available both as \"wp\" and as \"wp-cli\". npm and yarn (and the ddev yarn command will run yarn for you, ddev help yarn ) node sqlite3 These tools can be accessed for single commands using ddev exec <command> or ddev ssh for an interactive bash or sh session. You can also add tools that are not provided by default using webimage_extra_packages or a custom Dockerfile .","title":"Command-line Tools in the Containers"},{"location":"users/basics/developer-tools/#ddev-and-composer","text":"ddev provides a built-in command to simplify use of Composer , the dependency manager for PHP, that allows a user to create and manage projects without having Composer installed on the host machine. Generally, executing any Composer command through DDEV is as simple as prepending the command with ddev . DDEV will execute the command at the project root in the web container, passing (almost) all arguments and flags to Composer. To execute Composer in other directories within the container, use ddev ssh or ddev exec -d <dir> . For example: ddev composer help ddev composer require <package> Additionally, Composer can be used to initialize new projects with ddev composer create . This command supports limited argument and flag options, and will install a new project to the project root in /var/www/html . The package and version arguments are required: ddev composer create [<flags>] \"<package>:<version>\" For example: ddev composer create --no-dev \"typo3/cms-base-distribution:^9\" To execute a fully-featured composer create-project command, you can execute the command from within the container after executing ddev ssh , or pass the full command to ddev exec , like so: ddev exec composer create-project ... DDEV-Local uses composer version 2 by default. If you want to roll back to version 1, ddev config --composer-version=1 && ddev start composer.json Location : The most common situation is for the composer.json to be in the project root, but if your composer.json is not in the project root, use the composer_root option in .ddev/config.yaml or ddev config --composer-root <dir> . The composer_root value is the relative path from the project root to the directory where the composer.json file is. So if the composer.json is docroot/composer.json , the composer_root value should be docroot . Note: if you run ddev composer global require , (or run composer global require inside the web container) the global packages will be installed in the in-container user's home directory ( ~/.composer) and will disappear on the next container restart, requiring rerun of the command. You may need an additional step of synchronizing created composer configuration and installed packages with the DDEV's homeadditions folder on the host.","title":"DDEV and Composer"},{"location":"users/basics/developer-tools/#windows-os-and-ddev-composer","text":"Both composer and some configurations of Docker Desktop for Windows introduce quite complex filesystem workarounds. DDEV attempts to help you with each of them. You generally don't have to worry about any of this, but it does keep things cleaner. Mostly just a few of the more complex TYPO3 projects have been affected. On some older configurations of Docker Desktop for Windows, symlinks are created in the container as \"simulated symlinks\", or XSym files. These are special text files that behave as symlinks inside the container (on CIFS filesystem), but appear as simple text files on the Windows host. (on the CIFS filesystem used by Docker for Windows inside the container there is no capability to create real symlinks, even though Windows now has this capability.) DDEV-Local attempts to clean up for this situation. Since Windows 10/11+ (in developer mode) can create real symlinks, DDEV-Local scans your repository after a ddev composer command and attempts to convert XSym files into real symlinks. On older versions of Windows 10, it can only do this if your Windows 10 workstation is set to \"Developer Mode\". On Windows 10/11+, to set your computer to developer mode, search for \"developer\" in settings. Screenshots are below.","title":"Windows OS and ddev composer"},{"location":"users/basics/developer-tools/#limitations-with-ddev-composer","text":"Using ddev composer --version or ddev composer -V will not work, since ddev tries to utilize the command for itself. Use ddev composer -- --version instead.","title":"Limitations with ddev composer"},{"location":"users/basics/developer-tools/#email-capture-and-review-mailhog","text":"MailHog is a mail catcher which is configured to capture and display emails sent by PHP in the development environment. After your project is started, access the MailHog web interface at its default port like this: http://mysite.ddev.site:8025 or just use ddev launch -m to get to it. Please note this will not intercept emails if your application is configured to use SMTP or a 3 rd -party ESP integration. If you are using SMTP for outgoing mail handling ( Swift Mailer or SMTP modules for example), update your application configuration to use localhost on port 1025 as the SMTP server locally in order to use MailHog. For Laravel projects, Mailhog will capture Swift messages via SMTP. Update your .env to use Mailhog with the following settings: MAIL_MAILER=smtp MAIL_HOST=localhost MAIL_PORT=1025 MAIL_USERNAME=null MAIL_PASSWORD=null MAIL_ENCRYPTION=null","title":"Email Capture and Review (MailHog)"},{"location":"users/basics/developer-tools/#using-development-tools-on-the-host-machine","text":"It is possible in many cases to use development tools installed on your host machine on a project provisioned by ddev. Tools that interact with files and require no database connection, such as Git or Composer, can be run from the host machine against the code base for a ddev project with no additional configuration necessary.","title":"Using Development Tools on the Host Machine"},{"location":"users/basics/developer-tools/#database-connections-from-the-host","text":"If you need to connect to the database of your project from the host machine, run ddev describe to show the database connection information, like Host: localhost:49156 . The port referenced is unique per running project, and randomly chosen from available ports on your system when you run ddev start . You can force this port to be the same on every ddev start by setting host_db_port in the project .ddev/config.yaml. For example, host_db_port: \"49156\" or ddev config --host-db-port=49156 . This value needs to be different on each running DDEV project, and unless it is set, the database port will change on every ddev start . You can use this port with various tools that need a direct port, like mysql or psql clients, but it's usually easiest to use ddev mysql , ddev psql , ddev sequelace , ddev tableplus , etc, which set everything up for you.","title":"Database Connections from the Host"},{"location":"users/basics/developer-tools/#using-drush-8-installed-installation-on-the-host-computer","text":"Warning: Using drush on the host is discouraged, and you'll have some trouble with it. It's also mostly irrelevant for Drupal8, as you should be using composer-installed project-level drush. If you have PHP and Drush installed on your host system and the environment variable IS_DDEV_PROJECT=true, you can use drush to interact with a ddev project. On the host system the extra include host-side configuration for the database and port are derived in the settings.ddev.php file to allow drush to access the database server. This may not work for all drush commands because of course the actual webserver environment is not available. Note that on Drupal 8+ if you want to use drush uli on the host (or other drush commands that require a default URI), you'll need to set DRUSH_OPTIONS_URI on the host. For example, export DRUSH_OPTIONS_URI=https://mysite.ddev.site .","title":"Using Drush 8 installed Installation on the Host Computer"},{"location":"users/basics/developer-tools/#ddev-and-terminus","text":"Terminus is a command line tool providing advanced interaction with Pantheon services. As of version 1.13.0 , terminus is available inside the project's container, allowing users to get information from, or issue commands to their Pantheon-hosted sites. This is an especially helpful feature for Windows users as terminus is only officially supported on unix-based systems. To use terminus, you'll first need to: Use a machine token, more discussion in Pantheon provider discussion . Use ddev ssh to tunnel into your container Issue a command using the keyword terminus . For help using terminus try terminus list to get a list of possible commands. Terminus also allows you to issue drush , WP-CLI , and composer commands to your pantheon server. These are all usable from within the container as well, but will require authentication via either your Pantheon password or an SSH key. To use your host machine's SSH key, you can use the ddev auth ssh command described here .","title":"DDEV and Terminus"},{"location":"users/basics/faq/","text":"Frequently-Asked Questions (FAQ) \u00b6 What operating systems will DDEV-Local work with? DDEV-Local works nearly anywhere Docker will run, including macOS, Windows 10/11 Pro/Enterprise, Windows 10/11 Home, and every Linux variant we've ever tried. It also runs in many Linux-like environments, for example ChromeOS (in Linux machine) and Windows 10/11's WSL2. In general, DDEV works the same on each of these platforms, as all the important work is done inside identical Docker containers. Do I lose my data when I do a ddev poweroff or ddev stop or ddev restart ? No, you don't lose data in your database or code with any of these commands. Your database is safely stored on a docker volume. How does my project connect to the database? ddev describe gives full details of how to connect to the database. Inside the container the hostname is 'db' ( NOT 127.0.0.1). User/password/database are all 'db'. For connection from the host , see ddev describe . How can I troubleshoot what's going wrong? See the troubleshooting , Docker troubleshooting and Xdebug troubleshooting sections of the docs. Do I need to install PHP or Composer or Nginx or nodejs/npm on my computer? Absolutely not . All of these tools live inside DDEV's docker containers, so you need only Docker and DDEV. This is especially handy for Windows users where there's a bit more friction installing those tools. How do I get support? See the (many) support options , including Discord , Stack Overflow and others. How can I get the best performance? Docker's normal mounting can be slow, especially on macOS. See the Performance section for speed-up options including Mutagen and NFS mounting. How can I check that Docker is working? The Docker Installation docs have a full Docker troubleshooting section , including a single docker run command that will verify whether everything is set up. Can I run DDEV and also other Docker or non-Docker development environments at the same time? Yes, you can, as long as they're configured with different ports. But it's easiest to shut down one before using the other. For example, if you use Lando for one project, do a lando poweroff before using DDEV, and then do a ddev poweroff before using Lando again. If you run nginx or apache locally, just stop them before using DDEV. More information is in the troubleshooting section. How can I contribute to DDEV-Local? We love contributions of knowledge, support, docs, and code, and invite you to all of them. Make an issue or PR to the main repo . Add your external resource to awesome-ddev . Add your recipe or HOWTO to ddev-contrib . Help others in Discord and Stack Overflow . Follow the governance issue to learn about financial support possibilities. How can I show my local project to someone else? It's often the case that we want a customer or coworker to be able to view our local environment, even if they're on a different machine, network, etc. There are several ways to do this . ddev share is one of the ways - it provides a link that anyone can view and so they can interact with your local project while you allow it. See ddev share -h for more information. It does require an account on ngrok.com . Can I use additional databases with DDEV? Yes, you can create additional databases and manually do whatever you need on them. They are automatically created if you use ddev import-db with --target-db , for example ddev import-db --target-db=extradb --src=.tarballs/extradb.sql.gz . You can use ddev mysql or ddev psql for random queries, or also use the mysql/psql clients within ddev ssh or ddev ssh -s db as well. Can different projects communicate with each other? Yes, this is commonly required for situations like Drupal migrations. For the web container to access the db container of another project, use ddev-<projectname>-db as the hostname of the other project. For example, in project1, use mysql -h ddev-project2-db to access the db server of project2. For HTTP/S communication you can 1) access the web container of project2 directly with the hostname ddev-<project2>-web and port 80 or 443: curl https://ddev-project2-web or 2) Add a .ddev/docker-compose.communicate.yaml which will allow you to access the other project via the official FQDN. version : '3.6' services : web : external_links : - \"ddev-router:project2.ddev.site\" How do I make DDEV match my production webserver environment? You can change the PHP major version and choose between nginx+fpm (default) and apache+fpm and choose the MariaDB/MySQL/Postgresql version add extra services like solr and memcached . You will not be able to make every detail match your production server, but with database server type and version, PHP version and webserver type you'll be close. How do I completely destroy a project? Use ddev delete <project> to destroy a project. By default, a ddev snapshot of your database is taken, but you can skip this using ddev delete --omit-snapshot or ddev delete --omit-snapshot -y , see ddev delete -h for options. It's up to you to then delete the code directory. I don't like the settings files or gitignores that DDEV creates. What can I do? You have a couple of options that work well for most people: Use project type \"php\" instead of the type of your CMS. \"php\" just means \"Don't try to create settings files and such for me.\". The \"php\" type works great for experienced developers. \"Take over\" the settings file or .gitignore by deleting the line \"#ddev-generated\" in it (and then check in the file). If that line is removed, ddev will not try to replace or change the file. How can I change the name of a project? Use this process: 1. Export the database of the project: ddev export-db --file=/path/to/db.sql.gz 2. ddev delete <project> . By default this will make a snapshot, which is a nice safety valve. 3. Rename the project, ddev config --project-name=<new_name> 4. ddev start 5. ddev import-db --src=/path/to/db.sql.gz How can I move a project from one directory to another? ddev stop --unlist , then move the directory, then ddev start in the new directory. How can I move a project from one computer to another? Follow this procedure: 1. ddev start && ddev snapshot 2. ddev stop --unlist 3. Move the project directory to another computer any way you want. 4. On the new computer, ddev start && ddev snapshot restore --latest 5. Optionally, on the old computer, ddev delete --omit-snapshot to get rid of the database there. How can I move a project from traditional Windows to WSL2? This is exactly the same as moving a project from one computer to another, see above. Make sure you move the project into a native filesystem in WSL2, most likely /home. DDEV-Local wants to add a hostname to /etc/hosts but I don't think it should need to. If you see \"The hostname is not currently resolvable\" and you can ping <hostname> , it may be that DNS resolution is slow. DDEV doesn't have any control of your computer's name resolution, so doesn't have any way to influence how your browser gets an IP address from a hostname. It knows you have to be connected to the Internet to do that, and uses a test DNS lookup of .ddev.site as a way to guess whether you're connected to the internet. If it is unable to do a name lookup, or if the hostname associated with your project is not *.ddev.site, it will try to create entries in /etc/hosts, since it's assuming you can't look up your project's hostname(s) via DNS. If your internet (and name resolution) is actually working, but DNS is slow, just ddev config global --internet-detection-timeout-ms=3000 to set the timeout to 3 seconds (or higher). See issue link for more details. (If DNS rebinding is disallowed on your network/router, this won't be solvable without network/router changes. Help here and here .) For more detailed troubleshooting information please see the troubleshooting section . How can I configure a project with the defaults without hitting a bunch of times? Just use ddev config --auto and it will choose docroot and project type based on the discovered code. If it gets anything wrong (just look at .ddev/config.yaml ) you can change that at any time using various ddev config commands or just by editing the .ddev/config.yaml . Why do I get a 403 or 404 on my project after ddev launch ? The most likely reason for this is that the docroot is misconfigured, or there's no index.php or index.html file in the docroot. Take a look at your .ddev/config.yaml and see what is there for the docroot. It should be a relative path to where your index.php is. Why do I see nginx headers when I'm configured to use webserver_type: apache-fpm ? Apache runs in the web container but when you use the http://*.ddev.site URL, it goes through ddev-router, which is an nginx reverse proxy, and that's why you see the nginx headers. But rest assured you are using Apache. More detail in Stack Overflow answer Why does ddev start fail with \"error while mounting volume, Permission denied\"? This almost always means that you have NFS enabled in your project, but NFS isn't working on your machine. Start by completely turning NFS off for your projects with ddev config --nfs-mount-enabled=false && ddev config global --nfs-mount-enabled=false . Then later, go get NFS working . NFS can be a big performance help on macOS and traditional Windows, and not needed on Linux or Windows WSL2. How can I install a specific version of DDEV? If you want to use a different version of DDEV, you easily get a different version. If you're using homebrew, brew unlink ddev first, to get rid of the version you have there. Then use one of these options: Download the version you want from the releases page and place it somewhere in your $PATH . Use the install_ddev.sh script with the version number argument. For example, if you want v1.18.3-alpha1, use curl -LO https://raw.githubusercontent.com/drud/ddev/master/scripts/install_ddev.sh && bash install_ddev.sh v1.18.3-alpha1 If you want the very latest, unreleased version of ddev, use brew unlink ddev && brew install drud/ddev/ddev --HEAD . How can I back up or restore all databases of all projects? You can back up all projects that show in ddev list with ddev snapshot -a . This only snapshots projects that are shown in ddev list though, so if you have other projects that aren't shown, you'd need to start them so they'd be registered in ddev list . How can I contribute financially to the DDEV project? Thanks for asking! Contributions can be done via GitHub Sponsors . They go to the Localdev Foundation and are used for infrastructure and supporting development.","title":"Frequently-Asked Questions (FAQ)"},{"location":"users/basics/faq/#frequently-asked-questions-faq","text":"What operating systems will DDEV-Local work with? DDEV-Local works nearly anywhere Docker will run, including macOS, Windows 10/11 Pro/Enterprise, Windows 10/11 Home, and every Linux variant we've ever tried. It also runs in many Linux-like environments, for example ChromeOS (in Linux machine) and Windows 10/11's WSL2. In general, DDEV works the same on each of these platforms, as all the important work is done inside identical Docker containers. Do I lose my data when I do a ddev poweroff or ddev stop or ddev restart ? No, you don't lose data in your database or code with any of these commands. Your database is safely stored on a docker volume. How does my project connect to the database? ddev describe gives full details of how to connect to the database. Inside the container the hostname is 'db' ( NOT 127.0.0.1). User/password/database are all 'db'. For connection from the host , see ddev describe . How can I troubleshoot what's going wrong? See the troubleshooting , Docker troubleshooting and Xdebug troubleshooting sections of the docs. Do I need to install PHP or Composer or Nginx or nodejs/npm on my computer? Absolutely not . All of these tools live inside DDEV's docker containers, so you need only Docker and DDEV. This is especially handy for Windows users where there's a bit more friction installing those tools. How do I get support? See the (many) support options , including Discord , Stack Overflow and others. How can I get the best performance? Docker's normal mounting can be slow, especially on macOS. See the Performance section for speed-up options including Mutagen and NFS mounting. How can I check that Docker is working? The Docker Installation docs have a full Docker troubleshooting section , including a single docker run command that will verify whether everything is set up. Can I run DDEV and also other Docker or non-Docker development environments at the same time? Yes, you can, as long as they're configured with different ports. But it's easiest to shut down one before using the other. For example, if you use Lando for one project, do a lando poweroff before using DDEV, and then do a ddev poweroff before using Lando again. If you run nginx or apache locally, just stop them before using DDEV. More information is in the troubleshooting section. How can I contribute to DDEV-Local? We love contributions of knowledge, support, docs, and code, and invite you to all of them. Make an issue or PR to the main repo . Add your external resource to awesome-ddev . Add your recipe or HOWTO to ddev-contrib . Help others in Discord and Stack Overflow . Follow the governance issue to learn about financial support possibilities. How can I show my local project to someone else? It's often the case that we want a customer or coworker to be able to view our local environment, even if they're on a different machine, network, etc. There are several ways to do this . ddev share is one of the ways - it provides a link that anyone can view and so they can interact with your local project while you allow it. See ddev share -h for more information. It does require an account on ngrok.com . Can I use additional databases with DDEV? Yes, you can create additional databases and manually do whatever you need on them. They are automatically created if you use ddev import-db with --target-db , for example ddev import-db --target-db=extradb --src=.tarballs/extradb.sql.gz . You can use ddev mysql or ddev psql for random queries, or also use the mysql/psql clients within ddev ssh or ddev ssh -s db as well. Can different projects communicate with each other? Yes, this is commonly required for situations like Drupal migrations. For the web container to access the db container of another project, use ddev-<projectname>-db as the hostname of the other project. For example, in project1, use mysql -h ddev-project2-db to access the db server of project2. For HTTP/S communication you can 1) access the web container of project2 directly with the hostname ddev-<project2>-web and port 80 or 443: curl https://ddev-project2-web or 2) Add a .ddev/docker-compose.communicate.yaml which will allow you to access the other project via the official FQDN. version : '3.6' services : web : external_links : - \"ddev-router:project2.ddev.site\" How do I make DDEV match my production webserver environment? You can change the PHP major version and choose between nginx+fpm (default) and apache+fpm and choose the MariaDB/MySQL/Postgresql version add extra services like solr and memcached . You will not be able to make every detail match your production server, but with database server type and version, PHP version and webserver type you'll be close. How do I completely destroy a project? Use ddev delete <project> to destroy a project. By default, a ddev snapshot of your database is taken, but you can skip this using ddev delete --omit-snapshot or ddev delete --omit-snapshot -y , see ddev delete -h for options. It's up to you to then delete the code directory. I don't like the settings files or gitignores that DDEV creates. What can I do? You have a couple of options that work well for most people: Use project type \"php\" instead of the type of your CMS. \"php\" just means \"Don't try to create settings files and such for me.\". The \"php\" type works great for experienced developers. \"Take over\" the settings file or .gitignore by deleting the line \"#ddev-generated\" in it (and then check in the file). If that line is removed, ddev will not try to replace or change the file. How can I change the name of a project? Use this process: 1. Export the database of the project: ddev export-db --file=/path/to/db.sql.gz 2. ddev delete <project> . By default this will make a snapshot, which is a nice safety valve. 3. Rename the project, ddev config --project-name=<new_name> 4. ddev start 5. ddev import-db --src=/path/to/db.sql.gz How can I move a project from one directory to another? ddev stop --unlist , then move the directory, then ddev start in the new directory. How can I move a project from one computer to another? Follow this procedure: 1. ddev start && ddev snapshot 2. ddev stop --unlist 3. Move the project directory to another computer any way you want. 4. On the new computer, ddev start && ddev snapshot restore --latest 5. Optionally, on the old computer, ddev delete --omit-snapshot to get rid of the database there. How can I move a project from traditional Windows to WSL2? This is exactly the same as moving a project from one computer to another, see above. Make sure you move the project into a native filesystem in WSL2, most likely /home. DDEV-Local wants to add a hostname to /etc/hosts but I don't think it should need to. If you see \"The hostname is not currently resolvable\" and you can ping <hostname> , it may be that DNS resolution is slow. DDEV doesn't have any control of your computer's name resolution, so doesn't have any way to influence how your browser gets an IP address from a hostname. It knows you have to be connected to the Internet to do that, and uses a test DNS lookup of .ddev.site as a way to guess whether you're connected to the internet. If it is unable to do a name lookup, or if the hostname associated with your project is not *.ddev.site, it will try to create entries in /etc/hosts, since it's assuming you can't look up your project's hostname(s) via DNS. If your internet (and name resolution) is actually working, but DNS is slow, just ddev config global --internet-detection-timeout-ms=3000 to set the timeout to 3 seconds (or higher). See issue link for more details. (If DNS rebinding is disallowed on your network/router, this won't be solvable without network/router changes. Help here and here .) For more detailed troubleshooting information please see the troubleshooting section . How can I configure a project with the defaults without hitting a bunch of times? Just use ddev config --auto and it will choose docroot and project type based on the discovered code. If it gets anything wrong (just look at .ddev/config.yaml ) you can change that at any time using various ddev config commands or just by editing the .ddev/config.yaml . Why do I get a 403 or 404 on my project after ddev launch ? The most likely reason for this is that the docroot is misconfigured, or there's no index.php or index.html file in the docroot. Take a look at your .ddev/config.yaml and see what is there for the docroot. It should be a relative path to where your index.php is. Why do I see nginx headers when I'm configured to use webserver_type: apache-fpm ? Apache runs in the web container but when you use the http://*.ddev.site URL, it goes through ddev-router, which is an nginx reverse proxy, and that's why you see the nginx headers. But rest assured you are using Apache. More detail in Stack Overflow answer Why does ddev start fail with \"error while mounting volume, Permission denied\"? This almost always means that you have NFS enabled in your project, but NFS isn't working on your machine. Start by completely turning NFS off for your projects with ddev config --nfs-mount-enabled=false && ddev config global --nfs-mount-enabled=false . Then later, go get NFS working . NFS can be a big performance help on macOS and traditional Windows, and not needed on Linux or Windows WSL2. How can I install a specific version of DDEV? If you want to use a different version of DDEV, you easily get a different version. If you're using homebrew, brew unlink ddev first, to get rid of the version you have there. Then use one of these options: Download the version you want from the releases page and place it somewhere in your $PATH . Use the install_ddev.sh script with the version number argument. For example, if you want v1.18.3-alpha1, use curl -LO https://raw.githubusercontent.com/drud/ddev/master/scripts/install_ddev.sh && bash install_ddev.sh v1.18.3-alpha1 If you want the very latest, unreleased version of ddev, use brew unlink ddev && brew install drud/ddev/ddev --HEAD . How can I back up or restore all databases of all projects? You can back up all projects that show in ddev list with ddev snapshot -a . This only snapshots projects that are shown in ddev list though, so if you have other projects that aren't shown, you'd need to start them so they'd be registered in ddev list . How can I contribute financially to the DDEV project? Thanks for asking! Contributions can be done via GitHub Sponsors . They go to the Localdev Foundation and are used for infrastructure and supporting development.","title":"Frequently-Asked Questions (FAQ)"},{"location":"users/basics/how-ddev-works/","text":"How DDEV Works \u00b6 The easiest way to think about how DDEV works is to think of it as a set of little networked computers (docker containers). You can think of them as being in a different network world than your workstation computer, but reachable from there. The ddev-webserver container (one per project) runs nginx or apache and php-fpm for a single site, so it does all the basic work of a PHP-interpreting webserver. The ddev-dbserver container (one per project) handles MariaDB/MySQL/Postgresql database management. It can be reached from the webserver by the hostname db or with the more explicit name ddev-<projectname>-db . The optional dba container runs PhpMyAdmin for projects with MySQL or MariaDB. Additional add-on services may be there for a given project, for example solr or elasticsearch or memcached . Although it's not common usage, different projects can communicate with each other as described in the FAQ Now for the two oddball containers, which are global (there is only one of each). The ddev-router container is a \"reverse proxy\". It takes incoming HTTP/S requests and looks up the hostname in the incoming URL and routes it to the correct project's ddev-webserver . Depending on the project's configuration with additional_hostnames and additional_fqdns it can route many different URLs to a single project's ddev-webserver . If like most people you use the named URLs (like https://something.ddev.site ) then your request goes through the router. When you use the 127.0.0.1 URLs, the requests go directly to the ddev-webserver . The ddev-ssh-agent container runs an ssh-agent inside the docker network so that after you do a ddev auth ssh all the different projects can use your ssh keys for outgoing requests (like private composer access or scp from a remote host). Here's a basic diagram of how it works inside the docker network:","title":"How DDEV Works"},{"location":"users/basics/how-ddev-works/#how-ddev-works","text":"The easiest way to think about how DDEV works is to think of it as a set of little networked computers (docker containers). You can think of them as being in a different network world than your workstation computer, but reachable from there. The ddev-webserver container (one per project) runs nginx or apache and php-fpm for a single site, so it does all the basic work of a PHP-interpreting webserver. The ddev-dbserver container (one per project) handles MariaDB/MySQL/Postgresql database management. It can be reached from the webserver by the hostname db or with the more explicit name ddev-<projectname>-db . The optional dba container runs PhpMyAdmin for projects with MySQL or MariaDB. Additional add-on services may be there for a given project, for example solr or elasticsearch or memcached . Although it's not common usage, different projects can communicate with each other as described in the FAQ Now for the two oddball containers, which are global (there is only one of each). The ddev-router container is a \"reverse proxy\". It takes incoming HTTP/S requests and looks up the hostname in the incoming URL and routes it to the correct project's ddev-webserver . Depending on the project's configuration with additional_hostnames and additional_fqdns it can route many different URLs to a single project's ddev-webserver . If like most people you use the named URLs (like https://something.ddev.site ) then your request goes through the router. When you use the 127.0.0.1 URLs, the requests go directly to the ddev-webserver . The ddev-ssh-agent container runs an ssh-agent inside the docker network so that after you do a ddev auth ssh all the different projects can use your ssh keys for outgoing requests (like private composer access or scp from a remote host). Here's a basic diagram of how it works inside the docker network:","title":"How DDEV Works"},{"location":"users/basics/troubleshooting/","text":"Troubleshooting \u00b6 Things might go wrong! Besides the suggestions on this page don't forget about Stack Overflow and the ddev issue queue and other support options . And see Docker troubleshooting suggestions . General Troubleshooting Strategies \u00b6 Please start with a ddev poweroff to make sure all containers can start fresh. Temporarily turn off firewalls, VPNs, network proxies, and virus checkers while you're troubleshooting. If you have any proxies set up in Docker's settings, temporarily remove them. ddev debug dockercheck will help sort out Docker problems, as will ddev debug test . On macOS and traditional Windows, please check to make sure that Docker Desktop is not out of disk space. In Settings (or Preferences)->Resources->Disk image size there should be lots of space left; I never let it go over 80% because the number reported here is not reliable. If it says zero used, something is wrong. If you have customizations (PHP overrides, nginx or Apache overrides, MySQL/Postgresql overrides, custom services, config.yaml changes) please back them out while troubleshooting. It's important to have the simplest possible environment while troubleshooting. Restart Docker. Consider a Docker factory reset in serious cases (this will destroy any databases you've loaded). See Docker Troubleshooting for more. Try the simplest possible ddev project to try to get it to work (just as ddev debug test does). ddev poweroff mkdir ~/tmp/testddev cd ~/tmp/testddev ddev config --auto printf \"<?php\\nphpinfo();\\n\" > index.php ddev start Does that start up OK? If so, maybe something is wrong with the more complicated project you're trying to start. Using DDEV with other development environments installed DDEV by default uses ports 80 and 443 on your system when projects are running. If you are using another local development environment (like Lando or Docksal or a native setup) you can either stop the other environment or configure DDEV to use different ports. See troubleshooting for more detailed problem-solving. It's easiest just to stop the other environment when you want to use DDEV, and stop DDEV when you want to use the other environment. Webserver ports are already occupied by another webserver \u00b6 DDEV may notify you about port conflicts with this message about port 80 or 443: Failed to start yoursite: Unable to listen on required ports, localhost port 80 is in use ddev sometimes also has this error message that will alert you to port conflicts: ERROR: for ddev-router Cannot start service ddev-router: Ports are not available: listen tcp 127.0.0.1:XX: bind: An attempt was made to access a socket in a way forbidden by its access permissions. This means there is another webserver listening on the named port(s) and ddev cannot access the port. The most common conflicts are on ports 80 and 443. (In some cases the conflict could be over port 8036 (phpMyAdmin) or port 8025 (MailHog)). To resolve this conflict, choose one of three methods: If you are using another local development environment (MAMP, WAMP, lando, etc.) that uses these ports, consider stopping it. Fix port conflicts by configuring your project to use different ports. Fix port conflicts by stopping the competing application. Method 1: Stop the conflicting application \u00b6 Consider lando poweroff for Lando, or fin system stop for Docksal, or stop MAMP using GUI interface or stop.sh . Method 2: Fix port conflicts by configuring your project to use different ports \u00b6 To configure a project to use non-conflicting ports, edit the project's .ddev/config.yaml to add entries like router_http_port: 8000 and router_https_port: 8443 depending on your needs. Then use ddev start again. For example, if there was a port conflict with a local apache http on port 80 add the following to the config.yaml file. router_http_port : 8080 router_https_port : 8443 Then run ddev start . This changes the project's http URL to http://yoursite.ddev.site:8080 and the https URL to https://yoursite.ddev.site:8443 . If the conflict is over port 8025, it's normally a conflict over the default port for MailHog. You can add to your .ddev/config.yaml mailhog_port : 8300 If the conflict is over port 8036, it's normally about phpMyAdmin, and you can add to your .ddev/config.yaml phpmyadmin_port : 8302 Method 3: Fix port conflicts by stopping the competing application \u00b6 Alternatively, stop the other application. Probably the most common conflicting application is Apache running locally. It can often be stopped gracefully (but temporarily) with: sudo apachectl stop Common tools that use port 80 and port 443: Here are some of the other common processes that could be using ports 80/443 and methods to stop them. MAMP (macOS): Stop MAMP. Apache: Temporarily stop with sudo apachectl stop , permanent stop depends on your environment. nginx (macOS Homebrew): sudo brew services stop nginx or sudo launchctl stop homebrew.mxcl.nginx nginx (Ubuntu): sudo service nginx stop apache (often named \"httpd\") (many environments): sudo apachectl stop or on Ubuntu sudo service apache2 stop vpnkit (macOS): You likely have a docker container bound to port 80, do you have containers up for Lando or another docker-based development environment? If so, stop the other environment. Lando: If you have previously used Lando try running lando poweroff To dig deeper, you can use a number of tools to find out what process is listening. On macOS and Linux, try the lsof tool on ports 80 or 443 or whatever port you're having trouble with: $ sudo lsof -i :443 -sTCP:LISTEN COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME nginx 1608 www-data 46u IPv4 13913 0t0 TCP *:http (LISTEN) nginx 5234 root 46u IPv4 13913 0t0 TCP *:http (LISTEN) On Windows CMD, use sysinternals tcpview or try using netstat and tasklist to find the pid: > netstat -aon | findstr \":80.*LISTENING\" TCP 127.0.0.1:80 0.0.0.0:0 LISTENING 5760 TCP 127.0.0.1:8025 0.0.0.0:0 LISTENING 5760 TCP 127.0.0.1:8036 0.0.0.0:0 LISTENING 5760 > tasklist | findstr \"5760\" com.docker.backend.exe 5760 Services 0 9,536 K The resulting output displays which command is running and its pid. Choose the appropriate method to stop the other server. We welcome your suggestions based on other issues you've run into and your troubleshooting technique. Database container fails to start \u00b6 Use ddev logs -s db to see what's wrong. The most common cause of the database container not coming up is changing the database type or version in the project configuration, so the database server daemon is unable to start using an existing configuration that is for a different type or version. To solve this: Change the configuration in .ddev/config.yaml back to the original configuration. Export the database with ddev export-db . Delete the project with ddev delete (or stop the project and remove the database volume using docker volume rm <project>-mariadb or docker volume rm <project>-postgres ). Change the .ddev/config.yaml to use the new database type or version. Start the project and import the database from your export. \"web service unhealthy\" or \"web service starting\" or exited \u00b6 Use ddev logs to see what's wrong. The most common cause of the web container being unhealthy is a user-defined .ddev/nginx-full/nginx-site.conf or .ddev/apache/apache-site.conf - Please rename these to during testing. To figure out what's wrong with it after you've identified that as the problem, use ddev logs and review the error. Changes to .ddev/nginx-site.conf and .ddev/apache/apache-site.conf take effect only when you do a ddev restart or the equivalent. No input file specified (404) or Forbidden (403) \u00b6 If you get a 404 with \"No input file specified\" (nginx) or a 403 with \"Forbidden\" (apache) when you visit your project it usually means that no index.php or index.html is being found in the docroot. This can result from: Misconfigured docroot: If the docroot isn't where the webserver thinks it is, then the webserver won't find the index.php. Look at your .ddev/config.yaml to verify it has a docroot that will lead to the index.php. It should be a relative path from the project root to the directory where the index.php is. Missing index.php: There may not be an index.php or index.html in your project. ddev start fails and logs contain \"failed (28: No space left on device)\" - Docker File Space \u00b6 If ddev start fails, it's most often because the web container or db container fails to start. In this case the error message from ddev start says something like \"Failed to start : db container failed: log=, err=container exited, please use 'ddev logs -s db' to find out why it failed\". You can ddev logs -s db to find out what happened. If you see any variant of \"no space left on device\" in the logs when using Docker Desktop, it means that you have to increase or clean up Docker's file space. To increase the allocated space, go to \"Resources\" in Docker's Preferences as shown in If you see \"no space left on device\" on Linux, it most likely means your filesystem is full. ddev start fails with \"container failed to become ready\" \u00b6 If a container fails to become ready, it means it's failing the healthcheck. This can happen to any of the containers, but you can usually find out quickly what the issue is with a docker inspect command. You may need to install jq for these, brew install jq , or just remove the \"| jq\" from the command and read the raw json output. For the web container, docker inspect --format \"{{json .State.Health }}\" ddev-<projectname>-web | jq For ddev-router, docker inspect --format \"{{json .State.Health }}\" ddev-router For ddev-ssh-agent, docker inspect --format \"{{json .State.Health }}\" ddev-ssh-agent Don't forget that ddev logs (for the web container) or ddev logs -s db (for the db container) are your friend. For ddev-router and ddev-ssh-agent, docker logs ddev-router and docker logs ddev-ssh-agent . Run ddev debug router-nginx-config to print the Nginx configuration of the currently running ddev-router. ddev start fails with \"Failed to start [project name]: No such container: ddev-router\" \u00b6 Deleting the images and re-pulling them generally solves this problem. Try running the following commands from the host machine. ddev poweroff docker rm -f $(docker ps -aq) docker rmi -f $(docker images -q) You should then be able to start your ddev machine. Trouble Building Dockerfiles \u00b6 The additional .ddev/web-build/Dockerfile capability in ddev is wonderful, but it can be hard to figure out what to put in there. The best approach for any significant Dockerfile is to ddev ssh and sudo -s and then one at a time, do the things that you plan to do with a RUN command in the Dockerfile. For example, if your Dockerfile were RUN npm install --global forever You could test it with ddev ssh , sudo -s and then npm install --global forever The error messages you get will be more informative than messages that come when the Dockerfile is processed. You can also see the full Docker build using ~/.ddev/bin/docker-compose -f .ddev/.ddev-docker-compose-full.yaml build --no-cache --progress=plain . Ddev starts fine, but my browser can't access the URL \" server IP address could not be found\" or \"We can\u2019t connect to the server at \" \u00b6 Most people use *.ddev.site URLs for most projects, and that works great most of the time, but requires internet access. \"*.ddev.site\" is a wildcard DNS entry that always returns the IP address 127.0.0.1 (localhost). However, if you're not connected to the internet, or if various other name resolution issues (below) fail, this name resolution won't work. While ddev can create a webserver and a docker network infrastructure for a project, it doesn't have control of your computer's name resolution, so its backup technique to make a hostname resolvable by the browser is to add an entry to the hosts file (/etc/hosts on Linux and macOS, C:\\Windows\\system32\\drivers\\etc\\hosts on traditional Windows). If you're not connected to the internet, your browser will not be able to look up *.ddev.site hostnames. DDEV works fine offline, but for your browser to look up names they'll have to be resolved in a different way. DDEV assumes that hostnames can be resolved within 3 seconds. That assumption is not valid on all networks or computers, so you can increase the amount of time it waits for resolution with ddev config global --internet-detection-timeout-ms=5000 for example. If DDEV detects that it can't look up one of the hostnames assigned to your project for that or other reasons, it will try to add that to the hosts file on your computer, but of course that requires administrative privileges (sudo or Windows UAC) This technique may not work on Windows WSL2, see below. Only 10 hosts are valid on a line on traditional Windows, see below ; beyond that hostnames are ignored. Windows WSL2 name resolution on non-ddev.site hostnames or when not internet-connected \u00b6 On Windows WSL2, there is a hosts file inside the WSL2 instance ( /etc/hosts ), and there is also one on the Windows side ( C:\\Windows\\system32\\drivers\\etc\\hosts ). Many people use a browser on the Windows side, which has no idea about hostnames that may be set up in the WSL2 /etc/hosts file. So a WSL2 project which uses *.ddev.site works fine when accessed by a browser on the Windows side, as long as internet connectivity is available (DNS lookups of *.ddev.site succeed). However, if the project uses non-ddev.site hostnames, or if not connected to the Internet, or if use_dns_when_possible is false in the .ddev/config.yaml, a Windows-side browser will be unable to look up project hostnames, and you'll get complaints from the browser like \" server IP address could not be found\" or \"We can\u2019t connect to the server at \". In this case, you can: Add the needed hostname(s) manually to the Windows hosts file. This can easily be done with the Windows version of ddev.exe with sudo ddev hostname <hostname> 127.0.0.1 on Windows in PowerShell or Cmd or git-bash. Or run a browser within WSL2. On Windows 11 this is built-in, but in Windows 10 may require an X11 server like X410. DNS Rebinding Prohibited \u00b6 Some DNS servers prevent the use of DNS records that resolve to localhost (127.0.0.1) because in uncontrolled environments this may be used as a form of attack called DNS Rebinding . Since *.ddev.site resolves to 127.0.0.1, they may refuse to resolve, and your browser may be unable to look up a hostname, and give you messages like \" server IP address could not be found\" or \"We can\u2019t connect to the server at \". In this case, you can Reconfigure the DNS server to allow DNS Rebinding. Many Fritzbox routers have added default DNS Rebinding disallowal, and they can be reconfigured to allow it, see issue . If you have the local dnsmasq DNS server it may also be configured to disallow DNS rebinding, but it's a simple change to a configuration directive to allow it. Most computers can use most relaxed DNS resolution if they are not on corporate intranets that have non-internet DNS. So for example, the computer can be set to use 8.8.8.8 (Google) or 1.1.1.1 (Cloudflare) for DNS name resolution. If you have control of the router, you can usually change its DHCP settings to choose a DNS server to a public, relaxed DNS server as in #2 . You can live with ddev trying to edit the /etc/hosts file, which it only has to do when a new name is added to a project. Windows Hosts File limited to 10 hosts per IP address line \u00b6 On Windows only, there is a limit to the number of hosts that can be placed in one line. But since all ddev hosts are typically on the same IP address (typically 127.0.0.1, localhost), they can really add up. As soon as you have more than 10 entries there, your browser won't be able to resolve the addresses beyond the 10 th entry. There are two workarounds for this problem: Use ddev stop --all and sudo ddev hostname --remove-inactive to prune the number of hosts on that hosts-file line. When you start a project, the hostname(s) associated with that project will be added back again. Manually edit the hosts file (typically C:\\Windows\\System32\\drivers\\etc\\hosts ) and put some of your hosts on a separate line in the file. Windows WSL2 Network Issues \u00b6 If you're using a browser on Windows, accessing a project in WSL2, you can end up with very confusing results if your project is listening on a port inside WSL2, but a Windows process is listening on the port on Windows. The way to sort this out is to stop your project inside WSL2, verify that nothing is listening on the port there, and then study the port on the Windows side, by visiting it with a browser or using other tools as described above. Limitations on Symbolic Links (symlinks) \u00b6 Symbolic links are widely used but have specific limitations in many environments, not just in DDEV. Here are some of the ways those may affect you: Crossing mount boundaries : Symlinks may not generally cross between network mounts. In other words, if you have a relative symlink in the root of your project directory on the host that points to ../somefile.txt , that symlink will not be valid inside the container where ../ is a completely different filesystem (and is not mounted typically). Symlinks to absolute paths : If you have an absolute symlink to something like /Users/xxx/somefile.txt on the host, it will not be resolvable inside the container because /Users is not mounted there. Note that some tools, especially on Magento 2, may create symlinks to rooted paths, with targets like /var/www/html/path/to/something . These basically can't make it to the host, so may create errors. Windows restrictions on symlinks : Inside the Docker container on Windows you may not be able to even create a symlink that goes outside the container. Mutagen restrictions on Windows symlinks : On macOS and Linux (including WSL2) the default .ddev/mutagen/mutagen.yml chooses the posix-raw type of symlink handling (See mutagen docs ). This basically means that any symlink created will try to sync, regardless of whether it's valid in the other environment. However, Mutagen does not support posix-raw on traditional Windows, so ddev uses the portable symlink mode. So on Windows with Mutagen... symlinks have to be strictly limited to relative links that are inside the mutagen section of the project. Delete and re-download docker images \u00b6 In just a few unusual cases, the actual downloaded docker images have somehow corrupted. In that case we can delete all images and they'll be re-downloaded or rebuilt. This does no harm, as everything is just rebuilt, but a ddev start make take extra time the first time while it downloads needed resources: ddev poweroff docker rm -f $( docker ps -aq ) # stop any other random containers that may be running docker rmi -f $( docker images -q ) # You might have to repeat this a time or two to get rid of all images","title":"Troubleshooting"},{"location":"users/basics/troubleshooting/#troubleshooting","text":"Things might go wrong! Besides the suggestions on this page don't forget about Stack Overflow and the ddev issue queue and other support options . And see Docker troubleshooting suggestions .","title":"Troubleshooting"},{"location":"users/basics/troubleshooting/#general-troubleshooting-strategies","text":"Please start with a ddev poweroff to make sure all containers can start fresh. Temporarily turn off firewalls, VPNs, network proxies, and virus checkers while you're troubleshooting. If you have any proxies set up in Docker's settings, temporarily remove them. ddev debug dockercheck will help sort out Docker problems, as will ddev debug test . On macOS and traditional Windows, please check to make sure that Docker Desktop is not out of disk space. In Settings (or Preferences)->Resources->Disk image size there should be lots of space left; I never let it go over 80% because the number reported here is not reliable. If it says zero used, something is wrong. If you have customizations (PHP overrides, nginx or Apache overrides, MySQL/Postgresql overrides, custom services, config.yaml changes) please back them out while troubleshooting. It's important to have the simplest possible environment while troubleshooting. Restart Docker. Consider a Docker factory reset in serious cases (this will destroy any databases you've loaded). See Docker Troubleshooting for more. Try the simplest possible ddev project to try to get it to work (just as ddev debug test does). ddev poweroff mkdir ~/tmp/testddev cd ~/tmp/testddev ddev config --auto printf \"<?php\\nphpinfo();\\n\" > index.php ddev start Does that start up OK? If so, maybe something is wrong with the more complicated project you're trying to start. Using DDEV with other development environments installed DDEV by default uses ports 80 and 443 on your system when projects are running. If you are using another local development environment (like Lando or Docksal or a native setup) you can either stop the other environment or configure DDEV to use different ports. See troubleshooting for more detailed problem-solving. It's easiest just to stop the other environment when you want to use DDEV, and stop DDEV when you want to use the other environment.","title":"General Troubleshooting Strategies"},{"location":"users/basics/troubleshooting/#webserver-ports-are-already-occupied-by-another-webserver","text":"DDEV may notify you about port conflicts with this message about port 80 or 443: Failed to start yoursite: Unable to listen on required ports, localhost port 80 is in use ddev sometimes also has this error message that will alert you to port conflicts: ERROR: for ddev-router Cannot start service ddev-router: Ports are not available: listen tcp 127.0.0.1:XX: bind: An attempt was made to access a socket in a way forbidden by its access permissions. This means there is another webserver listening on the named port(s) and ddev cannot access the port. The most common conflicts are on ports 80 and 443. (In some cases the conflict could be over port 8036 (phpMyAdmin) or port 8025 (MailHog)). To resolve this conflict, choose one of three methods: If you are using another local development environment (MAMP, WAMP, lando, etc.) that uses these ports, consider stopping it. Fix port conflicts by configuring your project to use different ports. Fix port conflicts by stopping the competing application.","title":"Webserver ports are already occupied by another webserver"},{"location":"users/basics/troubleshooting/#method-1-stop-the-conflicting-application","text":"Consider lando poweroff for Lando, or fin system stop for Docksal, or stop MAMP using GUI interface or stop.sh .","title":"Method 1: Stop the conflicting application"},{"location":"users/basics/troubleshooting/#method-2-fix-port-conflicts-by-configuring-your-project-to-use-different-ports","text":"To configure a project to use non-conflicting ports, edit the project's .ddev/config.yaml to add entries like router_http_port: 8000 and router_https_port: 8443 depending on your needs. Then use ddev start again. For example, if there was a port conflict with a local apache http on port 80 add the following to the config.yaml file. router_http_port : 8080 router_https_port : 8443 Then run ddev start . This changes the project's http URL to http://yoursite.ddev.site:8080 and the https URL to https://yoursite.ddev.site:8443 . If the conflict is over port 8025, it's normally a conflict over the default port for MailHog. You can add to your .ddev/config.yaml mailhog_port : 8300 If the conflict is over port 8036, it's normally about phpMyAdmin, and you can add to your .ddev/config.yaml phpmyadmin_port : 8302","title":"Method 2: Fix port conflicts by configuring your project to use different ports"},{"location":"users/basics/troubleshooting/#method-3-fix-port-conflicts-by-stopping-the-competing-application","text":"Alternatively, stop the other application. Probably the most common conflicting application is Apache running locally. It can often be stopped gracefully (but temporarily) with: sudo apachectl stop Common tools that use port 80 and port 443: Here are some of the other common processes that could be using ports 80/443 and methods to stop them. MAMP (macOS): Stop MAMP. Apache: Temporarily stop with sudo apachectl stop , permanent stop depends on your environment. nginx (macOS Homebrew): sudo brew services stop nginx or sudo launchctl stop homebrew.mxcl.nginx nginx (Ubuntu): sudo service nginx stop apache (often named \"httpd\") (many environments): sudo apachectl stop or on Ubuntu sudo service apache2 stop vpnkit (macOS): You likely have a docker container bound to port 80, do you have containers up for Lando or another docker-based development environment? If so, stop the other environment. Lando: If you have previously used Lando try running lando poweroff To dig deeper, you can use a number of tools to find out what process is listening. On macOS and Linux, try the lsof tool on ports 80 or 443 or whatever port you're having trouble with: $ sudo lsof -i :443 -sTCP:LISTEN COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME nginx 1608 www-data 46u IPv4 13913 0t0 TCP *:http (LISTEN) nginx 5234 root 46u IPv4 13913 0t0 TCP *:http (LISTEN) On Windows CMD, use sysinternals tcpview or try using netstat and tasklist to find the pid: > netstat -aon | findstr \":80.*LISTENING\" TCP 127.0.0.1:80 0.0.0.0:0 LISTENING 5760 TCP 127.0.0.1:8025 0.0.0.0:0 LISTENING 5760 TCP 127.0.0.1:8036 0.0.0.0:0 LISTENING 5760 > tasklist | findstr \"5760\" com.docker.backend.exe 5760 Services 0 9,536 K The resulting output displays which command is running and its pid. Choose the appropriate method to stop the other server. We welcome your suggestions based on other issues you've run into and your troubleshooting technique.","title":"Method 3: Fix port conflicts by stopping the competing application"},{"location":"users/basics/troubleshooting/#database-container-fails-to-start","text":"Use ddev logs -s db to see what's wrong. The most common cause of the database container not coming up is changing the database type or version in the project configuration, so the database server daemon is unable to start using an existing configuration that is for a different type or version. To solve this: Change the configuration in .ddev/config.yaml back to the original configuration. Export the database with ddev export-db . Delete the project with ddev delete (or stop the project and remove the database volume using docker volume rm <project>-mariadb or docker volume rm <project>-postgres ). Change the .ddev/config.yaml to use the new database type or version. Start the project and import the database from your export.","title":"Database container fails to start"},{"location":"users/basics/troubleshooting/#web-service-unhealthy-or-web-service-starting-or-exited","text":"Use ddev logs to see what's wrong. The most common cause of the web container being unhealthy is a user-defined .ddev/nginx-full/nginx-site.conf or .ddev/apache/apache-site.conf - Please rename these to during testing. To figure out what's wrong with it after you've identified that as the problem, use ddev logs and review the error. Changes to .ddev/nginx-site.conf and .ddev/apache/apache-site.conf take effect only when you do a ddev restart or the equivalent.","title":"\"web service unhealthy\" or \"web service starting\" or exited"},{"location":"users/basics/troubleshooting/#no-input-file-specified-404-or-forbidden-403","text":"If you get a 404 with \"No input file specified\" (nginx) or a 403 with \"Forbidden\" (apache) when you visit your project it usually means that no index.php or index.html is being found in the docroot. This can result from: Misconfigured docroot: If the docroot isn't where the webserver thinks it is, then the webserver won't find the index.php. Look at your .ddev/config.yaml to verify it has a docroot that will lead to the index.php. It should be a relative path from the project root to the directory where the index.php is. Missing index.php: There may not be an index.php or index.html in your project.","title":"No input file specified (404) or Forbidden (403)"},{"location":"users/basics/troubleshooting/#ddev-start-fails-and-logs-contain-failed-28-no-space-left-on-device-docker-file-space","text":"If ddev start fails, it's most often because the web container or db container fails to start. In this case the error message from ddev start says something like \"Failed to start : db container failed: log=, err=container exited, please use 'ddev logs -s db' to find out why it failed\". You can ddev logs -s db to find out what happened. If you see any variant of \"no space left on device\" in the logs when using Docker Desktop, it means that you have to increase or clean up Docker's file space. To increase the allocated space, go to \"Resources\" in Docker's Preferences as shown in If you see \"no space left on device\" on Linux, it most likely means your filesystem is full.","title":"ddev start fails and logs contain \"failed (28: No space left on device)\" - Docker File Space"},{"location":"users/basics/troubleshooting/#ddev-start-fails-with-container-failed-to-become-ready","text":"If a container fails to become ready, it means it's failing the healthcheck. This can happen to any of the containers, but you can usually find out quickly what the issue is with a docker inspect command. You may need to install jq for these, brew install jq , or just remove the \"| jq\" from the command and read the raw json output. For the web container, docker inspect --format \"{{json .State.Health }}\" ddev-<projectname>-web | jq For ddev-router, docker inspect --format \"{{json .State.Health }}\" ddev-router For ddev-ssh-agent, docker inspect --format \"{{json .State.Health }}\" ddev-ssh-agent Don't forget that ddev logs (for the web container) or ddev logs -s db (for the db container) are your friend. For ddev-router and ddev-ssh-agent, docker logs ddev-router and docker logs ddev-ssh-agent . Run ddev debug router-nginx-config to print the Nginx configuration of the currently running ddev-router.","title":"ddev start fails with \"container failed to become ready\""},{"location":"users/basics/troubleshooting/#ddev-start-fails-with-failed-to-start-project-name-no-such-container-ddev-router","text":"Deleting the images and re-pulling them generally solves this problem. Try running the following commands from the host machine. ddev poweroff docker rm -f $(docker ps -aq) docker rmi -f $(docker images -q) You should then be able to start your ddev machine.","title":"ddev start fails with \"Failed to start [project name]: No such container: ddev-router\""},{"location":"users/basics/troubleshooting/#trouble-building-dockerfiles","text":"The additional .ddev/web-build/Dockerfile capability in ddev is wonderful, but it can be hard to figure out what to put in there. The best approach for any significant Dockerfile is to ddev ssh and sudo -s and then one at a time, do the things that you plan to do with a RUN command in the Dockerfile. For example, if your Dockerfile were RUN npm install --global forever You could test it with ddev ssh , sudo -s and then npm install --global forever The error messages you get will be more informative than messages that come when the Dockerfile is processed. You can also see the full Docker build using ~/.ddev/bin/docker-compose -f .ddev/.ddev-docker-compose-full.yaml build --no-cache --progress=plain .","title":"Trouble Building Dockerfiles"},{"location":"users/basics/troubleshooting/#ddev-starts-fine-but-my-browser-cant-access-the-url-server-ip-address-could-not-be-found-or-we-cant-connect-to-the-server-at","text":"Most people use *.ddev.site URLs for most projects, and that works great most of the time, but requires internet access. \"*.ddev.site\" is a wildcard DNS entry that always returns the IP address 127.0.0.1 (localhost). However, if you're not connected to the internet, or if various other name resolution issues (below) fail, this name resolution won't work. While ddev can create a webserver and a docker network infrastructure for a project, it doesn't have control of your computer's name resolution, so its backup technique to make a hostname resolvable by the browser is to add an entry to the hosts file (/etc/hosts on Linux and macOS, C:\\Windows\\system32\\drivers\\etc\\hosts on traditional Windows). If you're not connected to the internet, your browser will not be able to look up *.ddev.site hostnames. DDEV works fine offline, but for your browser to look up names they'll have to be resolved in a different way. DDEV assumes that hostnames can be resolved within 3 seconds. That assumption is not valid on all networks or computers, so you can increase the amount of time it waits for resolution with ddev config global --internet-detection-timeout-ms=5000 for example. If DDEV detects that it can't look up one of the hostnames assigned to your project for that or other reasons, it will try to add that to the hosts file on your computer, but of course that requires administrative privileges (sudo or Windows UAC) This technique may not work on Windows WSL2, see below. Only 10 hosts are valid on a line on traditional Windows, see below ; beyond that hostnames are ignored.","title":"Ddev starts fine, but my browser can't access the URL \" server IP address could not be found\" or \"We can\u2019t connect to the server at \""},{"location":"users/basics/troubleshooting/#windows-wsl2-name-resolution-on-non-ddevsite-hostnames-or-when-not-internet-connected","text":"On Windows WSL2, there is a hosts file inside the WSL2 instance ( /etc/hosts ), and there is also one on the Windows side ( C:\\Windows\\system32\\drivers\\etc\\hosts ). Many people use a browser on the Windows side, which has no idea about hostnames that may be set up in the WSL2 /etc/hosts file. So a WSL2 project which uses *.ddev.site works fine when accessed by a browser on the Windows side, as long as internet connectivity is available (DNS lookups of *.ddev.site succeed). However, if the project uses non-ddev.site hostnames, or if not connected to the Internet, or if use_dns_when_possible is false in the .ddev/config.yaml, a Windows-side browser will be unable to look up project hostnames, and you'll get complaints from the browser like \" server IP address could not be found\" or \"We can\u2019t connect to the server at \". In this case, you can: Add the needed hostname(s) manually to the Windows hosts file. This can easily be done with the Windows version of ddev.exe with sudo ddev hostname <hostname> 127.0.0.1 on Windows in PowerShell or Cmd or git-bash. Or run a browser within WSL2. On Windows 11 this is built-in, but in Windows 10 may require an X11 server like X410.","title":"Windows WSL2 name resolution on non-ddev.site hostnames or when not internet-connected"},{"location":"users/basics/troubleshooting/#dns-rebinding-prohibited","text":"Some DNS servers prevent the use of DNS records that resolve to localhost (127.0.0.1) because in uncontrolled environments this may be used as a form of attack called DNS Rebinding . Since *.ddev.site resolves to 127.0.0.1, they may refuse to resolve, and your browser may be unable to look up a hostname, and give you messages like \" server IP address could not be found\" or \"We can\u2019t connect to the server at \". In this case, you can Reconfigure the DNS server to allow DNS Rebinding. Many Fritzbox routers have added default DNS Rebinding disallowal, and they can be reconfigured to allow it, see issue . If you have the local dnsmasq DNS server it may also be configured to disallow DNS rebinding, but it's a simple change to a configuration directive to allow it. Most computers can use most relaxed DNS resolution if they are not on corporate intranets that have non-internet DNS. So for example, the computer can be set to use 8.8.8.8 (Google) or 1.1.1.1 (Cloudflare) for DNS name resolution. If you have control of the router, you can usually change its DHCP settings to choose a DNS server to a public, relaxed DNS server as in #2 . You can live with ddev trying to edit the /etc/hosts file, which it only has to do when a new name is added to a project.","title":"DNS Rebinding Prohibited"},{"location":"users/basics/troubleshooting/#windows-hosts-file-limited-to-10-hosts-per-ip-address-line","text":"On Windows only, there is a limit to the number of hosts that can be placed in one line. But since all ddev hosts are typically on the same IP address (typically 127.0.0.1, localhost), they can really add up. As soon as you have more than 10 entries there, your browser won't be able to resolve the addresses beyond the 10 th entry. There are two workarounds for this problem: Use ddev stop --all and sudo ddev hostname --remove-inactive to prune the number of hosts on that hosts-file line. When you start a project, the hostname(s) associated with that project will be added back again. Manually edit the hosts file (typically C:\\Windows\\System32\\drivers\\etc\\hosts ) and put some of your hosts on a separate line in the file.","title":"Windows Hosts File limited to 10 hosts per IP address line"},{"location":"users/basics/troubleshooting/#windows-wsl2-network-issues","text":"If you're using a browser on Windows, accessing a project in WSL2, you can end up with very confusing results if your project is listening on a port inside WSL2, but a Windows process is listening on the port on Windows. The way to sort this out is to stop your project inside WSL2, verify that nothing is listening on the port there, and then study the port on the Windows side, by visiting it with a browser or using other tools as described above.","title":"Windows WSL2 Network Issues"},{"location":"users/basics/troubleshooting/#limitations-on-symbolic-links-symlinks","text":"Symbolic links are widely used but have specific limitations in many environments, not just in DDEV. Here are some of the ways those may affect you: Crossing mount boundaries : Symlinks may not generally cross between network mounts. In other words, if you have a relative symlink in the root of your project directory on the host that points to ../somefile.txt , that symlink will not be valid inside the container where ../ is a completely different filesystem (and is not mounted typically). Symlinks to absolute paths : If you have an absolute symlink to something like /Users/xxx/somefile.txt on the host, it will not be resolvable inside the container because /Users is not mounted there. Note that some tools, especially on Magento 2, may create symlinks to rooted paths, with targets like /var/www/html/path/to/something . These basically can't make it to the host, so may create errors. Windows restrictions on symlinks : Inside the Docker container on Windows you may not be able to even create a symlink that goes outside the container. Mutagen restrictions on Windows symlinks : On macOS and Linux (including WSL2) the default .ddev/mutagen/mutagen.yml chooses the posix-raw type of symlink handling (See mutagen docs ). This basically means that any symlink created will try to sync, regardless of whether it's valid in the other environment. However, Mutagen does not support posix-raw on traditional Windows, so ddev uses the portable symlink mode. So on Windows with Mutagen... symlinks have to be strictly limited to relative links that are inside the mutagen section of the project.","title":"Limitations on Symbolic Links (symlinks)"},{"location":"users/basics/troubleshooting/#delete-and-re-download-docker-images","text":"In just a few unusual cases, the actual downloaded docker images have somehow corrupted. In that case we can delete all images and they'll be re-downloaded or rebuilt. This does no harm, as everything is just rebuilt, but a ddev start make take extra time the first time while it downloads needed resources: ddev poweroff docker rm -f $( docker ps -aq ) # stop any other random containers that may be running docker rmi -f $( docker images -q ) # You might have to repeat this a time or two to get rid of all images","title":"Delete and re-download docker images"},{"location":"users/basics/uninstall/","text":"Uninstalling DDEV \u00b6 A DDEV-Local installation consists of: The binary itself (self-contained) The .ddev folder in a project The ~/.ddev folder where various global items are stored. The docker images and containers created. Any entries in /etc/hosts Please make backups of your databases before deleting projects or uninstalling. You can do this with ddev snapshot or ddev export-db . You can use ddev clean to uninstall the vast majority of things DDEV has touched. For example, ddev clean <project> or ddev clean --all . To uninstall just a project: ddev delete <project> . This removes any hostnames in /etc/hosts and removes your database. If you don't want it to make a database backup/snapshot on the way down: ddev delete --omit-snapshot <project> To remove all /etc/hosts entries owned by ddev: ddev hostname --remove-inactive To remove the global .ddev directory: rm -r ~/.ddev If you installed docker just for ddev and want to uninstall it with all containers and images, just uninstall it for your version of Docker. Otherwise: Remove Docker images from before the current ddev release with ddev delete images . To remove all ddev docker containers that might still exist: docker rm $(docker ps -a | awk '/ddev/ { print $1 }') To remove all ddev docker images that might exist: docker rmi $(docker images | awk '/ddev/ {print $3}') To remove all Docker images of any type (does no harm, they'll just be re-downloaded): docker rmi -f $(docker images -q) To remove any docker volumes: docker volume rm $(docker volume ls | awk '/ddev|-mariadb/ { print $2 }') To remove the ddev binary: On macOS or Linux with Homebrew, brew uninstall ddev For linux or other simple installs, just remove the binary, for example sudo rm /usr/local/bin/ddev On Windows (if you used the ddev Windows installer) use the uninstall on the start menu or in the \"Add or Remove Programs\" section of Windows settings.","title":"Uninstalling DDEV"},{"location":"users/basics/uninstall/#uninstalling-ddev","text":"A DDEV-Local installation consists of: The binary itself (self-contained) The .ddev folder in a project The ~/.ddev folder where various global items are stored. The docker images and containers created. Any entries in /etc/hosts Please make backups of your databases before deleting projects or uninstalling. You can do this with ddev snapshot or ddev export-db . You can use ddev clean to uninstall the vast majority of things DDEV has touched. For example, ddev clean <project> or ddev clean --all . To uninstall just a project: ddev delete <project> . This removes any hostnames in /etc/hosts and removes your database. If you don't want it to make a database backup/snapshot on the way down: ddev delete --omit-snapshot <project> To remove all /etc/hosts entries owned by ddev: ddev hostname --remove-inactive To remove the global .ddev directory: rm -r ~/.ddev If you installed docker just for ddev and want to uninstall it with all containers and images, just uninstall it for your version of Docker. Otherwise: Remove Docker images from before the current ddev release with ddev delete images . To remove all ddev docker containers that might still exist: docker rm $(docker ps -a | awk '/ddev/ { print $1 }') To remove all ddev docker images that might exist: docker rmi $(docker images | awk '/ddev/ {print $3}') To remove all Docker images of any type (does no harm, they'll just be re-downloaded): docker rmi -f $(docker images -q) To remove any docker volumes: docker volume rm $(docker volume ls | awk '/ddev|-mariadb/ { print $2 }') To remove the ddev binary: On macOS or Linux with Homebrew, brew uninstall ddev For linux or other simple installs, just remove the binary, for example sudo rm /usr/local/bin/ddev On Windows (if you used the ddev Windows installer) use the uninstall on the start menu or in the \"Add or Remove Programs\" section of Windows settings.","title":"Uninstalling DDEV"},{"location":"users/configuration/config_yaml/","text":".ddev/config.yaml options \u00b6 Each project has a (hidden) directory named .ddev, and the .ddev/config.yaml is the primary configuration for the project. You can override the config.yaml with extra files named \"config.*.yaml\". For example, many teams use config.local.yaml for configuration that is specific to one environment, and that is not intended to be checked into the team's default config.yaml. Most configuration options take effect on ddev start Nearly all configuration options have equivalent ddev config flags, so you can use ddev config instead of editing the config.yaml. See ddev help config to see all the flags. Item Description Notes name Project name Must be unique on the host (no two projects can have the same name). It's best if this is the same as the directory name. type Project type php/drupal6/drupal7/drupal8/backdrop/typo3wordpress. Project type \"php\" does not try to do any CMS configuration or settings file management, and can work with any project docroot Relative path to the docroot (where index.php or index.html is) from the project root php_version 5.6/7.0/7.1/7.2/7.3/7.4/8.0 It is only possible to provide the major version (like \"7.3\"), not a minor version like \"7.3.2\", and it is only possible to use the provided php versions. webimage docker image to use for webserver It is unusual to change the default and is not recommended, but the webimage can be overridden with a correctly crafted image, probably derived from drud/ddev-webserver database type and version of database to be used Defaults to mariadb:10.3, but mariadb 5.5 through 10.7. MySQL 5.5 through 8.0, and Postgres 9-14 are available. See Database Server Types for details and caveats. Older usages (v1.18 and earlier) mariadb_version and mysql_version served this purpose, but they will now be automatically converted to the database format. router_http_port Port used by the router for http Defaults to port 80. This can be changed if there is a conflict on the host over port 80 router_https_port Port used by the router for https Defaults to 443, usually only changed if there is a conflicting process using port 443 xdebug_enabled \"true\" enables xdebug Most people use ddev xdebug and ddev xdebug off instead of configuring this, because xdebug has a significant performance impact. webserver_type nginx-fpm or apache-fpm The default is nginx-fpm, and it works best for many projects. timezone timezone to use in container and in PHP configuration It can be set to any valid timezone, see timezone list . For example \"Europe/Dublin\" or \"MST7MDT\". The default is UTC. composer_root Relative path to the composer root directory from the project root This is the directory which contains the composer.json and where all Composer related commands are executed. composer_version version of composer to use in web container and ddev composer It defaults to composer v2; you can set it to \"\" or \"2\" (default) for composer v2 or \"1\" for composer v1 to use the latest major.minor.patch versions available at the time your currently installed ddev version was bundled and released. Note that the bundled default version might be behind the latest available composer release. Alternatively, an explicit composer version may be specified, for example composer_version: 1.0.22 . nodejs_version version of nodejs to use in web container as \"system\" version It defaults to current LTS version; you can currently set it to \"12\", \"14\", \"16\", \"17\", \"18\". Note that nvm is also available inside the container and via ddev nvm and can be set to any valid version including very old versions. additional_hostnames array of extra hostnames additional_hostnames: [\"somename\", \"someothername\", \"*.thirdname\"] would provide http and https URLs for somename.ddev.site and someothername.ddev.site , as well as \" one.thirdname.ddev.site and two.thirdname.ddev.site . Note that the wildcard/asterisk setting only works if you're using DNS to resolve hostnames (which is the default) and you're connected to the internet. additional_fqdns extra fully-qualified domain names additional_fqdns: [\"example.com\", \"sub1.example.com\"] would provide http and https URLs for example.com and sub1.example.com . Please take care with this because it can cause great confusion and adds extraneous items to your /etc/hosts file. upload_dir Path from <docroot> to the upload directory used as a target by ddev import-files working_dir explicitly specify the working directory used by ddev exec and ddev ssh working_dir: { web: \"/var/www\", db: \"/etc\" } would set the working directories for the web and db containers. omit_containers Allows the project to not load specified containers For example, omit_containers: [db, dba, ddev-ssh-agent] . Currently only these containers are supported. Some containers can also be omitted globally in the ~/.ddev/global_config.yaml and the result is additive; all containers named in both places will be omitted. Note that if you omit the \"db\" container, several standard features of ddev that access the database container will be unusable. web_environment Set the DDEV-provided environment variables in the web container For example, web_environment: [\"SOMEENV=someval\", \"SOMEOTHERENV=someotherval\"] . nfs_mount_enabled Allows using NFS to mount the project into the container for performance reasons See nfs_mount_enabled documentation . This requires configuration on the host before it can be used. Note that project-level configuration of nfs_mount_enabled is unusual, and that if it's true in the global config, that overrides the project-specific nfs_mount_enabled fail_on_hook_fail Decide whether ddev start should be interrupted by a failing hook host_https_port Specify a specific and persistent https port for direct binding to the localhost interface This is not commonly used, but a specific port can be provided here and the https URL will always remain the same. For example, if you put \"59001\", the project will always use https://127.0.0.1:59001\" for the localhost URL. (Note that the named URL is more commonly used and for most purposes is better.) If this is not set the port will change from ddev start to ddev start host_webserver_port Specify a specific and persistent http port for direct binding to the localhost interface This is not commonly used, but a specific port can be provided here and the https URL will always remain the same. For example, if you put \"59000\", the project will always use \" http://127.0.0.1:59000\". for the localhost URL. (Note that the named URL is more commonly used and for most purposes is better.) If this is not set the port will change from ddev start to ddev start host_db_port localhost binding port for database server If specified here, the database port will remain consistent. This is useful for configuration of host-side database browsers. Note, though, that ddev mysql , ddev psql , and ddev sequelpro do all this automatically, as does the sample command ddev mysqlworkbench . phpmyadmin_port port used for phpMyAdmin URL This is sometimes changed from the default 8036 when a port conflict is discovered phpmyadmin_https_ port port used for phpMyAdmin URL (https) This is sometimes changed from the default 8037 when a port conflict is discovered mailhog_port port used in MailHog URL this can be changed from the default 8025 in case of port conflicts mailhog_https_port port used in MailHog URL this can be changed from the default 8026 in case of port conflicts webimage_extra_ packages Add extra Debian packages to the ddev-webserver. For example, webimage_extra_packages: [php-yaml, php-bcmath] will add those two packages dbimage_extra_ packages Add extra Debian packages to the ddev-dbserver. For example, dbimage_extra_packages: [\"less\"] will add those that package. use_dns_when_ possible defaults to true (using DNS instead of editing /etc/hosts) If set to false, ddev will always update the /etc/hosts file with the project hostname instead of using DNS for name resolution project_tld defaults to \"ddev.site\" so project urls become someproject.ddev.site This can be changed to anything that works for you; to keep things the way they were before ddev v1.9, use \"ddev.local\" ngrok_args Extra flags for ngrok when using the ddev share command For example, --basic-auth username:pass1234 . See ngrok docs disable_settings_ management defaults to false If true, ddev will not create or update CMS-specific settings files hooks See hooks for more information. no_project_mount Skip mounting the project into the web container If true, the project will not be mounted by ddev into the web container. This is to enable experimentation with alternate file mounting strategies. Advanced users only! default_container_timeout Can adjust the time in seconds that DDEV will wait for all containers to become ready Normally this does not need to be changed, but for restoring huge snapshots it may be useful. global_config.yaml Options \u00b6 The $HOME/.ddev/global_config.yaml has a few key global config options. Item Description Notes nfs_mount_enabled Enables NFS mounting globally for all projects Only a \"true\" value has any effect. If true, NFS will be used on all projects, regardless of any settings in the individual projects. mutagen_enabled Enables Mutagen asynchronous caching globally for all projects If true, Mutagen will be used on all projects, and this overrides NFS mounting as it's incompatible with NFS. table-style Set the style for ddev list and ddev describe Options are \"default\", \"bold\", and \"bright\". \"bright\" is a pleasant colored output that some people will like. simple-formatting If true, turns off most table formatting in ddev list and ddev describe This tries to give plain vanilla output for list and describe, and also suppresses colorized text everywhere. fail_on_hook_fail Enables ddev start interruption globally for all projects when a hook fails Decide whether ddev start should be interrupted by a failing hook omit_containers Allows the project to not load specified containers For example, omit_containers: [ \"dba\", \"ddev-ssh-agent\"] . Currently only these containers are supported. Note that you cannot omit the \"db\" container in the global configuration, but you can in the per-project .ddev/config.yaml. web_environment Set the DDEV-provided variables in the web container For example, web_environment: [\"SOMEENV=someval\", \"SOMEOTHERENV=someotherval\"] . instrumentation_opt_in Opt in or out of instrumentation reporting If true, anonymous usage information is sent to ddev via segment router_bind_all_interfaces Bind on all network interfaces If true, ddev-router will bind on all network interfaces instead of just localhost, exposing ddev projects to your local network. If you set this to true, you may consider omit_containers: [\"dba\"] so that the phpMyAdmin port is not available. disable_http2 Disable http/2 listen in ddev-router If true, nginx will not listen for http/2, but just use http/1.1 ssl. There are some browsers which don't work well with http/2. internet_detection_timeout_ms Internet detection timeout ddev must detect whether the internet is working to determine whether to add hostnames to /etc/hosts. It uses a DNS query and times it out by default at 750ms. In rare cases you may need to increase this value if you have slow but working internet. See FAQ and issue link . use_hardened_images If true, use more secure 'hardened' images for an actual internet deployment The most important thing about hardened images is that sudo is not included in the web container, and the container is run without elevated privileges. This is generally used with experimental casual hosting feature. use_letsencrypt If true, enables experimental Let's Encrypt integration 'ddev global --use-letsencrypt' or `ddev global --use-letsencrypt=false'. This requires letsencrypt_email to be set, and can't work if the system is not available on the internet. Used with experimental casual hosting feature. letsencrypt_email Email associated with Let's Encrypt for experimental Let's Encrypt feature Set with`ddev global --letsencrypt-email= me@example.com '. Used with experimental casual hosting feature. developer_mode Set developer mode If true, developer_mode is set. This is not currently used. required_docker_compose_version Specify an alternate docker-compose version for download If set to v1.29.2 , for example, it will download and use that version instead of the expected version for docker-compose. use_docker_compose_from_path Use the system-installed docker-compose If this is true, then DDEV will use the docker-compose found in on your system's path instead of using its private known-good docker-compose version. no_bind_mounts Do not use docker bind mounts Some docker environments (like remote docker) do not allow bind mounts, so this option turns off those and turns on mutagen and uses volume copies to do what bind mounts would otherwise do.","title":".ddev/config.yaml options"},{"location":"users/configuration/config_yaml/#ddevconfigyaml-options","text":"Each project has a (hidden) directory named .ddev, and the .ddev/config.yaml is the primary configuration for the project. You can override the config.yaml with extra files named \"config.*.yaml\". For example, many teams use config.local.yaml for configuration that is specific to one environment, and that is not intended to be checked into the team's default config.yaml. Most configuration options take effect on ddev start Nearly all configuration options have equivalent ddev config flags, so you can use ddev config instead of editing the config.yaml. See ddev help config to see all the flags. Item Description Notes name Project name Must be unique on the host (no two projects can have the same name). It's best if this is the same as the directory name. type Project type php/drupal6/drupal7/drupal8/backdrop/typo3wordpress. Project type \"php\" does not try to do any CMS configuration or settings file management, and can work with any project docroot Relative path to the docroot (where index.php or index.html is) from the project root php_version 5.6/7.0/7.1/7.2/7.3/7.4/8.0 It is only possible to provide the major version (like \"7.3\"), not a minor version like \"7.3.2\", and it is only possible to use the provided php versions. webimage docker image to use for webserver It is unusual to change the default and is not recommended, but the webimage can be overridden with a correctly crafted image, probably derived from drud/ddev-webserver database type and version of database to be used Defaults to mariadb:10.3, but mariadb 5.5 through 10.7. MySQL 5.5 through 8.0, and Postgres 9-14 are available. See Database Server Types for details and caveats. Older usages (v1.18 and earlier) mariadb_version and mysql_version served this purpose, but they will now be automatically converted to the database format. router_http_port Port used by the router for http Defaults to port 80. This can be changed if there is a conflict on the host over port 80 router_https_port Port used by the router for https Defaults to 443, usually only changed if there is a conflicting process using port 443 xdebug_enabled \"true\" enables xdebug Most people use ddev xdebug and ddev xdebug off instead of configuring this, because xdebug has a significant performance impact. webserver_type nginx-fpm or apache-fpm The default is nginx-fpm, and it works best for many projects. timezone timezone to use in container and in PHP configuration It can be set to any valid timezone, see timezone list . For example \"Europe/Dublin\" or \"MST7MDT\". The default is UTC. composer_root Relative path to the composer root directory from the project root This is the directory which contains the composer.json and where all Composer related commands are executed. composer_version version of composer to use in web container and ddev composer It defaults to composer v2; you can set it to \"\" or \"2\" (default) for composer v2 or \"1\" for composer v1 to use the latest major.minor.patch versions available at the time your currently installed ddev version was bundled and released. Note that the bundled default version might be behind the latest available composer release. Alternatively, an explicit composer version may be specified, for example composer_version: 1.0.22 . nodejs_version version of nodejs to use in web container as \"system\" version It defaults to current LTS version; you can currently set it to \"12\", \"14\", \"16\", \"17\", \"18\". Note that nvm is also available inside the container and via ddev nvm and can be set to any valid version including very old versions. additional_hostnames array of extra hostnames additional_hostnames: [\"somename\", \"someothername\", \"*.thirdname\"] would provide http and https URLs for somename.ddev.site and someothername.ddev.site , as well as \" one.thirdname.ddev.site and two.thirdname.ddev.site . Note that the wildcard/asterisk setting only works if you're using DNS to resolve hostnames (which is the default) and you're connected to the internet. additional_fqdns extra fully-qualified domain names additional_fqdns: [\"example.com\", \"sub1.example.com\"] would provide http and https URLs for example.com and sub1.example.com . Please take care with this because it can cause great confusion and adds extraneous items to your /etc/hosts file. upload_dir Path from <docroot> to the upload directory used as a target by ddev import-files working_dir explicitly specify the working directory used by ddev exec and ddev ssh working_dir: { web: \"/var/www\", db: \"/etc\" } would set the working directories for the web and db containers. omit_containers Allows the project to not load specified containers For example, omit_containers: [db, dba, ddev-ssh-agent] . Currently only these containers are supported. Some containers can also be omitted globally in the ~/.ddev/global_config.yaml and the result is additive; all containers named in both places will be omitted. Note that if you omit the \"db\" container, several standard features of ddev that access the database container will be unusable. web_environment Set the DDEV-provided environment variables in the web container For example, web_environment: [\"SOMEENV=someval\", \"SOMEOTHERENV=someotherval\"] . nfs_mount_enabled Allows using NFS to mount the project into the container for performance reasons See nfs_mount_enabled documentation . This requires configuration on the host before it can be used. Note that project-level configuration of nfs_mount_enabled is unusual, and that if it's true in the global config, that overrides the project-specific nfs_mount_enabled fail_on_hook_fail Decide whether ddev start should be interrupted by a failing hook host_https_port Specify a specific and persistent https port for direct binding to the localhost interface This is not commonly used, but a specific port can be provided here and the https URL will always remain the same. For example, if you put \"59001\", the project will always use https://127.0.0.1:59001\" for the localhost URL. (Note that the named URL is more commonly used and for most purposes is better.) If this is not set the port will change from ddev start to ddev start host_webserver_port Specify a specific and persistent http port for direct binding to the localhost interface This is not commonly used, but a specific port can be provided here and the https URL will always remain the same. For example, if you put \"59000\", the project will always use \" http://127.0.0.1:59000\". for the localhost URL. (Note that the named URL is more commonly used and for most purposes is better.) If this is not set the port will change from ddev start to ddev start host_db_port localhost binding port for database server If specified here, the database port will remain consistent. This is useful for configuration of host-side database browsers. Note, though, that ddev mysql , ddev psql , and ddev sequelpro do all this automatically, as does the sample command ddev mysqlworkbench . phpmyadmin_port port used for phpMyAdmin URL This is sometimes changed from the default 8036 when a port conflict is discovered phpmyadmin_https_ port port used for phpMyAdmin URL (https) This is sometimes changed from the default 8037 when a port conflict is discovered mailhog_port port used in MailHog URL this can be changed from the default 8025 in case of port conflicts mailhog_https_port port used in MailHog URL this can be changed from the default 8026 in case of port conflicts webimage_extra_ packages Add extra Debian packages to the ddev-webserver. For example, webimage_extra_packages: [php-yaml, php-bcmath] will add those two packages dbimage_extra_ packages Add extra Debian packages to the ddev-dbserver. For example, dbimage_extra_packages: [\"less\"] will add those that package. use_dns_when_ possible defaults to true (using DNS instead of editing /etc/hosts) If set to false, ddev will always update the /etc/hosts file with the project hostname instead of using DNS for name resolution project_tld defaults to \"ddev.site\" so project urls become someproject.ddev.site This can be changed to anything that works for you; to keep things the way they were before ddev v1.9, use \"ddev.local\" ngrok_args Extra flags for ngrok when using the ddev share command For example, --basic-auth username:pass1234 . See ngrok docs disable_settings_ management defaults to false If true, ddev will not create or update CMS-specific settings files hooks See hooks for more information. no_project_mount Skip mounting the project into the web container If true, the project will not be mounted by ddev into the web container. This is to enable experimentation with alternate file mounting strategies. Advanced users only! default_container_timeout Can adjust the time in seconds that DDEV will wait for all containers to become ready Normally this does not need to be changed, but for restoring huge snapshots it may be useful.","title":".ddev/config.yaml options"},{"location":"users/configuration/config_yaml/#global_configyaml-options","text":"The $HOME/.ddev/global_config.yaml has a few key global config options. Item Description Notes nfs_mount_enabled Enables NFS mounting globally for all projects Only a \"true\" value has any effect. If true, NFS will be used on all projects, regardless of any settings in the individual projects. mutagen_enabled Enables Mutagen asynchronous caching globally for all projects If true, Mutagen will be used on all projects, and this overrides NFS mounting as it's incompatible with NFS. table-style Set the style for ddev list and ddev describe Options are \"default\", \"bold\", and \"bright\". \"bright\" is a pleasant colored output that some people will like. simple-formatting If true, turns off most table formatting in ddev list and ddev describe This tries to give plain vanilla output for list and describe, and also suppresses colorized text everywhere. fail_on_hook_fail Enables ddev start interruption globally for all projects when a hook fails Decide whether ddev start should be interrupted by a failing hook omit_containers Allows the project to not load specified containers For example, omit_containers: [ \"dba\", \"ddev-ssh-agent\"] . Currently only these containers are supported. Note that you cannot omit the \"db\" container in the global configuration, but you can in the per-project .ddev/config.yaml. web_environment Set the DDEV-provided variables in the web container For example, web_environment: [\"SOMEENV=someval\", \"SOMEOTHERENV=someotherval\"] . instrumentation_opt_in Opt in or out of instrumentation reporting If true, anonymous usage information is sent to ddev via segment router_bind_all_interfaces Bind on all network interfaces If true, ddev-router will bind on all network interfaces instead of just localhost, exposing ddev projects to your local network. If you set this to true, you may consider omit_containers: [\"dba\"] so that the phpMyAdmin port is not available. disable_http2 Disable http/2 listen in ddev-router If true, nginx will not listen for http/2, but just use http/1.1 ssl. There are some browsers which don't work well with http/2. internet_detection_timeout_ms Internet detection timeout ddev must detect whether the internet is working to determine whether to add hostnames to /etc/hosts. It uses a DNS query and times it out by default at 750ms. In rare cases you may need to increase this value if you have slow but working internet. See FAQ and issue link . use_hardened_images If true, use more secure 'hardened' images for an actual internet deployment The most important thing about hardened images is that sudo is not included in the web container, and the container is run without elevated privileges. This is generally used with experimental casual hosting feature. use_letsencrypt If true, enables experimental Let's Encrypt integration 'ddev global --use-letsencrypt' or `ddev global --use-letsencrypt=false'. This requires letsencrypt_email to be set, and can't work if the system is not available on the internet. Used with experimental casual hosting feature. letsencrypt_email Email associated with Let's Encrypt for experimental Let's Encrypt feature Set with`ddev global --letsencrypt-email= me@example.com '. Used with experimental casual hosting feature. developer_mode Set developer mode If true, developer_mode is set. This is not currently used. required_docker_compose_version Specify an alternate docker-compose version for download If set to v1.29.2 , for example, it will download and use that version instead of the expected version for docker-compose. use_docker_compose_from_path Use the system-installed docker-compose If this is true, then DDEV will use the docker-compose found in on your system's path instead of using its private known-good docker-compose version. no_bind_mounts Do not use docker bind mounts Some docker environments (like remote docker) do not allow bind mounts, so this option turns off those and turns on mutagen and uses volume copies to do what bind mounts would otherwise do.","title":"global_config.yaml Options"},{"location":"users/configuration/experimental/","text":"Experimental Docker Configurations \u00b6 Remote Docker Instances \u00b6 You can use remote docker instances, whether on the internet or inside your network or running in a virtual machine. On the remote machine, the docker port must be exposed if it is not exposed already. See instructions for how to do this on a systemd-based remote server. Be aware that this has serious security implications and must not be done without taking those into consideration. . In fact, dockerd will complain Binding to IP address without --tlsverify is insecure and gives root access on this machine to everyone who has access to your network. host=\"tcp://0.0.0.0:2375\". If you do not have the docker client installed another way (like from Docker Desktop) then install it with brew install docker to get just the client. Create a docker context that points to the remote docker instance. For example, if the remote hostname is debian-11 then docker context create debian-11 --docker host=tcp://debian-11:2375 && docker use debian-11 . Alternately, you can use the DOCKER_HOST environment variable, for example export DOCKER_HOST=tcp://debian-11:2375 . Make sure you can access the remote machine using docker ps . Bind-mounts cannot work on a remote docker setup, so you must use ddev config global --no-bind-mounts . This will cause ddev to push needed information to and from the remote docker instance when needed. This also automatically turns on mutagen caching. You may want to use a FQDN other than *.ddev.site because the ddev site will not be at 127.0.0.1 . For example, ddev config --fqdns=debian-11 and then use https://debian-11 to access the site. If the docker host is reachable on the internet, you can actually enable real https for it using Let's Encrypt as described in Casual Webhosting . Just make sure that port 2375 is not available on the internet. Rancher Desktop on macOS \u00b6 Rancher Desktop is another Docker Desktop alternative that is quickly maturing for macOS. You can install it for many target platforms from the release page . Rancher desktop integration currently has no automated testing for DDEV integration. By default, Rancher desktop will provide a version of the docker client if you do not have one on your machine. Rancher changes over the \"default\" context in docker, so you'll want to turn off Docker Desktop if you're using it. Rancher Desktop does not provide bind mounts, so use ddev config global --no-bind-mounts which also turns on mutagen. Use a non- ddev.site name, ddev config --additional-fqdns=rancher for example, because the resolution of *.ddev.site seems to make it not work. Rancher Desktop does not seem to currently work with mkcert and https , so turn those off with mkcert -uninstall && rm -r \"$(mkcert -CAROOT)\" . This does no harm and can be undone with just mkcert -install again.","title":"Experimental Docker Configurations"},{"location":"users/configuration/experimental/#experimental-docker-configurations","text":"","title":"Experimental Docker Configurations"},{"location":"users/configuration/experimental/#remote-docker-instances","text":"You can use remote docker instances, whether on the internet or inside your network or running in a virtual machine. On the remote machine, the docker port must be exposed if it is not exposed already. See instructions for how to do this on a systemd-based remote server. Be aware that this has serious security implications and must not be done without taking those into consideration. . In fact, dockerd will complain Binding to IP address without --tlsverify is insecure and gives root access on this machine to everyone who has access to your network. host=\"tcp://0.0.0.0:2375\". If you do not have the docker client installed another way (like from Docker Desktop) then install it with brew install docker to get just the client. Create a docker context that points to the remote docker instance. For example, if the remote hostname is debian-11 then docker context create debian-11 --docker host=tcp://debian-11:2375 && docker use debian-11 . Alternately, you can use the DOCKER_HOST environment variable, for example export DOCKER_HOST=tcp://debian-11:2375 . Make sure you can access the remote machine using docker ps . Bind-mounts cannot work on a remote docker setup, so you must use ddev config global --no-bind-mounts . This will cause ddev to push needed information to and from the remote docker instance when needed. This also automatically turns on mutagen caching. You may want to use a FQDN other than *.ddev.site because the ddev site will not be at 127.0.0.1 . For example, ddev config --fqdns=debian-11 and then use https://debian-11 to access the site. If the docker host is reachable on the internet, you can actually enable real https for it using Let's Encrypt as described in Casual Webhosting . Just make sure that port 2375 is not available on the internet.","title":"Remote Docker Instances"},{"location":"users/configuration/experimental/#rancher-desktop-on-macos","text":"Rancher Desktop is another Docker Desktop alternative that is quickly maturing for macOS. You can install it for many target platforms from the release page . Rancher desktop integration currently has no automated testing for DDEV integration. By default, Rancher desktop will provide a version of the docker client if you do not have one on your machine. Rancher changes over the \"default\" context in docker, so you'll want to turn off Docker Desktop if you're using it. Rancher Desktop does not provide bind mounts, so use ddev config global --no-bind-mounts which also turns on mutagen. Use a non- ddev.site name, ddev config --additional-fqdns=rancher for example, because the resolution of *.ddev.site seems to make it not work. Rancher Desktop does not seem to currently work with mkcert and https , so turn those off with mkcert -uninstall && rm -r \"$(mkcert -CAROOT)\" . This does no harm and can be undone with just mkcert -install again.","title":"Rancher Desktop on macOS"},{"location":"users/configuration/hooks/","text":"Hooks \u00b6 Most ddev commands provide hooks to run tasks before or after the main command executes. To automate setup tasks specific to your project, define them in the project's config.yaml file. To define command tasks in your configuration, specify the desired command hook as a subfield to hooks , then provide a list of tasks to run. Example: hooks : post-start : - exec : \"simple command expression\" - exec : \"ls >/dev/null && touch /var/www/html/somefile.txt\" - exec-host : \"simple command expression\" post-import-db : - exec : \"drush uli\" Supported Command Hooks \u00b6 pre-start : Hooks into \"ddev start\". Execute tasks before the project environment starts. Note: Only exec-host tasks can be generally run successfully during pre-start. See Supported Tasks below for more info. post-start : Execute tasks after the project environment has started. pre-import-db and post-import-db : Execute tasks before or after database import. pre-import-files and post-import-files : Execute tasks before or after files are imported pre-composer and post-composer : Execute tasks before or after the composer command. pre-stop , pre-config , post-config , pre-exec , post-exec , pre-pause , post-pause , pre-pull , post-pull , pre-push , post-push , pre-snapshot , post-snapshot , pre-restore-snapshot , post-restore-snapshot : Execute as the name suggests. post-stop : Hooks into \"ddev stop\". Execute tasks after the project environment stopped. Note: Only exec-host tasks can be generally run successfully during post-stop. Supported Tasks \u00b6 ddev currently supports these tasks: exec to execute a command in any service/container exec-host to execute a command on the host composer to execute a composer command in the web container exec : Execute a shell command in a container (defaults to web container) \u00b6 Value: string providing the command to run. Commands requiring user interaction are not supported. You can also add a \"service\" key to the command, specifying to run it on the db container or any other container you use. Example: Use drush to clear the Drupal cache and get a user login link after database import hooks : post-import-db : - exec : drush cr - exec : drush uli Example: Use wp-cli to replace the production URL with development URL in the database of a WordPress project hooks : post-import-db : - exec : wp search-replace https://www.myproductionsite.com http://mydevsite.ddev.site Example: Add an extra database before import-db, executing in db container hooks : pre-import-db : - exec : mysql -uroot -proot -e \"CREATE DATABASE IF NOT EXISTS some_new_database;\" service : db Example: Add the common \"ll\" alias into the web container .bashrc file hooks : post-start : - exec : sudo echo alias ll=\\\"ls -lhA\\\" >> ~/.bashrc (Note that this could probably be done more efficiently in a .ddev/web-build/Dockerfile as explained in Customizing Images .) Advanced usages may require running commands directly with explicit arguments. This approach is useful when bash interpretation is not required (no environment variables, no redirection, etc.) hooks : post-start : - exec : exec_raw : [ ls , -lR , /var/www/html ] exec-host : Execute a shell command on the host system \u00b6 Value: string providing the command to run. Commands requiring user interaction are not supported. Example: Run \"composer install\" from your system before starting the project (composer must already be installed on the host workstation): hooks : pre-start : - exec-host : \"composer install\" composer : Execute a composer command in the web container \u00b6 Value: string providing the composer command to run. Example: hooks : post-start : - composer : config discard-changes true WordPress Example \u00b6 hooks : post-start : # Install WordPress after start - exec : \"wp config create --dbname=db --dbuser=db --dbpass=db --dbhost=db\" - exec : \"wp core install --url=http://mysite.ddev.site --title=MySite --admin_user=admin --admin_email=admin@mail.test\" post-import-db : # Update the URL of your project throughout your database after import - exec : \"wp search-replace https://www.myproductionsite.com http://mydevsite.ddev.site\" Drupal 7 Example \u00b6 hooks : post-start : # Install Drupal after start if not installed already - exec : \"(drush status bootstrap | grep -q Successful) || drush site-install -y --db-url=db:db@db/db\" # Generate a one-time login link for the admin account. - exec : \"drush uli 1\" post-import-db : # Set the project name - exec : \"drush vset site_name MyDevSite\" # Enable the environment indicator module - exec : \"drush en -y environment_indicator\" # Clear the cache - exec : \"drush cc all\" Drupal 8 Example \u00b6 hooks : pre-start : # Install composer dependencies using composer on host system - exec-host : \"composer install\" post-start : # Install Drupal after start if not installed already - exec : \"(drush status bootstrap | grep -q Successful) || drush site-install -y --db-url=mysql://db:db@db/db\" # Generate a one-time login link for the admin account. - exec : \"drush uli 1\" post-import-db : # Set the site name - exec : \"drush config-set system.site name MyDevSite\" # Enable the environment indicator module - exec : \"drush en -y environment_indicator\" # Clear the cache - exec : \"drush cr\" TYPO3 Example \u00b6 hooks : post-start : - composer : install Adding Additional Debian Packages (PHP Modules) Example \u00b6 webimage_extra_packages : [ \"php-bcmath\" , \"php7.4-tidy\" ] dbimage_extra_packages : [ \"vim\" ]","title":"Hooks"},{"location":"users/configuration/hooks/#hooks","text":"Most ddev commands provide hooks to run tasks before or after the main command executes. To automate setup tasks specific to your project, define them in the project's config.yaml file. To define command tasks in your configuration, specify the desired command hook as a subfield to hooks , then provide a list of tasks to run. Example: hooks : post-start : - exec : \"simple command expression\" - exec : \"ls >/dev/null && touch /var/www/html/somefile.txt\" - exec-host : \"simple command expression\" post-import-db : - exec : \"drush uli\"","title":"Hooks"},{"location":"users/configuration/hooks/#supported-command-hooks","text":"pre-start : Hooks into \"ddev start\". Execute tasks before the project environment starts. Note: Only exec-host tasks can be generally run successfully during pre-start. See Supported Tasks below for more info. post-start : Execute tasks after the project environment has started. pre-import-db and post-import-db : Execute tasks before or after database import. pre-import-files and post-import-files : Execute tasks before or after files are imported pre-composer and post-composer : Execute tasks before or after the composer command. pre-stop , pre-config , post-config , pre-exec , post-exec , pre-pause , post-pause , pre-pull , post-pull , pre-push , post-push , pre-snapshot , post-snapshot , pre-restore-snapshot , post-restore-snapshot : Execute as the name suggests. post-stop : Hooks into \"ddev stop\". Execute tasks after the project environment stopped. Note: Only exec-host tasks can be generally run successfully during post-stop.","title":"Supported Command Hooks"},{"location":"users/configuration/hooks/#supported-tasks","text":"ddev currently supports these tasks: exec to execute a command in any service/container exec-host to execute a command on the host composer to execute a composer command in the web container","title":"Supported Tasks"},{"location":"users/configuration/hooks/#exec-execute-a-shell-command-in-a-container-defaults-to-web-container","text":"Value: string providing the command to run. Commands requiring user interaction are not supported. You can also add a \"service\" key to the command, specifying to run it on the db container or any other container you use. Example: Use drush to clear the Drupal cache and get a user login link after database import hooks : post-import-db : - exec : drush cr - exec : drush uli Example: Use wp-cli to replace the production URL with development URL in the database of a WordPress project hooks : post-import-db : - exec : wp search-replace https://www.myproductionsite.com http://mydevsite.ddev.site Example: Add an extra database before import-db, executing in db container hooks : pre-import-db : - exec : mysql -uroot -proot -e \"CREATE DATABASE IF NOT EXISTS some_new_database;\" service : db Example: Add the common \"ll\" alias into the web container .bashrc file hooks : post-start : - exec : sudo echo alias ll=\\\"ls -lhA\\\" >> ~/.bashrc (Note that this could probably be done more efficiently in a .ddev/web-build/Dockerfile as explained in Customizing Images .) Advanced usages may require running commands directly with explicit arguments. This approach is useful when bash interpretation is not required (no environment variables, no redirection, etc.) hooks : post-start : - exec : exec_raw : [ ls , -lR , /var/www/html ]","title":"exec: Execute a shell command in a container (defaults to web container)"},{"location":"users/configuration/hooks/#exec-host-execute-a-shell-command-on-the-host-system","text":"Value: string providing the command to run. Commands requiring user interaction are not supported. Example: Run \"composer install\" from your system before starting the project (composer must already be installed on the host workstation): hooks : pre-start : - exec-host : \"composer install\"","title":"exec-host: Execute a shell command on the host system"},{"location":"users/configuration/hooks/#composer-execute-a-composer-command-in-the-web-container","text":"Value: string providing the composer command to run. Example: hooks : post-start : - composer : config discard-changes true","title":"composer: Execute a composer command in the web container"},{"location":"users/configuration/hooks/#wordpress-example","text":"hooks : post-start : # Install WordPress after start - exec : \"wp config create --dbname=db --dbuser=db --dbpass=db --dbhost=db\" - exec : \"wp core install --url=http://mysite.ddev.site --title=MySite --admin_user=admin --admin_email=admin@mail.test\" post-import-db : # Update the URL of your project throughout your database after import - exec : \"wp search-replace https://www.myproductionsite.com http://mydevsite.ddev.site\"","title":"WordPress Example"},{"location":"users/configuration/hooks/#drupal-7-example","text":"hooks : post-start : # Install Drupal after start if not installed already - exec : \"(drush status bootstrap | grep -q Successful) || drush site-install -y --db-url=db:db@db/db\" # Generate a one-time login link for the admin account. - exec : \"drush uli 1\" post-import-db : # Set the project name - exec : \"drush vset site_name MyDevSite\" # Enable the environment indicator module - exec : \"drush en -y environment_indicator\" # Clear the cache - exec : \"drush cc all\"","title":"Drupal 7 Example"},{"location":"users/configuration/hooks/#drupal-8-example","text":"hooks : pre-start : # Install composer dependencies using composer on host system - exec-host : \"composer install\" post-start : # Install Drupal after start if not installed already - exec : \"(drush status bootstrap | grep -q Successful) || drush site-install -y --db-url=mysql://db:db@db/db\" # Generate a one-time login link for the admin account. - exec : \"drush uli 1\" post-import-db : # Set the site name - exec : \"drush config-set system.site name MyDevSite\" # Enable the environment indicator module - exec : \"drush en -y environment_indicator\" # Clear the cache - exec : \"drush cr\"","title":"Drupal 8 Example"},{"location":"users/configuration/hooks/#typo3-example","text":"hooks : post-start : - composer : install","title":"TYPO3 Example"},{"location":"users/configuration/hooks/#adding-additional-debian-packages-php-modules-example","text":"webimage_extra_packages : [ \"php-bcmath\" , \"php7.4-tidy\" ] dbimage_extra_packages : [ \"vim\" ]","title":"Adding Additional Debian Packages (PHP Modules) Example"},{"location":"users/debugging-profiling/blackfire-profiling/","text":"Blackfire.io Profiling \u00b6 DDEV-Local has built-in blackfire.io integration. Basic Blackfire Usage (Using Browser Plugin) \u00b6 Create an account on blackfire.io Install the Chrome or Firefox browser plugin . Get the Server ID, Server Token, Client ID, and Client Token from your Account->Credentials or environment on blackfire.io. Configure ddev with the credentials, ddev config global --web-environment-add=\"BLACKFIRE_SERVER_ID=<id>,BLACKFIRE_SERVER_TOKEN=<token>,BLACKFIRE_CLIENT_ID=<id>,BLACKFIRE_CLIENT_TOKEN=<token>\" . It's easiest to do this globally, but you can do the same thing at the project-level using ddev config --web-environment-add . (It may be easier to manually edit the relevant config file, .ddev/config.yaml or ~/.ddev/global_config.yaml .) ddev start ddev blackfire on to enable, ddev blackfire off to disable, ddev blackfire status to see status. With Blackfire enabled, you can use the browser extension . Profiling with the Blackfire CLI \u00b6 The Blackfire CLI is built into the web container, so no installation needs to take place. Add the BLACKFIRE_SERVER_ID, BLACKFIRE_SERVER_TOKEN, BLACKFIRE_CLIENT_ID, and BLACKFIRE_CLIENT_TOKEN environment variables to your ~/.ddev/global_config.yaml. You can do this by adding to the web_environment key: web_environment : - OTHER_ENV=something - BLACKFIRE_SERVER_ID=dde5f66d-xxxxxx - BLACKFIRE_SERVER_TOKEN=09b0ec-xxxxx - BLACKFIRE_CLIENT_ID=f5e88b7e-xxxxx - BLACKFIRE_CLIENT_TOKEN=00cee15-xxxxx1 It can also be done with ddev config global --web-environment-add=\"BLACKFIRE_SERVER_ID=<id>,BLACKFIRE_SERVER_TOKEN=<token>,BLACKFIRE_CLIENT_ID=<id>,BLACKFIRE_CLIENT_TOKEN=<token>\" , but if there are already environment variables there they will be deleted. 2. ddev start 3. ddev blackfire on 4. Click the \"blackfire\" browser extension to profile Examples of using the Blackfire CLI \u00b6 ddev blackfire on and ddev blackfire off ddev exec blackfire curl https://<yoursite>.ddev.site ddev exec blackfire drush st ddev exec blackfire curl https://<yoursite>.ddev.site ddev ssh and then use the Blackfire CLI as described in Profiling HTTP Requests with the CLI .","title":"Blackfire.io Profiling"},{"location":"users/debugging-profiling/blackfire-profiling/#blackfireio-profiling","text":"DDEV-Local has built-in blackfire.io integration.","title":"Blackfire.io Profiling"},{"location":"users/debugging-profiling/blackfire-profiling/#basic-blackfire-usage-using-browser-plugin","text":"Create an account on blackfire.io Install the Chrome or Firefox browser plugin . Get the Server ID, Server Token, Client ID, and Client Token from your Account->Credentials or environment on blackfire.io. Configure ddev with the credentials, ddev config global --web-environment-add=\"BLACKFIRE_SERVER_ID=<id>,BLACKFIRE_SERVER_TOKEN=<token>,BLACKFIRE_CLIENT_ID=<id>,BLACKFIRE_CLIENT_TOKEN=<token>\" . It's easiest to do this globally, but you can do the same thing at the project-level using ddev config --web-environment-add . (It may be easier to manually edit the relevant config file, .ddev/config.yaml or ~/.ddev/global_config.yaml .) ddev start ddev blackfire on to enable, ddev blackfire off to disable, ddev blackfire status to see status. With Blackfire enabled, you can use the browser extension .","title":"Basic Blackfire Usage (Using Browser Plugin)"},{"location":"users/debugging-profiling/blackfire-profiling/#profiling-with-the-blackfire-cli","text":"The Blackfire CLI is built into the web container, so no installation needs to take place. Add the BLACKFIRE_SERVER_ID, BLACKFIRE_SERVER_TOKEN, BLACKFIRE_CLIENT_ID, and BLACKFIRE_CLIENT_TOKEN environment variables to your ~/.ddev/global_config.yaml. You can do this by adding to the web_environment key: web_environment : - OTHER_ENV=something - BLACKFIRE_SERVER_ID=dde5f66d-xxxxxx - BLACKFIRE_SERVER_TOKEN=09b0ec-xxxxx - BLACKFIRE_CLIENT_ID=f5e88b7e-xxxxx - BLACKFIRE_CLIENT_TOKEN=00cee15-xxxxx1 It can also be done with ddev config global --web-environment-add=\"BLACKFIRE_SERVER_ID=<id>,BLACKFIRE_SERVER_TOKEN=<token>,BLACKFIRE_CLIENT_ID=<id>,BLACKFIRE_CLIENT_TOKEN=<token>\" , but if there are already environment variables there they will be deleted. 2. ddev start 3. ddev blackfire on 4. Click the \"blackfire\" browser extension to profile","title":"Profiling with the Blackfire CLI"},{"location":"users/debugging-profiling/blackfire-profiling/#examples-of-using-the-blackfire-cli","text":"ddev blackfire on and ddev blackfire off ddev exec blackfire curl https://<yoursite>.ddev.site ddev exec blackfire drush st ddev exec blackfire curl https://<yoursite>.ddev.site ddev ssh and then use the Blackfire CLI as described in Profiling HTTP Requests with the CLI .","title":"Examples of using the Blackfire CLI"},{"location":"users/debugging-profiling/step-debugging/","text":"Step-debugging with Xdebug \u00b6 Every ddev project is automatically configured with xdebug so that popular IDEs can do step-debugging of PHP code. It is disabled by default for performance reasons, so you'll need to enable it in your config.yaml. xdebug is a server-side tool: It is installed automatically on the container and you do not need to install or configure it on your workstation. All IDEs basically work the same: They listen on a port and react when they're contacted there. IDEs other than those listed here work fine, if they listen on the default xdebug port 9003. (This was port 9000 through DDEV v1.18, changed to 9003 in v1.19+) Key facts: Enable xdebug by running ddev xdebug or ddev xdebug on in your project directory. It will remain enabled until you start or restart the project. Disable xdebug for better performance when not debugging with ddev xdebug off ddev xdebug status will show current status. The debug server port on the IDE must be set to port 9003 (port 9000 before v1.19), which is the default and is probably already set in most popular IDEs. (If you need to change the xdebug port due to a port conflict on your host computer, you can do it with a PHP override, explained below.) For more background on XDebug see XDebug documentation . The intention here is that one won't have to understand XDebug to do debugging. For each IDE the link to their documentation is provided, and the skeleton steps required are listed here. Setup for Various IDEs \u00b6 PhpStorm Visual Studio Code (vscode) PhpStorm Debugging Setup \u00b6 PhpStorm is a leading PHP development IDE with extensive built-in debugging support. It provides two different ways to do debugging. One requires very little effort in the PhpStorm IDE (they call it zero-configuration debugging) and the other requires you to set up a \"run configuration\", and is basically identical to the Netbeans or Eclipse setup. If you are using PhpStorm inside WSL2 (or perhaps other Linux configurations), under Help\u2192 Edit Custom VM Options , add an additional line: -Djava.net.preferIPv4Stack=true This makes PhpStorm listen for Xdebug using IPV4; the Linux version of PhpStorm seems to default to using only IPV6. PhpStorm Zero-Configuration Debugging \u00b6 PhpStorm zero-configuration debugging will automatically detect a connection and offer to create a \"server\", a file mapping from your workstation to the container. This means you only have to: Toggle the \u201cStart Listening for PHP Debug Connections\u201d button: Set a breakpoint. Visit a page that should stop in the breakpoint you set. PhpStorm will ask you what mapping to use, so it can figure out how to map the path inside the container to the path on your workstation. The first time you do this with a project, PhpStorm will pop up a \"server\" dialog box to set the mapping. The default will work, but it's best to click the checkbox to map the whole project directory to /var/www/html. Note when using this recommended option: Please use the latest DDEV version. Under Run >> Edit Configurations, check that there are no \"Servers\" already defined. PhpStorm will create a new \"Server\" (file mapping) for you as discussed above, but only if you don't already have one. You can delete all servers and have PhpStorm create a new one, or you can create/edit an existing server as discussed below. PhpStorm \"Run/Debug configuration\" Debugging \u00b6 PhpStorm run/debug configurations require slightly more up-front work but can offer more flexibility and may be easier for some people. Under the \"Run\" menu select \"Edit configurations\" Click the \"+\" in the upper left and choose \"PHP Web Application\" to create a configuration. Give it a reasonable name. Create a \"server\" for the project. Make sure that \"Name\" is exactly the same as your \"host\" (e.g. my-site.ddev.site ) (Screenshot below) Add file mappings for the files on the server. Click on the local repo path and add \"/var/www/html\" as the \"Absolute path on the server\" and your repository root as the path on the host. Set an appropriate breakpoint. Start debugging by clicking the \"debug\" button, which will launch a page in your browser. Server creation: PhpStorm and Command-Line Debugging \u00b6 If you need to debug command-line PHP processes, especially code that is outside the docroot, the environment variable PHP_IDE_CONFIG is already set inside the web container, so you don't have to do much more. However, if you have not yet used PhpStorm with xdebug for a regular web request, do that to automatically create the PhpStorm \"server\" with the same name as your primary URL (see \"Languages and Frameworks\" -> \"PHP\" -> \"Servers\"). The key job of the \"server\" is to map filesystem locations on the workstation (your computer) to filesystem locations on the remote server (in this case the ddev-webserver container). Often, PhpStorm has automatically set up a mapping that doesn't include the entire project (so the vendor directory is not mapped, for example). So map the top-level directory of your project to /var/www/html in the container, as in this image: Visual Studio Code (vscode) Debugging Setup \u00b6 Install the php-debug extension. Update the project's [launch.json] (in .vscode/launch.json ) to add \"Listen for xdebug\" (see config snippet ). For more on launch.json, see vscode docs . Set a breakpoint in your index.php. If it isn't solid red, restart. In the menu, choose Run->Start Debugging.You may have to select \"Listen for XDebug\" by the green arrowhead at the top left. The bottom pane of vscode should now be orange (live) and should say \"Listen for XDebug\". Enable XDebug with ddev xdebug on In a browser, visit your project, you should hit the breakpoint. Note that if you're using vscode on Windows with WSL2, you'll want the \"PHP Debug\" extension enabled in your distro (for example, Ubuntu). You'll also need the \"Remote - WSL\" extension enabled. vscode will suggest both of these to you if you have WSL2 enabled and a PHP project. Using Xdebug on a Port Other than the Default 9003 \u00b6 By default, ddev is set up to contact the default port, port 9003 on your IDE. However, if you have something else listening on that port or your IDE does not yet default to 9003, you'll need to change the port. (PhpStorm and vscode have switch to supporting 9003 instead of 9000 for some time now.) To override the port, add an override file in the project's .ddev/php directory. For example, a file .ddev/php/xdebug_client_port.ini would change to use the traditional old port 9000: [PHP] xdebug.client_port = 9000 Then change your IDE's configuration to listen on the new port. NOTE: If you are using a PHP version below PHP7.2, you will be using Xdebug version 2.x, instead of 3.x. In that case the port config should be xdebug.remote_port instead. Troubleshooting Xdebug \u00b6 The basic thing to understand about xdebug is that it's a network protocol. Your IDE (like PhpStorm) will listen on the xdebug port (9003 by default in v1.19+, previously 9000). Then if xdebug is enabled in the ddev web container with ddev xdebug on , then php inside the container will try to open a TCP connection to the IDE. Docker's networking places the host-side listening IDE at host.docker.internal:9003 . So you have to make sure that the network connection is clear and can be made and everything should work. Here are basic steps to take to sort out any difficulty: Remember that the port in play is port 9003 for DDEV v1.19+, but before that it was port 9000. Reboot your computer. Temporarily disable any firewall or VPN if you're having trouble. Xdebug is a network protocol, and the php process inside the web container must be able to establish a TCP connection to the listening IDE (PhpStorm, for example). Use ddev xdebug on to enable xdebug when you want it, and ddev xdebug off when you're done with it. Set a breakpoint at the first executable line of your index.php. Tell your IDE to start listening. (PhpStorm: Click the telephone button, vscode: run the debugger.) Use curl or a browser to create a web request. For example, curl https://d9.ddev.site If the IDE doesn't respond, take a look at ddev logs . If you see a message like \"\"PHP message: Xdebug: [Step Debug] Could not connect to debugging client. Tried: host.docker.internal:9003 (through xdebug.client_host/xdebug.client_port)\" then php/xdebug (inside the container) is not able to make a connection to port 9003. ddev ssh into the web container. Can you telnet host.docker.internal 9003 and have it connect? If you can't, you might have an over-aggressive firewall. Disable it, or add a rule that would allow the connection to pass through. For example, on Debian/ Ubuntu that would be sudo ufw allow 9003/tcp . In PhpStorm, disable the \"listen for connections\" button so it won't listen. Or just exit PhpStorm. With another IDE like vscode, stop the debugger from listening. ddev ssh : Can telnet host.docker.internal 9003 connect? If it does, you have something else running on port 9003. On the host, use sudo lsof -i :9003 -sTCP:LISTEN to find out what is there and stop it. Don't continue debugging until your telnet command does not connect. (Note that on Windows WSL2 you may have to look for listeners both inside WSL2 and on the Windows side.) Now click the listen button on PhpStorm to start it listening for connections. ddev ssh and try the telnet host.docker.internal 9003 again. It should connect. If not, maybe PhpStorm is not listening, or not configured to listen on port 9003? Check to make sure that Xdebug is enabled. You can use php -i | grep -i xdebug inside the container, or use any other technique you want that gives the output of phpinfo() , including Drupal's admin/reports/status/php. You should see with Xdebug v3 and php -i | grep xdebug.mode should give you xdebug.mode => debug,develop => debug,develop\" . Set a breakpoint in the first relevant line of the index.php of your project and then visit the site in a browser. It should stop at that first line. If you are using PhpStorm inside WSL2 (or perhaps other Linux configurations), under Help\u2192 Edit Custom VM Options , add an additional line: -Djava.net.preferIPv4Stack=true This makes PhpStorm listen for Xdebug using IPV4; the Linux version of PhpStorm seems to default to using only IPV6. If you are on WSL2 using Docker Desktop, make sure that the docker command is the one provided by Docker Desktop. ls -l $(which docker) should show a link to /mnt/wsl/docker-desktop... . If you are on WSL2 using docker installed inside WSL2, make sure that ls -l $(which docker) is not a link to /mnt/wsl .","title":"Step-debugging with Xdebug"},{"location":"users/debugging-profiling/step-debugging/#step-debugging-with-xdebug","text":"Every ddev project is automatically configured with xdebug so that popular IDEs can do step-debugging of PHP code. It is disabled by default for performance reasons, so you'll need to enable it in your config.yaml. xdebug is a server-side tool: It is installed automatically on the container and you do not need to install or configure it on your workstation. All IDEs basically work the same: They listen on a port and react when they're contacted there. IDEs other than those listed here work fine, if they listen on the default xdebug port 9003. (This was port 9000 through DDEV v1.18, changed to 9003 in v1.19+) Key facts: Enable xdebug by running ddev xdebug or ddev xdebug on in your project directory. It will remain enabled until you start or restart the project. Disable xdebug for better performance when not debugging with ddev xdebug off ddev xdebug status will show current status. The debug server port on the IDE must be set to port 9003 (port 9000 before v1.19), which is the default and is probably already set in most popular IDEs. (If you need to change the xdebug port due to a port conflict on your host computer, you can do it with a PHP override, explained below.) For more background on XDebug see XDebug documentation . The intention here is that one won't have to understand XDebug to do debugging. For each IDE the link to their documentation is provided, and the skeleton steps required are listed here.","title":"Step-debugging with Xdebug"},{"location":"users/debugging-profiling/step-debugging/#setup-for-various-ides","text":"PhpStorm Visual Studio Code (vscode)","title":"Setup for Various IDEs"},{"location":"users/debugging-profiling/step-debugging/#phpstorm-debugging-setup","text":"PhpStorm is a leading PHP development IDE with extensive built-in debugging support. It provides two different ways to do debugging. One requires very little effort in the PhpStorm IDE (they call it zero-configuration debugging) and the other requires you to set up a \"run configuration\", and is basically identical to the Netbeans or Eclipse setup. If you are using PhpStorm inside WSL2 (or perhaps other Linux configurations), under Help\u2192 Edit Custom VM Options , add an additional line: -Djava.net.preferIPv4Stack=true This makes PhpStorm listen for Xdebug using IPV4; the Linux version of PhpStorm seems to default to using only IPV6.","title":"PhpStorm Debugging Setup"},{"location":"users/debugging-profiling/step-debugging/#phpstorm-zero-configuration-debugging","text":"PhpStorm zero-configuration debugging will automatically detect a connection and offer to create a \"server\", a file mapping from your workstation to the container. This means you only have to: Toggle the \u201cStart Listening for PHP Debug Connections\u201d button: Set a breakpoint. Visit a page that should stop in the breakpoint you set. PhpStorm will ask you what mapping to use, so it can figure out how to map the path inside the container to the path on your workstation. The first time you do this with a project, PhpStorm will pop up a \"server\" dialog box to set the mapping. The default will work, but it's best to click the checkbox to map the whole project directory to /var/www/html. Note when using this recommended option: Please use the latest DDEV version. Under Run >> Edit Configurations, check that there are no \"Servers\" already defined. PhpStorm will create a new \"Server\" (file mapping) for you as discussed above, but only if you don't already have one. You can delete all servers and have PhpStorm create a new one, or you can create/edit an existing server as discussed below.","title":"PhpStorm Zero-Configuration Debugging"},{"location":"users/debugging-profiling/step-debugging/#phpstorm-rundebug-configuration-debugging","text":"PhpStorm run/debug configurations require slightly more up-front work but can offer more flexibility and may be easier for some people. Under the \"Run\" menu select \"Edit configurations\" Click the \"+\" in the upper left and choose \"PHP Web Application\" to create a configuration. Give it a reasonable name. Create a \"server\" for the project. Make sure that \"Name\" is exactly the same as your \"host\" (e.g. my-site.ddev.site ) (Screenshot below) Add file mappings for the files on the server. Click on the local repo path and add \"/var/www/html\" as the \"Absolute path on the server\" and your repository root as the path on the host. Set an appropriate breakpoint. Start debugging by clicking the \"debug\" button, which will launch a page in your browser. Server creation:","title":"PhpStorm \"Run/Debug configuration\" Debugging"},{"location":"users/debugging-profiling/step-debugging/#phpstorm-and-command-line-debugging","text":"If you need to debug command-line PHP processes, especially code that is outside the docroot, the environment variable PHP_IDE_CONFIG is already set inside the web container, so you don't have to do much more. However, if you have not yet used PhpStorm with xdebug for a regular web request, do that to automatically create the PhpStorm \"server\" with the same name as your primary URL (see \"Languages and Frameworks\" -> \"PHP\" -> \"Servers\"). The key job of the \"server\" is to map filesystem locations on the workstation (your computer) to filesystem locations on the remote server (in this case the ddev-webserver container). Often, PhpStorm has automatically set up a mapping that doesn't include the entire project (so the vendor directory is not mapped, for example). So map the top-level directory of your project to /var/www/html in the container, as in this image:","title":"PhpStorm and Command-Line Debugging"},{"location":"users/debugging-profiling/step-debugging/#visual-studio-code-vscode-debugging-setup","text":"Install the php-debug extension. Update the project's [launch.json] (in .vscode/launch.json ) to add \"Listen for xdebug\" (see config snippet ). For more on launch.json, see vscode docs . Set a breakpoint in your index.php. If it isn't solid red, restart. In the menu, choose Run->Start Debugging.You may have to select \"Listen for XDebug\" by the green arrowhead at the top left. The bottom pane of vscode should now be orange (live) and should say \"Listen for XDebug\". Enable XDebug with ddev xdebug on In a browser, visit your project, you should hit the breakpoint. Note that if you're using vscode on Windows with WSL2, you'll want the \"PHP Debug\" extension enabled in your distro (for example, Ubuntu). You'll also need the \"Remote - WSL\" extension enabled. vscode will suggest both of these to you if you have WSL2 enabled and a PHP project.","title":"Visual Studio Code (vscode) Debugging Setup"},{"location":"users/debugging-profiling/step-debugging/#using-xdebug-on-a-port-other-than-the-default-9003","text":"By default, ddev is set up to contact the default port, port 9003 on your IDE. However, if you have something else listening on that port or your IDE does not yet default to 9003, you'll need to change the port. (PhpStorm and vscode have switch to supporting 9003 instead of 9000 for some time now.) To override the port, add an override file in the project's .ddev/php directory. For example, a file .ddev/php/xdebug_client_port.ini would change to use the traditional old port 9000: [PHP] xdebug.client_port = 9000 Then change your IDE's configuration to listen on the new port. NOTE: If you are using a PHP version below PHP7.2, you will be using Xdebug version 2.x, instead of 3.x. In that case the port config should be xdebug.remote_port instead.","title":"Using Xdebug on a Port Other than the Default 9003"},{"location":"users/debugging-profiling/step-debugging/#troubleshooting-xdebug","text":"The basic thing to understand about xdebug is that it's a network protocol. Your IDE (like PhpStorm) will listen on the xdebug port (9003 by default in v1.19+, previously 9000). Then if xdebug is enabled in the ddev web container with ddev xdebug on , then php inside the container will try to open a TCP connection to the IDE. Docker's networking places the host-side listening IDE at host.docker.internal:9003 . So you have to make sure that the network connection is clear and can be made and everything should work. Here are basic steps to take to sort out any difficulty: Remember that the port in play is port 9003 for DDEV v1.19+, but before that it was port 9000. Reboot your computer. Temporarily disable any firewall or VPN if you're having trouble. Xdebug is a network protocol, and the php process inside the web container must be able to establish a TCP connection to the listening IDE (PhpStorm, for example). Use ddev xdebug on to enable xdebug when you want it, and ddev xdebug off when you're done with it. Set a breakpoint at the first executable line of your index.php. Tell your IDE to start listening. (PhpStorm: Click the telephone button, vscode: run the debugger.) Use curl or a browser to create a web request. For example, curl https://d9.ddev.site If the IDE doesn't respond, take a look at ddev logs . If you see a message like \"\"PHP message: Xdebug: [Step Debug] Could not connect to debugging client. Tried: host.docker.internal:9003 (through xdebug.client_host/xdebug.client_port)\" then php/xdebug (inside the container) is not able to make a connection to port 9003. ddev ssh into the web container. Can you telnet host.docker.internal 9003 and have it connect? If you can't, you might have an over-aggressive firewall. Disable it, or add a rule that would allow the connection to pass through. For example, on Debian/ Ubuntu that would be sudo ufw allow 9003/tcp . In PhpStorm, disable the \"listen for connections\" button so it won't listen. Or just exit PhpStorm. With another IDE like vscode, stop the debugger from listening. ddev ssh : Can telnet host.docker.internal 9003 connect? If it does, you have something else running on port 9003. On the host, use sudo lsof -i :9003 -sTCP:LISTEN to find out what is there and stop it. Don't continue debugging until your telnet command does not connect. (Note that on Windows WSL2 you may have to look for listeners both inside WSL2 and on the Windows side.) Now click the listen button on PhpStorm to start it listening for connections. ddev ssh and try the telnet host.docker.internal 9003 again. It should connect. If not, maybe PhpStorm is not listening, or not configured to listen on port 9003? Check to make sure that Xdebug is enabled. You can use php -i | grep -i xdebug inside the container, or use any other technique you want that gives the output of phpinfo() , including Drupal's admin/reports/status/php. You should see with Xdebug v3 and php -i | grep xdebug.mode should give you xdebug.mode => debug,develop => debug,develop\" . Set a breakpoint in the first relevant line of the index.php of your project and then visit the site in a browser. It should stop at that first line. If you are using PhpStorm inside WSL2 (or perhaps other Linux configurations), under Help\u2192 Edit Custom VM Options , add an additional line: -Djava.net.preferIPv4Stack=true This makes PhpStorm listen for Xdebug using IPV4; the Linux version of PhpStorm seems to default to using only IPV6. If you are on WSL2 using Docker Desktop, make sure that the docker command is the one provided by Docker Desktop. ls -l $(which docker) should show a link to /mnt/wsl/docker-desktop... . If you are on WSL2 using docker installed inside WSL2, make sure that ls -l $(which docker) is not a link to /mnt/wsl .","title":"Troubleshooting Xdebug"},{"location":"users/debugging-profiling/xdebug-profiling/","text":"Xdebug Profiling \u00b6 Although DDEV has more sophisticated profiling capabilities with xhprof and blackfire.io it also has built-in support for xdebug profiling . Basic usage \u00b6 Create the directory .ddev/xdebug , which is where the output files will be dumped. Switch XDebug to profiling mode by adding this in .ddev/php/xdebug.ini xdebug.mode = profile xdebug.start_with_request = yes xdebug.output_dir = /var/www/html/.ddev/xdebug xdebug.profiler_output_name = trace.%c%p%r%u.out Enable xdebug with ddev xdebug on Do a HTTP request to the DDEV project and the profile will be located in .ddev/xdebug directory. Analyze it with any call graph viewer, for example kcachegrind . When you're done, execute ddev xdebug off to avoid generating unneeded profile files. Information Links \u00b6 xdebug profiling docs kcachegrind","title":"Xdebug Profiling"},{"location":"users/debugging-profiling/xdebug-profiling/#xdebug-profiling","text":"Although DDEV has more sophisticated profiling capabilities with xhprof and blackfire.io it also has built-in support for xdebug profiling .","title":"Xdebug Profiling"},{"location":"users/debugging-profiling/xdebug-profiling/#basic-usage","text":"Create the directory .ddev/xdebug , which is where the output files will be dumped. Switch XDebug to profiling mode by adding this in .ddev/php/xdebug.ini xdebug.mode = profile xdebug.start_with_request = yes xdebug.output_dir = /var/www/html/.ddev/xdebug xdebug.profiler_output_name = trace.%c%p%r%u.out Enable xdebug with ddev xdebug on Do a HTTP request to the DDEV project and the profile will be located in .ddev/xdebug directory. Analyze it with any call graph viewer, for example kcachegrind . When you're done, execute ddev xdebug off to avoid generating unneeded profile files.","title":"Basic usage"},{"location":"users/debugging-profiling/xdebug-profiling/#information-links","text":"xdebug profiling docs kcachegrind","title":"Information Links"},{"location":"users/debugging-profiling/xhprof-profiling/","text":"xhprof Profiling \u00b6 DDEV-Local has built-in support for xhprof . The official PECL xhprof extension does not support PHP5.6, but only PHP 7.* and PHP 8.*. Basic xhprof Usage \u00b6 Enable xhprof with ddev xhprof on (or ddev xhprof or ddev xhprof enable ) and see status with ddev xhprof status ddev xhprof on will show you the URL you can use to see the xhprof analysis, https://<projectname>.ddev.site/xhprof shows recent runs. It's often useful to just have a tab or window open with this URL and refresh it as needed. Use a web browser or other technique to visit a page whose performance you want to study. To eliminate first-time cache-building issues, you may want to hit it twice. Visit one of the links provided by ddev xhprof on and study the results. On the profiler output page you can drill down to the function that you want to study, or use the graphical \"View Full Callgraph\" link. Click the column headers to sort by number of runs and inclusive or exclusive wall time, then drill down into the function you really want to study and do the same. The runs are erased on ddev restart . If you are using webserver_type apache-fpm and you have a custom .ddev/apache/apache-site.conf, you'll need to make sure it has the Alias \"/xhprof\" \"/var/xhprof/xhprof_html\" in it that the provided apache-site.conf has. For a tutorial on how to study the various xhprof reports, see the section \"How to use XHPROF UI\" in A Guide to Profiling with XHPROF . It takes a little time to get your eyes used to the reporting. (You do not need to do any of the installation described in that article, of course.) Advanced xhprof configuration \u00b6 You can change the contents of the xhprof_prepend function - it's in .ddev/xhprof/xhprof_prepend.php . For example, you may want to add a link to the profile run to the bottom of the profiled web page; the provided xhprof_prepend.php has comments and a sample function to do that, which works with Drupal 7. If you change it, remove the #ddev-generated line from the top, and check it in ( git add -f .ddev/xhprof/xhprof_prepend.php ) For another example, if you want to exclude the memory profiling so there are less columns to study, change xhprof_enable(XHPROF_FLAGS_CPU + XHPROF_FLAGS_MEMORY); to just xhprof_enable(XHPROF_FLAGS_CPU); in .ddev/xhprof/xhprof_prepend.php and remote the #ddev-generated at the top of the file. See the docs on xhprof_enable() . Information Links \u00b6 php.net xhprof Old facebook xhprof docs rfay screencast on xhprof and blackfire.io pecl.php.net docs Upstream github repo lonngxhinH/xhprof","title":"xhprof Profiling"},{"location":"users/debugging-profiling/xhprof-profiling/#xhprof-profiling","text":"DDEV-Local has built-in support for xhprof . The official PECL xhprof extension does not support PHP5.6, but only PHP 7.* and PHP 8.*.","title":"xhprof Profiling"},{"location":"users/debugging-profiling/xhprof-profiling/#basic-xhprof-usage","text":"Enable xhprof with ddev xhprof on (or ddev xhprof or ddev xhprof enable ) and see status with ddev xhprof status ddev xhprof on will show you the URL you can use to see the xhprof analysis, https://<projectname>.ddev.site/xhprof shows recent runs. It's often useful to just have a tab or window open with this URL and refresh it as needed. Use a web browser or other technique to visit a page whose performance you want to study. To eliminate first-time cache-building issues, you may want to hit it twice. Visit one of the links provided by ddev xhprof on and study the results. On the profiler output page you can drill down to the function that you want to study, or use the graphical \"View Full Callgraph\" link. Click the column headers to sort by number of runs and inclusive or exclusive wall time, then drill down into the function you really want to study and do the same. The runs are erased on ddev restart . If you are using webserver_type apache-fpm and you have a custom .ddev/apache/apache-site.conf, you'll need to make sure it has the Alias \"/xhprof\" \"/var/xhprof/xhprof_html\" in it that the provided apache-site.conf has. For a tutorial on how to study the various xhprof reports, see the section \"How to use XHPROF UI\" in A Guide to Profiling with XHPROF . It takes a little time to get your eyes used to the reporting. (You do not need to do any of the installation described in that article, of course.)","title":"Basic xhprof Usage"},{"location":"users/debugging-profiling/xhprof-profiling/#advanced-xhprof-configuration","text":"You can change the contents of the xhprof_prepend function - it's in .ddev/xhprof/xhprof_prepend.php . For example, you may want to add a link to the profile run to the bottom of the profiled web page; the provided xhprof_prepend.php has comments and a sample function to do that, which works with Drupal 7. If you change it, remove the #ddev-generated line from the top, and check it in ( git add -f .ddev/xhprof/xhprof_prepend.php ) For another example, if you want to exclude the memory profiling so there are less columns to study, change xhprof_enable(XHPROF_FLAGS_CPU + XHPROF_FLAGS_MEMORY); to just xhprof_enable(XHPROF_FLAGS_CPU); in .ddev/xhprof/xhprof_prepend.php and remote the #ddev-generated at the top of the file. See the docs on xhprof_enable() .","title":"Advanced xhprof configuration"},{"location":"users/debugging-profiling/xhprof-profiling/#information-links","text":"php.net xhprof Old facebook xhprof docs rfay screencast on xhprof and blackfire.io pecl.php.net docs Upstream github repo lonngxhinH/xhprof","title":"Information Links"},{"location":"users/details/alternate-uses/","text":"Alternate Uses for DDEV \u00b6 Continuous Integration (CI) for a project \u00b6 Although it has not a primary goal of DDEV-Local, a number of people have found it easy to use DDEV-Local on a CI system like GitHub Actions or TravisCI or CircleCI to test out their projects. Instead of setting up a hosting environment for testing, they just start the project using DDEV and run their tests. Examples of this approach are shown in Codeception tests in Travis CI with DDEV and Selenium and GitHub Action Setup Ddev Integration of DDEV-Local Docker Images Into Other Projects \u00b6 It is possible to use DDEV-Local Docker images outside the context of the DDEV-Local environment. People have used the ddev-webserver image for running tests in PhpStorm, for example. Casual Project Webhosting on the Internet (including Let's Encrypt) \u00b6 An experimental feature of DDEV-local is simplified small-project hosting on the internet. One can run DDEV-Local on an internet server and point their DNS to it and use it as a regular (though limited) hosting environment. This may be completely appropriate for small or abandoned sites that have special requirements like old versions of PHP that aren't supported elsewhere. Note that this is no replacement for a scalable managed hosting offering. It's unknown how much traffic it can handle in a given environment. And it's EXPERIMENTAL. And it will never replace managed hosting. Install DDEV-Local on a regular Linux server that is directly connected to the Internet. You're responsible for your firewall and maintenance of the server, of course. On Debian/Ubuntu, you can set up a simple firewall with ufw allow 80 && ufw allow 443 && ufw allow 22 && ufw enable Point DNS for the site you're going to host to the server. Before proceeding, your system and your project must be accessible on the internet on port 80 and your project DNS name (myproject.example.com) must resolve to the appropriate server. Configure your project with ddev config Import your database and files using ddev import-db and ddev import-files . Use ddev config global --router-bind-all-interfaces --omit-containers=dba,ddev-ssh-agent --use-hardened-images --use-letsencrypt --letsencrypt-email=you@example.com to tell DDEV to listen to all network interfaces (not just localhost), not provide phpMyAdmin or ddev-ssh-agent, use the hardened images, and turn on Let's Encrypt. Create your DDEV-Local project as you normally would, but ddev config --additional-fqdns=<internet_fqdn . If your website responds to multiple hostnames (for example, with \"www\" and without it) then you'll need to add each hostname. ddev start and visit your site. Clear your cache (on some CMSs). You may have to restart ddev with ddev poweroff && ddev start --all if Let's Encrypt has failed due to port 80 not being open or the DNS name not yet resolving. (Use docker logs ddev-router to see Let's Encrypt activity.) Additional Server Setup \u00b6 Depending on how you're using this, you may want to set up automated database and files backups (preferably offsite) as on all production systems. Many CMSs have modules/plugins to allow this, or you can use ddev export-db or ddev snapshot as you see fit and do the backup on the host. You may want to allow your host system to send email (for notifications from the host itself). On Debian/Ubuntu sudo apt-get install postfix . Typically you'll need to set up reverse DNS for your system, and perhaps an SPF record in order for other systems to accept the email. You may want to update your php settings to use other than the defaults. For example, the error-reporting defaults in php.ini are very aggressive and you may want something less: ; Error handling and logging ; error_reporting = E_ALL display_errors = On display_startup_errors = On log_errors = On To make ddev start sites on system boot, you'll want to set up a systemd unit on systemd systems like Debian/Ubuntu and Fedora. For example, a file named /etc/systemd/system/ddev.service containing: # Start ddev when system starts (after docker) # Stop ddev when docker shuts down # Start with `sudo systemctl start ddev` # Enable on boot with `sudo systemctl enable ddev` # Make sure to edit the User= for your user and the # full path to ddev on your system. # Optionally give a list of sites instead of --all [Unit] Description=DDEV-Local sites After=network.target Requires=docker.service PartOf=docker.service [Service] User=rfay Type=oneshot ExecStart=/usr/local/bin/ddev start --all RemainAfterExit=true ExecStop=/usr/local/bin/ddev poweroff [Install] WantedBy=multi-user.target You will probably want to regularly renew the Let's Encrypt certificates. This is often done on a system reboot, but that may not be soon enough. A cron with the command docker exec ddev-router bash -c \"certbot renew && nginx -s reload\" will do the renewals. You'll likely want to turn off PHP errors to screen in a .ddev/php/noerrors.ini: display_errors = Off display_startup_errors = Off Caveats: It's unknown how much traffic a given server and docker setup can sustain, or what the results will be if the traffic is more than the server can handle. DDEV-Local does not provide outgoing SMTP mailhandling service, and the development-focused MailHog feature is disabled if you're using use_hardened_images . You can provide SMTP service a number of ways, but the recommended way is to enable SMTP mailsending in your application and leverage a third-party transactional email service such as SendGrid, Mandrill, or Mailgun. This is the best way to make sure your mail actually gets delivered. You may need an external cron trigger for some types of CMS. Debugging Let's Encrypt failures requires viewing the ddev-router logs with docker logs ddev-router A malicious attack on a website hosted with use_hardened_images will likely not be able to do anything significant to the host, but it can certainly change your code, which is mounted on the host. When using use_hardened_images docker runs the webimage as an unprivileged user, and the container does not have sudo. However, any docker server hosted on the internet is a potential vulnerability. Keep your packages up-to-date. Make sure that your firewall does not allow access to ports other than (normally) 22, 80, and 443. There are no warranties implied or expressed.","title":"Alternate Uses for DDEV"},{"location":"users/details/alternate-uses/#alternate-uses-for-ddev","text":"","title":"Alternate Uses for DDEV"},{"location":"users/details/alternate-uses/#continuous-integration-ci-for-a-project","text":"Although it has not a primary goal of DDEV-Local, a number of people have found it easy to use DDEV-Local on a CI system like GitHub Actions or TravisCI or CircleCI to test out their projects. Instead of setting up a hosting environment for testing, they just start the project using DDEV and run their tests. Examples of this approach are shown in Codeception tests in Travis CI with DDEV and Selenium and GitHub Action Setup Ddev","title":"Continuous Integration (CI) for a project"},{"location":"users/details/alternate-uses/#integration-of-ddev-local-docker-images-into-other-projects","text":"It is possible to use DDEV-Local Docker images outside the context of the DDEV-Local environment. People have used the ddev-webserver image for running tests in PhpStorm, for example.","title":"Integration of DDEV-Local Docker Images Into Other Projects"},{"location":"users/details/alternate-uses/#casual-project-webhosting-on-the-internet-including-lets-encrypt","text":"An experimental feature of DDEV-local is simplified small-project hosting on the internet. One can run DDEV-Local on an internet server and point their DNS to it and use it as a regular (though limited) hosting environment. This may be completely appropriate for small or abandoned sites that have special requirements like old versions of PHP that aren't supported elsewhere. Note that this is no replacement for a scalable managed hosting offering. It's unknown how much traffic it can handle in a given environment. And it's EXPERIMENTAL. And it will never replace managed hosting. Install DDEV-Local on a regular Linux server that is directly connected to the Internet. You're responsible for your firewall and maintenance of the server, of course. On Debian/Ubuntu, you can set up a simple firewall with ufw allow 80 && ufw allow 443 && ufw allow 22 && ufw enable Point DNS for the site you're going to host to the server. Before proceeding, your system and your project must be accessible on the internet on port 80 and your project DNS name (myproject.example.com) must resolve to the appropriate server. Configure your project with ddev config Import your database and files using ddev import-db and ddev import-files . Use ddev config global --router-bind-all-interfaces --omit-containers=dba,ddev-ssh-agent --use-hardened-images --use-letsencrypt --letsencrypt-email=you@example.com to tell DDEV to listen to all network interfaces (not just localhost), not provide phpMyAdmin or ddev-ssh-agent, use the hardened images, and turn on Let's Encrypt. Create your DDEV-Local project as you normally would, but ddev config --additional-fqdns=<internet_fqdn . If your website responds to multiple hostnames (for example, with \"www\" and without it) then you'll need to add each hostname. ddev start and visit your site. Clear your cache (on some CMSs). You may have to restart ddev with ddev poweroff && ddev start --all if Let's Encrypt has failed due to port 80 not being open or the DNS name not yet resolving. (Use docker logs ddev-router to see Let's Encrypt activity.)","title":"Casual Project Webhosting on the Internet (including Let's Encrypt)"},{"location":"users/details/alternate-uses/#additional-server-setup","text":"Depending on how you're using this, you may want to set up automated database and files backups (preferably offsite) as on all production systems. Many CMSs have modules/plugins to allow this, or you can use ddev export-db or ddev snapshot as you see fit and do the backup on the host. You may want to allow your host system to send email (for notifications from the host itself). On Debian/Ubuntu sudo apt-get install postfix . Typically you'll need to set up reverse DNS for your system, and perhaps an SPF record in order for other systems to accept the email. You may want to update your php settings to use other than the defaults. For example, the error-reporting defaults in php.ini are very aggressive and you may want something less: ; Error handling and logging ; error_reporting = E_ALL display_errors = On display_startup_errors = On log_errors = On To make ddev start sites on system boot, you'll want to set up a systemd unit on systemd systems like Debian/Ubuntu and Fedora. For example, a file named /etc/systemd/system/ddev.service containing: # Start ddev when system starts (after docker) # Stop ddev when docker shuts down # Start with `sudo systemctl start ddev` # Enable on boot with `sudo systemctl enable ddev` # Make sure to edit the User= for your user and the # full path to ddev on your system. # Optionally give a list of sites instead of --all [Unit] Description=DDEV-Local sites After=network.target Requires=docker.service PartOf=docker.service [Service] User=rfay Type=oneshot ExecStart=/usr/local/bin/ddev start --all RemainAfterExit=true ExecStop=/usr/local/bin/ddev poweroff [Install] WantedBy=multi-user.target You will probably want to regularly renew the Let's Encrypt certificates. This is often done on a system reboot, but that may not be soon enough. A cron with the command docker exec ddev-router bash -c \"certbot renew && nginx -s reload\" will do the renewals. You'll likely want to turn off PHP errors to screen in a .ddev/php/noerrors.ini: display_errors = Off display_startup_errors = Off Caveats: It's unknown how much traffic a given server and docker setup can sustain, or what the results will be if the traffic is more than the server can handle. DDEV-Local does not provide outgoing SMTP mailhandling service, and the development-focused MailHog feature is disabled if you're using use_hardened_images . You can provide SMTP service a number of ways, but the recommended way is to enable SMTP mailsending in your application and leverage a third-party transactional email service such as SendGrid, Mandrill, or Mailgun. This is the best way to make sure your mail actually gets delivered. You may need an external cron trigger for some types of CMS. Debugging Let's Encrypt failures requires viewing the ddev-router logs with docker logs ddev-router A malicious attack on a website hosted with use_hardened_images will likely not be able to do anything significant to the host, but it can certainly change your code, which is mounted on the host. When using use_hardened_images docker runs the webimage as an unprivileged user, and the container does not have sudo. However, any docker server hosted on the internet is a potential vulnerability. Keep your packages up-to-date. Make sure that your firewall does not allow access to ports other than (normally) 22, 80, and 443. There are no warranties implied or expressed.","title":"Additional Server Setup"},{"location":"users/details/offline-usage/","text":"Using DDEV offline \u00b6 DDEV-Local attempts to make offline use work as well as possible, and you really shouldn't have to do anything to make it work: It doesn't attempt instrumentation or update reporting if offline It uses /etc/hosts entries instead of DNS resolution if DNS resolution fails However, it does not (yet) attempt to prevent docker pulls if a new docker image is required, so you'll want to make sure that you try a ddev start before going offline to make sure everything has been pulled. If you have a project running when you're online (using DNS for name resolution) and you then go offline, you'll want to do a ddev restart to get the hostname added into /etc/hosts for name resolution. You have general options as well: In .ddev/config.yaml use_dns_when_possible: false will make ddev never try to use DNS for resolution, instead adding hostnames to /etc/hosts. You can also use ddev config --use-dns-when-possible=false to set this configuration option. In .ddev/config.yaml project_tld: example.com (or any other domain) can set ddev to use a project that could never be looked up in DNS. You can also use ddev config --project-tld=example.com You can also set up a local DNS server like dnsmasq (Linux and macOS, brew install dnsmasq ) or ( unbound or many others on Windows) in your own host environment that serves the project_tld that you choose, and DNS resolution will work just fine. You'll likely want a wildcard A record pointing to 127.0.0.1 (on most ddev installations). If you use dnsmasq you must configure it to allow DNS rebinding. If you're using a browser on Windows, accessing a DDEV project in WSL2, Windows will attempt to resolve the site name via DNS. If you do not have an internet connection, this will fail. To resolve this, update your C:\\Windows\\System32\\drivers\\etc\\hosts file. 127.0.0.1 example.ddev.site Administrative privileges required You must have administrative privileges to save the Windows hosts file. See Windows Hosts File limited to 10 hosts per IP address line .","title":"Using DDEV offline"},{"location":"users/details/offline-usage/#using-ddev-offline","text":"DDEV-Local attempts to make offline use work as well as possible, and you really shouldn't have to do anything to make it work: It doesn't attempt instrumentation or update reporting if offline It uses /etc/hosts entries instead of DNS resolution if DNS resolution fails However, it does not (yet) attempt to prevent docker pulls if a new docker image is required, so you'll want to make sure that you try a ddev start before going offline to make sure everything has been pulled. If you have a project running when you're online (using DNS for name resolution) and you then go offline, you'll want to do a ddev restart to get the hostname added into /etc/hosts for name resolution. You have general options as well: In .ddev/config.yaml use_dns_when_possible: false will make ddev never try to use DNS for resolution, instead adding hostnames to /etc/hosts. You can also use ddev config --use-dns-when-possible=false to set this configuration option. In .ddev/config.yaml project_tld: example.com (or any other domain) can set ddev to use a project that could never be looked up in DNS. You can also use ddev config --project-tld=example.com You can also set up a local DNS server like dnsmasq (Linux and macOS, brew install dnsmasq ) or ( unbound or many others on Windows) in your own host environment that serves the project_tld that you choose, and DNS resolution will work just fine. You'll likely want a wildcard A record pointing to 127.0.0.1 (on most ddev installations). If you use dnsmasq you must configure it to allow DNS rebinding. If you're using a browser on Windows, accessing a DDEV project in WSL2, Windows will attempt to resolve the site name via DNS. If you do not have an internet connection, this will fail. To resolve this, update your C:\\Windows\\System32\\drivers\\etc\\hosts file. 127.0.0.1 example.ddev.site Administrative privileges required You must have administrative privileges to save the Windows hosts file. See Windows Hosts File limited to 10 hosts per IP address line .","title":"Using DDEV offline"},{"location":"users/details/opting-in/","text":"Opt-In Usage Information \u00b6 When you start ddev for the first time (or install a new release) you'll be asked to decide whether to opt-in to send usage and error information to the developers. You can change this at any time by editing the ~/.ddev/global_config.yaml file and setting instrumentation_opt_in: true or instrumentation_opt_in: false . If you do choose to send the diagnostics it helps us tremendously in our effort to improve this tool. What information gets sent? Here's an example of what we might see: Of course if you have any reservations about this, please just opt-out ( ddev config global --instrumentation-opt-in=false ). If you have any problems or concerns with it, we'd like to know.","title":"Opting in"},{"location":"users/details/opting-in/#opt-in-usage-information","text":"When you start ddev for the first time (or install a new release) you'll be asked to decide whether to opt-in to send usage and error information to the developers. You can change this at any time by editing the ~/.ddev/global_config.yaml file and setting instrumentation_opt_in: true or instrumentation_opt_in: false . If you do choose to send the diagnostics it helps us tremendously in our effort to improve this tool. What information gets sent? Here's an example of what we might see: Of course if you have any reservations about this, please just opt-out ( ddev config global --instrumentation-opt-in=false ). If you have any problems or concerns with it, we'd like to know.","title":"Opt-In Usage Information"},{"location":"users/extend/additional-hostnames/","text":"Additional Project Hostnames \u00b6 Add additional hostnames to a project in the project's .ddev/config.yaml: name: mysite additional_hostnames: - \"extraname\" - \"fr.mysite\" - \"es.mysite\" - \"it.mysite\" - \"\\*.lotsofnames\" This configuration would result in working hostnames of mysite.ddev.site , extraname.ddev.site , fr.mysite.ddev.site , es.mysite.ddev.site , and it.mysite.ddev.site (with full http and https URLs for each). In addition, the wildcard *.lotsofnames will result in anything *.lotsofnames.ddev.site being recognized by the project. This works only if you're connected to the internet, using \"ddev.site\" for your top-level-domain, and using DNS for name lookups. (These are all the defaults.) Although we recommend extreme care with this feature , you can also provide additional_fqdn entries, which don't use the .ddev.site top-level domain. This feature populates your hosts file with entries which may hide the real DNS entries on the internet, causing way too much head-scratching. If you use a FQDN which is resolvable on the internet, you must use use_dns_when_possible: false or configure that with ddev config --use-dns-when-possible=false . name: somename additional_fqdns: - example.com - somesite.example.com - anothersite.example.com This configuration would result in working FQDNs of somename.ddev.site , example.com , somesite.example.com , and anothersite.example.com . Don't use the same additional_fqdns or additional_hostnames in two different projects. If you see ddev-router status become unhealthy in ddev list , it's most often a result of trying to use conflicting FQDNs in more than one project. example.com can only be assigned to one project, or it will break ddev-router . May not work predictably everywhere This may not work predictably on all systems. There are operating systems and machines where /etc/hosts may not be the first or only resolution technique, especially if the additional_fqdn you use is also in DNS. Don't override a real domain name! If you use an additional_fqdn that exists on the internet (like www.google.com ), your hosts file will override access to the original (internet) site, and you'll be sad and confused that you can't get to it.","title":"Additional Project Hostnames"},{"location":"users/extend/additional-hostnames/#additional-project-hostnames","text":"Add additional hostnames to a project in the project's .ddev/config.yaml: name: mysite additional_hostnames: - \"extraname\" - \"fr.mysite\" - \"es.mysite\" - \"it.mysite\" - \"\\*.lotsofnames\" This configuration would result in working hostnames of mysite.ddev.site , extraname.ddev.site , fr.mysite.ddev.site , es.mysite.ddev.site , and it.mysite.ddev.site (with full http and https URLs for each). In addition, the wildcard *.lotsofnames will result in anything *.lotsofnames.ddev.site being recognized by the project. This works only if you're connected to the internet, using \"ddev.site\" for your top-level-domain, and using DNS for name lookups. (These are all the defaults.) Although we recommend extreme care with this feature , you can also provide additional_fqdn entries, which don't use the .ddev.site top-level domain. This feature populates your hosts file with entries which may hide the real DNS entries on the internet, causing way too much head-scratching. If you use a FQDN which is resolvable on the internet, you must use use_dns_when_possible: false or configure that with ddev config --use-dns-when-possible=false . name: somename additional_fqdns: - example.com - somesite.example.com - anothersite.example.com This configuration would result in working FQDNs of somename.ddev.site , example.com , somesite.example.com , and anothersite.example.com . Don't use the same additional_fqdns or additional_hostnames in two different projects. If you see ddev-router status become unhealthy in ddev list , it's most often a result of trying to use conflicting FQDNs in more than one project. example.com can only be assigned to one project, or it will break ddev-router . May not work predictably everywhere This may not work predictably on all systems. There are operating systems and machines where /etc/hosts may not be the first or only resolution technique, especially if the additional_fqdn you use is also in DNS. Don't override a real domain name! If you use an additional_fqdn that exists on the internet (like www.google.com ), your hosts file will override access to the original (internet) site, and you'll be sad and confused that you can't get to it.","title":"Additional Project Hostnames"},{"location":"users/extend/additional-services/","text":"Additional Service Configurations and Add-ons for ddev \u00b6 DDEV-Local projects can be extended to provide additional add-ons, including services. This is achieved by adding docker-compose files to a project's .ddev directory that defines the added add-on(s). If you need a service not provided here, see Defining an additional service with Docker Compose Although anyone can create their own services with a .ddev/docker-compose.*.yaml file, a growing number of services are supported and tested and can be installed with the ddev get command starting with DDEV v1.19.0+. You can see available supported and tested add-ons with the command ddev get --list . To see all possible add-ons (not necessarily supported or tested), use ddev get --list --all . For example, ddev get --list \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 ADD-ON \u2502 DESCRIPTION \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-elasticsearch \u2502 Elasticsearch add-on for DDEV* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-varnish \u2502 Varnish reverse proxy add-on for ddev* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-redis \u2502 redis service for ddev* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-beanstalkd \u2502 beanstalkd for ddev* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-redis-commander \u2502 Redis commander for use with ddev redis service* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-mongo \u2502 mongodb addon for ddev* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-drupal9-solr \u2502 Drupal 9 Apache Solr installation for DDEV* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-pdfreactor \u2502 PDFreactor service for ddev* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-memcached \u2502 Install memcached as an extra service in ddev* \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Here are some of the add-ons that are officially supported: Redis : ddev get drud/ddev-redis . Redis Commander : ddev get drud/ddev-redis-commander . Elasticsearch : ddev get drud/ddev-elasticsearch . Apache Solr for Drupal 9 : ddev get drud/ddev-drupal9-solr . Memcached : ddev get drud/ddev-memcached . Varnish : ddev get drud/ddev-varnish . Mongo : ddev get drud/ddev-mongo . PDFReactor : ddev get drud/ddev-pdfreactor Beanstalkd : ddev get drud/ddev-beanstalkd . Creating an additional service for ddev get \u00b6 Anyone can create an add-on for ddev get (see screencast and instructions in ddev-addon-template ): Click \"Use this template\" on ddev-addon-template . Create a new repository Test it and preferably make sure it has valid tests in tests.bats . When it's working and tested, create a release. Add the label ddev-get and a good short description to the repository on GitHub. When you're ready for the add-on to become official, open an issue in the DDEV issue queue requesting upgrade to official. You'll be expected to maintain it of course, and subscribe to all activity and be responsive to questions. Sections and features of ddev-get add-on install.yaml \u00b6 The install.yaml is a simple yaml file with a few main sections: pre_install_actions is an array of bash statements or scripts that will be executed before project_files are installed. The actions are executed in the context of the target project's root directory. project_files is an array of files or directories to be copied from the add-on into the target project's .ddev directory. global_files is an array of files or directories to be copied from the add-on into the target system's global .ddev directory ( ~/.ddev/ ). post_install_actions is an array of bash statements or scripts that will be executed after project_files and global_files are installed. The actions are executed in the context of the target project's root directory. yaml_read_files is a map of name: file of yaml files that will be read from the target project's root directory. The contents of these yaml files may be used as templated actions within pre_install_actions and post_install_actions . You can see a simple install.yaml in ddev-addon-template's install.yaml . Environment variable replacements \u00b6 Simple environment variables will be replaced in install.yaml as part of filenames. This can include environment variables in the context of where ddev is being run, as well as the standard environment variables provided to custom host commands, like DDEV_APPROOT , DDEV_DOCROOT , etc. For example, if a file in project_files is listed as somefile.${DDEV_PROJECT}.txt with a project named d10 , the file named somefile.d10.txt will be copied from the add-on into the project. Template action replacements (advanced) \u00b6 A number of additional replacements can be made using go template replacement techniques, using the format {{ .some-gotemplate-action }} . These are mostly for use of yaml information pulled into yaml_read_files . A map of values from each yaml file is placed in a map headed by the name of the yaml file. For example, if a yaml file named `example_yaml.yaml: value1 : xxx is referenced using yaml_read_files : example : example_yaml.yaml then value1 can be used throughout the install.yaml as {{ example.value1 }} and it will be replaced with the value xxx . More exotic template-based replacements can be seen in advanced test example . Additional services in ddev-contrib (MongoDB, Elasticsearch, etc) \u00b6 Commonly used services will be migrated from the ddev-contrib repository to individual, tested, supported repositories, but ddev-contrib repository has a wealth of additional examples and instructions: ElasticHQ :See ElasticHQ . Headless Chrome : See Headless Chrome for Behat Testing MongoDB : See MongoDB . Old PHP Versions to Run Old Sites : See Old PHP Versions RabbitMQ : See RabbitMQ TYPO3 Solr Integration : See TYPO3 Solr Your pull requests to integrate other services are welcome at ddev-contrib .","title":"Additional Service Configurations and Add-ons for ddev"},{"location":"users/extend/additional-services/#additional-service-configurations-and-add-ons-for-ddev","text":"DDEV-Local projects can be extended to provide additional add-ons, including services. This is achieved by adding docker-compose files to a project's .ddev directory that defines the added add-on(s). If you need a service not provided here, see Defining an additional service with Docker Compose Although anyone can create their own services with a .ddev/docker-compose.*.yaml file, a growing number of services are supported and tested and can be installed with the ddev get command starting with DDEV v1.19.0+. You can see available supported and tested add-ons with the command ddev get --list . To see all possible add-ons (not necessarily supported or tested), use ddev get --list --all . For example, ddev get --list \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 ADD-ON \u2502 DESCRIPTION \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-elasticsearch \u2502 Elasticsearch add-on for DDEV* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-varnish \u2502 Varnish reverse proxy add-on for ddev* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-redis \u2502 redis service for ddev* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-beanstalkd \u2502 beanstalkd for ddev* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-redis-commander \u2502 Redis commander for use with ddev redis service* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-mongo \u2502 mongodb addon for ddev* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-drupal9-solr \u2502 Drupal 9 Apache Solr installation for DDEV* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-pdfreactor \u2502 PDFreactor service for ddev* \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 drud/ddev-memcached \u2502 Install memcached as an extra service in ddev* \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Here are some of the add-ons that are officially supported: Redis : ddev get drud/ddev-redis . Redis Commander : ddev get drud/ddev-redis-commander . Elasticsearch : ddev get drud/ddev-elasticsearch . Apache Solr for Drupal 9 : ddev get drud/ddev-drupal9-solr . Memcached : ddev get drud/ddev-memcached . Varnish : ddev get drud/ddev-varnish . Mongo : ddev get drud/ddev-mongo . PDFReactor : ddev get drud/ddev-pdfreactor Beanstalkd : ddev get drud/ddev-beanstalkd .","title":"Additional Service Configurations and Add-ons for ddev"},{"location":"users/extend/additional-services/#creating-an-additional-service-for-ddev-get","text":"Anyone can create an add-on for ddev get (see screencast and instructions in ddev-addon-template ): Click \"Use this template\" on ddev-addon-template . Create a new repository Test it and preferably make sure it has valid tests in tests.bats . When it's working and tested, create a release. Add the label ddev-get and a good short description to the repository on GitHub. When you're ready for the add-on to become official, open an issue in the DDEV issue queue requesting upgrade to official. You'll be expected to maintain it of course, and subscribe to all activity and be responsive to questions.","title":"Creating an additional service for ddev get"},{"location":"users/extend/additional-services/#sections-and-features-of-ddev-get-add-on-installyaml","text":"The install.yaml is a simple yaml file with a few main sections: pre_install_actions is an array of bash statements or scripts that will be executed before project_files are installed. The actions are executed in the context of the target project's root directory. project_files is an array of files or directories to be copied from the add-on into the target project's .ddev directory. global_files is an array of files or directories to be copied from the add-on into the target system's global .ddev directory ( ~/.ddev/ ). post_install_actions is an array of bash statements or scripts that will be executed after project_files and global_files are installed. The actions are executed in the context of the target project's root directory. yaml_read_files is a map of name: file of yaml files that will be read from the target project's root directory. The contents of these yaml files may be used as templated actions within pre_install_actions and post_install_actions . You can see a simple install.yaml in ddev-addon-template's install.yaml .","title":"Sections and features of ddev-get add-on install.yaml"},{"location":"users/extend/additional-services/#environment-variable-replacements","text":"Simple environment variables will be replaced in install.yaml as part of filenames. This can include environment variables in the context of where ddev is being run, as well as the standard environment variables provided to custom host commands, like DDEV_APPROOT , DDEV_DOCROOT , etc. For example, if a file in project_files is listed as somefile.${DDEV_PROJECT}.txt with a project named d10 , the file named somefile.d10.txt will be copied from the add-on into the project.","title":"Environment variable replacements"},{"location":"users/extend/additional-services/#template-action-replacements-advanced","text":"A number of additional replacements can be made using go template replacement techniques, using the format {{ .some-gotemplate-action }} . These are mostly for use of yaml information pulled into yaml_read_files . A map of values from each yaml file is placed in a map headed by the name of the yaml file. For example, if a yaml file named `example_yaml.yaml: value1 : xxx is referenced using yaml_read_files : example : example_yaml.yaml then value1 can be used throughout the install.yaml as {{ example.value1 }} and it will be replaced with the value xxx . More exotic template-based replacements can be seen in advanced test example .","title":"Template action replacements (advanced)"},{"location":"users/extend/additional-services/#additional-services-in-ddev-contrib-mongodb-elasticsearch-etc","text":"Commonly used services will be migrated from the ddev-contrib repository to individual, tested, supported repositories, but ddev-contrib repository has a wealth of additional examples and instructions: ElasticHQ :See ElasticHQ . Headless Chrome : See Headless Chrome for Behat Testing MongoDB : See MongoDB . Old PHP Versions to Run Old Sites : See Old PHP Versions RabbitMQ : See RabbitMQ TYPO3 Solr Integration : See TYPO3 Solr Your pull requests to integrate other services are welcome at ddev-contrib .","title":"Additional services in ddev-contrib (MongoDB, Elasticsearch, etc)"},{"location":"users/extend/custom-commands/","text":"Custom (Shell) Commands \u00b6 It's quite easy to add custom commands to ddev; they can execute either on the host or in the various containers. The basic idea is to add a bash script to either the specific project in .ddev/commands/host or .ddev/commands/<containername> or globally for every project in ~/.ddev/commands There are example commands provided in ddev/commands/*/*.example that can just be copied or moved (or symlinked) and used as commands. For example, .ddev/commands/host/mysqlworkbench.example can be used to add a \"ddev mysqlworkbench\" command, just change it from \"mysqlworkbench.example\" to \"mysqlworkbench\". If you're on macOS or Linux (or some configurations of Windows) you can just cd .ddev/commands/host && ln -s mysqlworkbench.example mysqlworkbench . Also, a new ddev mysql command has been added using this technique (as a db container command). Also see the ddev mysql command . Notes for all command types \u00b6 The command filename is not what determines the name of the command. That comes from the Usage doc line ( ## Usage: commandname ). To confirm that your custom command is available, run ddev -h , and look for it in the list. Host commands \u00b6 To provide host commands, place a bash script in .ddev/commands/host. For example, a PhpStorm launcher to make the ddev PhpStorm command might go in .ddev/commands/host/phpstorm` with these contents: #!/usr/bin/env bash ## Description: Open PhpStorm with the current project ## Usage: phpstorm ## Example: \"ddev phpstorm\" # Example is macOS-specific, but easy to adapt to any OS open -a PhpStorm.app ${ DDEV_APPROOT } Container commands \u00b6 To provide a command which will execute in a container, add a bash script to .ddev/commands/<container_name> , for example, .ddev/commands/web/mycommand . The bash script will be executed inside the named container. For example, see the several standard ddev script-based web container commands , In addition to commands that run in the standard ddev containers like \"web\" and \"db\", you can run commands in custom containers, just using the service name, like .ddev/commands/solr/<command> . Note, however, that your service must mount /mnt/ddev_config as the web and db containers do, so the volumes section of docker-compose.<servicename>.yaml needs: volumes: - \".:/mnt/ddev_config\" For example, to add a solrtail command that runs in a solr service, add .ddev/commands/solr/solrtail with: #!/bin/bash ## Description: Tail the main solr log ## Usage: solrtail ## Example: ddev solrtail tail -f /opt/solr/server/logs/solr.log Global commands \u00b6 Global commands work exactly the same as project-level commands, you just have to put them in your global .ddev directory. Your home directory has a .ddev/commands in it; there you can add host or web or db commands. Shell Command Examples \u00b6 There are many examples of global and project-level custom/shell commands that are provided directly by DDEV, and you can adapt these to your use. They can be found in your ~/.ddev/commands/* directories and in your project's .ddev/commands/* directories. There you'll see how to provide usage, examples, and how to use arguments provided to the commands. For example, the xdebug command shows simple argument processing and the launch command demonstrates flag processing. Environment variables provided \u00b6 A number of environment variables are provided to the script. These are generally supported, but please avoid using undocumented environment variables. Useful variables for host scripts are: DDEV_APPROOT : file system location of the project on the host DDEV_DATABASE : database in use, in format type:version , for example mariadb:10.5 . DDEV_DOCROOT : Relative path from approot to docroot DDEV_HOSTNAME : Comma-separated list of FQDN hostnames DDEV_HOST_DB_PORT : Localhost port of the database server DDEV_HOST_HTTPS_PORT : Localhost port for https on webserver DDEV_HOST_WEBSERVER_PORT : Localhost port of the webserver DDEV_PHP_VERSION : PHP version running DDEV_PRIMARY_URL : Primary URL for the project DDEV_PROJECT : Project name, like \"d8composer\" DDEV_PROJECT_TYPE : drupal8, typo3, backdrop, wordpress, etc. DDEV_ROUTER_HTTP_PORT : Router port for http DDEV_ROUTER_HTTPS_PORT : Router port for https DDEV_SITENAME : Project name, like \"d8composer\". DDEV_TLD : Top-level domain of project, like \"ddev.site\" DDEV_WEBSERVER_TYPE : nginx-fpm, apache-fpm` GOARCH : architecture: \"arm64\", \"amd64\" GOOS : operating system: \"windows\", \"darwin\", \"linux\" Useful variables for container scripts are: DDEV_DOCROOT : Relative path from approot to docroot DDEV_FILES_DIR : Directory of user-uploaded files DDEV_HOSTNAME : Comma-separated list of FQDN hostnames DDEV_PHP_VERSION : PHP version running DDEV_PRIMARY_URL : Primary URL for the project DDEV_PROJECT : Project name, like \"d8composer\" DDEV_PROJECT_TYPE : drupal8, typo3, backdrop, wordpress, etc. DDEV_ROUTER_HTTP_PORT : Router port for http DDEV_ROUTER_HTTPS_PORT : Router port for https DDEV_SITENAME : Project name, like \"d8composer\". DDEV_TLD : Top-level domain of project, like \"ddev.site\" DDEV_WEBSERVER_TYPE : nginx-fpm, apache-fpm IS_DDEV_PROJECT : if set to \"true\" it means that php is running under DDEV Annotations supported \u00b6 The custom commands support various annotations in the header which are used to provide additional information about the command to the user. \"Description\" annotation \u00b6 Description is used for the listing of available commands and for the help message of the custom command. Usage: ## Description: <command-description> Example: ## Description: my great custom command \"Usage\" annotation \u00b6 Usage is used for the help message to provide an idea to the user how to use this command. Usage: ## Usage: <command-usage> Example: ## Usage: commandname [flags] [args] \"Example\" annotation \u00b6 Example is used for the help message to provide some usage examples to the user. Use \\n to force a line break. Usage: ## Example: <command-example> Example: ## Example: commandname\\ncommandname -h \"Flags\" annotation \u00b6 Flags is used for the help message. All defined flags here are listed with their shorthand if available. It has to be encoded according the following definition: Usage: ## Flags: <json-definition> This is the minimal usage of a flags definition: Example: ## Flags: [{\"Name\":\"flag\",\"Usage\":\"sets the flag option\"}] Output: Flags: -h, --help help for ddev -f, --flag sets the flag option Multiple flags are separated by a comma: Example: ## Flags: [{\"Name\":\"flag1\",\"Shorthand\":\"f\",\"Usage\":\"flag1 usage\"},{\"Name\":\"flag2\",\"Usage\":\"flag2 usage\"}] Output: Flags: -h, --help help for ddev -f, --flag1 flag1 usage --flag2 flag2 usage The following fields can be used for a flag definition: Name : the name as it appears on command line Shorthand : one-letter abbreviated flag Usage : help message Type : possible values are bool , string , int , uint (defaults to bool) DefValue : default value for usage message NoOptDefVal : default value, if the flag is on the command line without any options Annotations : used by cobra.Command bash autocomplete code see https://github.com/spf13/cobra/blob/master/bash_completions.md \" ProjectTypes \" annotation \u00b6 If your command should only be visible for a particular project type, ProjectTypes will allow you to define the supported types. This is especially useful for global custom commands. See Quickstart for many CMSs for more information about the supported project types. Multiple types are separated by a comma. Usage: ## ProjectTypes: <list-of-project-types> Example: ## ProjectTypes: drupal7,drupal8,drupal9,backdrop \" OSTypes \" annotation (host commands only) \u00b6 If your host command should only run on one or more operating systems, add the OSTypes annotation. Multiple types are separated by a comma. Valid types are: darwin for macOS windows for Windows linux for Linux Usage: ## OSTypes: <list-of-os-types> Example: ## OSTypes: darwin,linux \" HostBinaryExists \" annotation (host commands only) \u00b6 If your host command should only run if a particular file exists, add the HostBinaryExists annotation. Usage: ## HostBinaryExists: <path/to/file> Example: ## HostBinaryExists: /Applications/Sequel ace.app \" DBTypes \" annotation \u00b6 if your command should only be available for a particular database type, add the DBTypes annotation. Multiple types are separated by a comma. Valid types the available database types. Usage: ## DBTypes: <type> Example: ## DBTypes: postgres Known Windows OS issues \u00b6 Line Endings : If you are editing a custom command which will run in a container, it must have LF line endings (not traditional Windows CRLF line endings). Remember that a custom command in a container is a script that must execute in a Linux environment. If ddev can't find \"bash\" to execute it, then the commands can't be used. If you are running inside git-bash in most any terminal, this shouldn't be an issue, and ddev should be able to find git-bash if it's in C:\\Program Files\\Git\\bin as well. But if neither of those is true, add the directory of bash.exe to your PATH environment variable.","title":"Custom (Shell) Commands"},{"location":"users/extend/custom-commands/#custom-shell-commands","text":"It's quite easy to add custom commands to ddev; they can execute either on the host or in the various containers. The basic idea is to add a bash script to either the specific project in .ddev/commands/host or .ddev/commands/<containername> or globally for every project in ~/.ddev/commands There are example commands provided in ddev/commands/*/*.example that can just be copied or moved (or symlinked) and used as commands. For example, .ddev/commands/host/mysqlworkbench.example can be used to add a \"ddev mysqlworkbench\" command, just change it from \"mysqlworkbench.example\" to \"mysqlworkbench\". If you're on macOS or Linux (or some configurations of Windows) you can just cd .ddev/commands/host && ln -s mysqlworkbench.example mysqlworkbench . Also, a new ddev mysql command has been added using this technique (as a db container command). Also see the ddev mysql command .","title":"Custom (Shell) Commands"},{"location":"users/extend/custom-commands/#notes-for-all-command-types","text":"The command filename is not what determines the name of the command. That comes from the Usage doc line ( ## Usage: commandname ). To confirm that your custom command is available, run ddev -h , and look for it in the list.","title":"Notes for all command types"},{"location":"users/extend/custom-commands/#host-commands","text":"To provide host commands, place a bash script in .ddev/commands/host. For example, a PhpStorm launcher to make the ddev PhpStorm command might go in .ddev/commands/host/phpstorm` with these contents: #!/usr/bin/env bash ## Description: Open PhpStorm with the current project ## Usage: phpstorm ## Example: \"ddev phpstorm\" # Example is macOS-specific, but easy to adapt to any OS open -a PhpStorm.app ${ DDEV_APPROOT }","title":"Host commands"},{"location":"users/extend/custom-commands/#container-commands","text":"To provide a command which will execute in a container, add a bash script to .ddev/commands/<container_name> , for example, .ddev/commands/web/mycommand . The bash script will be executed inside the named container. For example, see the several standard ddev script-based web container commands , In addition to commands that run in the standard ddev containers like \"web\" and \"db\", you can run commands in custom containers, just using the service name, like .ddev/commands/solr/<command> . Note, however, that your service must mount /mnt/ddev_config as the web and db containers do, so the volumes section of docker-compose.<servicename>.yaml needs: volumes: - \".:/mnt/ddev_config\" For example, to add a solrtail command that runs in a solr service, add .ddev/commands/solr/solrtail with: #!/bin/bash ## Description: Tail the main solr log ## Usage: solrtail ## Example: ddev solrtail tail -f /opt/solr/server/logs/solr.log","title":"Container commands"},{"location":"users/extend/custom-commands/#global-commands","text":"Global commands work exactly the same as project-level commands, you just have to put them in your global .ddev directory. Your home directory has a .ddev/commands in it; there you can add host or web or db commands.","title":"Global commands"},{"location":"users/extend/custom-commands/#shell-command-examples","text":"There are many examples of global and project-level custom/shell commands that are provided directly by DDEV, and you can adapt these to your use. They can be found in your ~/.ddev/commands/* directories and in your project's .ddev/commands/* directories. There you'll see how to provide usage, examples, and how to use arguments provided to the commands. For example, the xdebug command shows simple argument processing and the launch command demonstrates flag processing.","title":"Shell Command Examples"},{"location":"users/extend/custom-commands/#environment-variables-provided","text":"A number of environment variables are provided to the script. These are generally supported, but please avoid using undocumented environment variables. Useful variables for host scripts are: DDEV_APPROOT : file system location of the project on the host DDEV_DATABASE : database in use, in format type:version , for example mariadb:10.5 . DDEV_DOCROOT : Relative path from approot to docroot DDEV_HOSTNAME : Comma-separated list of FQDN hostnames DDEV_HOST_DB_PORT : Localhost port of the database server DDEV_HOST_HTTPS_PORT : Localhost port for https on webserver DDEV_HOST_WEBSERVER_PORT : Localhost port of the webserver DDEV_PHP_VERSION : PHP version running DDEV_PRIMARY_URL : Primary URL for the project DDEV_PROJECT : Project name, like \"d8composer\" DDEV_PROJECT_TYPE : drupal8, typo3, backdrop, wordpress, etc. DDEV_ROUTER_HTTP_PORT : Router port for http DDEV_ROUTER_HTTPS_PORT : Router port for https DDEV_SITENAME : Project name, like \"d8composer\". DDEV_TLD : Top-level domain of project, like \"ddev.site\" DDEV_WEBSERVER_TYPE : nginx-fpm, apache-fpm` GOARCH : architecture: \"arm64\", \"amd64\" GOOS : operating system: \"windows\", \"darwin\", \"linux\" Useful variables for container scripts are: DDEV_DOCROOT : Relative path from approot to docroot DDEV_FILES_DIR : Directory of user-uploaded files DDEV_HOSTNAME : Comma-separated list of FQDN hostnames DDEV_PHP_VERSION : PHP version running DDEV_PRIMARY_URL : Primary URL for the project DDEV_PROJECT : Project name, like \"d8composer\" DDEV_PROJECT_TYPE : drupal8, typo3, backdrop, wordpress, etc. DDEV_ROUTER_HTTP_PORT : Router port for http DDEV_ROUTER_HTTPS_PORT : Router port for https DDEV_SITENAME : Project name, like \"d8composer\". DDEV_TLD : Top-level domain of project, like \"ddev.site\" DDEV_WEBSERVER_TYPE : nginx-fpm, apache-fpm IS_DDEV_PROJECT : if set to \"true\" it means that php is running under DDEV","title":"Environment variables provided"},{"location":"users/extend/custom-commands/#annotations-supported","text":"The custom commands support various annotations in the header which are used to provide additional information about the command to the user.","title":"Annotations supported"},{"location":"users/extend/custom-commands/#description-annotation","text":"Description is used for the listing of available commands and for the help message of the custom command. Usage: ## Description: <command-description> Example: ## Description: my great custom command","title":"\"Description\" annotation"},{"location":"users/extend/custom-commands/#usage-annotation","text":"Usage is used for the help message to provide an idea to the user how to use this command. Usage: ## Usage: <command-usage> Example: ## Usage: commandname [flags] [args]","title":"\"Usage\" annotation"},{"location":"users/extend/custom-commands/#example-annotation","text":"Example is used for the help message to provide some usage examples to the user. Use \\n to force a line break. Usage: ## Example: <command-example> Example: ## Example: commandname\\ncommandname -h","title":"\"Example\" annotation"},{"location":"users/extend/custom-commands/#flags-annotation","text":"Flags is used for the help message. All defined flags here are listed with their shorthand if available. It has to be encoded according the following definition: Usage: ## Flags: <json-definition> This is the minimal usage of a flags definition: Example: ## Flags: [{\"Name\":\"flag\",\"Usage\":\"sets the flag option\"}] Output: Flags: -h, --help help for ddev -f, --flag sets the flag option Multiple flags are separated by a comma: Example: ## Flags: [{\"Name\":\"flag1\",\"Shorthand\":\"f\",\"Usage\":\"flag1 usage\"},{\"Name\":\"flag2\",\"Usage\":\"flag2 usage\"}] Output: Flags: -h, --help help for ddev -f, --flag1 flag1 usage --flag2 flag2 usage The following fields can be used for a flag definition: Name : the name as it appears on command line Shorthand : one-letter abbreviated flag Usage : help message Type : possible values are bool , string , int , uint (defaults to bool) DefValue : default value for usage message NoOptDefVal : default value, if the flag is on the command line without any options Annotations : used by cobra.Command bash autocomplete code see https://github.com/spf13/cobra/blob/master/bash_completions.md","title":"\"Flags\" annotation"},{"location":"users/extend/custom-commands/#projecttypes-annotation","text":"If your command should only be visible for a particular project type, ProjectTypes will allow you to define the supported types. This is especially useful for global custom commands. See Quickstart for many CMSs for more information about the supported project types. Multiple types are separated by a comma. Usage: ## ProjectTypes: <list-of-project-types> Example: ## ProjectTypes: drupal7,drupal8,drupal9,backdrop","title":"\"ProjectTypes\" annotation"},{"location":"users/extend/custom-commands/#ostypes-annotation-host-commands-only","text":"If your host command should only run on one or more operating systems, add the OSTypes annotation. Multiple types are separated by a comma. Valid types are: darwin for macOS windows for Windows linux for Linux Usage: ## OSTypes: <list-of-os-types> Example: ## OSTypes: darwin,linux","title":"\"OSTypes\" annotation (host commands only)"},{"location":"users/extend/custom-commands/#hostbinaryexists-annotation-host-commands-only","text":"If your host command should only run if a particular file exists, add the HostBinaryExists annotation. Usage: ## HostBinaryExists: <path/to/file> Example: ## HostBinaryExists: /Applications/Sequel ace.app","title":"\"HostBinaryExists\" annotation (host commands only)"},{"location":"users/extend/custom-commands/#dbtypes-annotation","text":"if your command should only be available for a particular database type, add the DBTypes annotation. Multiple types are separated by a comma. Valid types the available database types. Usage: ## DBTypes: <type> Example: ## DBTypes: postgres","title":"\"DBTypes\" annotation"},{"location":"users/extend/custom-commands/#known-windows-os-issues","text":"Line Endings : If you are editing a custom command which will run in a container, it must have LF line endings (not traditional Windows CRLF line endings). Remember that a custom command in a container is a script that must execute in a Linux environment. If ddev can't find \"bash\" to execute it, then the commands can't be used. If you are running inside git-bash in most any terminal, this shouldn't be an issue, and ddev should be able to find git-bash if it's in C:\\Program Files\\Git\\bin as well. But if neither of those is true, add the directory of bash.exe to your PATH environment variable.","title":"Known Windows OS issues"},{"location":"users/extend/custom-compose-files/","text":"Defining an additional service with docker-compose.*.yaml \u00b6 Prerequisite understanding \u00b6 Much of ddev's customization ability and extensibility comes from leveraging features and functionality provided by Docker and Docker Compose . Some working knowledge of these tools is required in order to customize or extend the environment ddev provides. There are many examples of custom Docker compose files available on ddev-contrib . Background \u00b6 Under the hood, ddev uses a private copy of docker-compose to define and run the multiple containers that make up the local environment for a project. docker-compose supports defining multiple compose files to facilitate sharing Compose configurations between files and projects , and ddev is designed to leverage this ability. To add custom configuration or additional services to your project, create docker-compose files in the .ddev directory for your project. ddev will process any files using the docker-compose.[servicename].yaml naming convention and include them in executing docker-compose functionality. Optionally you can also create a docker-compose.override.yaml to override any configurations from the main .ddev/.ddev-docker-compose-base.yaml or any additional docker-compose files added to your project. !!!note Don't use or edit the .ddev-docker-compose-base.yaml or .ddev-docker-compose-full.yaml The main docker-compose file is named `.ddev/.ddev-docker-compose-base.yaml` and exclusively reserved for ddev's use; it is overwritten every time a project is started, so it should not be edited because edits will be lost. If you need to override configuration provided by .ddev/.ddev-docker-compose-base.yaml, use an additional file \"docker-compose.<whatever>.yaml\" to do so. docker-compose.*.yaml examples \u00b6 Expose an additional port 9999 to host port 9999, in a file perhaps called docker-compose.ports.yaml : version : '3.6' services : someservice : ports : - \"9999:9999\" That approach usually isn't sustainable because two projects might want to use the same port, so we expose the additional port (to the docker network) and then use the ddev-router to bind it to the host. This works only for services with an http API, but results in having both http and https ports (9998 and 9999). version : '3.6' services : someservice : container_name : \"ddev-${DDEV_SITENAME}-someservice\" labels : com.ddev.site-name : ${DDEV_SITENAME} com.ddev.approot : ${DDEV_APPROOT} expose : - \"9999\" environment : - VIRTUAL_HOST=$DDEV_HOSTNAME - HTTP_EXPOSE=9998:9999 - HTTPS_EXPOSE=9999:9999 Confirming docker-compose configurations \u00b6 To better understand how ddev is parsing your custom docker-compose files, you can run ddev debug compose-config to print the final docker-compose configuration as generated by ddev when starting your project. Conventions for defining additional services \u00b6 When defining additional services for your project, we recommended you follow these conventions to ensure ddev handles your service the same way ddev handles default services. The container name should be ddev-${DDEV_SITENAME}-<servicename> Provide containers with required labels: labels : com.ddev.site-name : ${DDEV_SITENAME} com.ddev.approot : ${DDEV_APPROOT} Exposing ports for service: you can expose the port for a service to be accessible as projectname.ddev.site:portNum while your project is running. This is achieved by the following configurations for the container(s) being added: Define only the internal port in the expose section for docker-compose; use ports: only if the port will be bound directly to localhost, as may be required for non-http services. To expose a web interface to be accessible over HTTP, define the following environment variables in the environment section for docker-compose: VIRTUAL_HOST=$DDEV_HOSTNAME HTTP_EXPOSE=portNum The hostPort:containerPort convention may be used here to expose a container's port to a different external port. To expose multiple ports for a single container, define the ports as comma-separated values. HTTPS_EXPOSE=<exposedPortNumber>:portNum This will expose an https interface on <exposedPortNumber> to the host (and to the web container) as https://<project>.ddev.site:exposedPortNumber . To expose multiple ports for a single container, use comma-separated definitions, as in HTTPS_EXPOSE=9998:80,9999:81 , which would expose http port 80 from the container as https://<project>.ddev.site:9998 and http port 81 from the container as https://<project>.ddev.site:9999 . Interacting with additional services \u00b6 ddev exec , ddev ssh , and ddev logs interact with containers on an individual basis. By default, these commands interact with the web container for a project. All of these commands, however, provide a --service or -s flag allowing you to specify the service name of the container you want to interact with. For example, if you added a service to provide Apache Solr, and the service was named solr , you would be able to run ddev logs --service solr to retrieve the logs of the Solr container.","title":"Defining an additional service with `docker-compose.*.yaml`"},{"location":"users/extend/custom-compose-files/#defining-an-additional-service-with-docker-composeyaml","text":"","title":"Defining an additional service with docker-compose.*.yaml"},{"location":"users/extend/custom-compose-files/#prerequisite-understanding","text":"Much of ddev's customization ability and extensibility comes from leveraging features and functionality provided by Docker and Docker Compose . Some working knowledge of these tools is required in order to customize or extend the environment ddev provides. There are many examples of custom Docker compose files available on ddev-contrib .","title":"Prerequisite understanding"},{"location":"users/extend/custom-compose-files/#background","text":"Under the hood, ddev uses a private copy of docker-compose to define and run the multiple containers that make up the local environment for a project. docker-compose supports defining multiple compose files to facilitate sharing Compose configurations between files and projects , and ddev is designed to leverage this ability. To add custom configuration or additional services to your project, create docker-compose files in the .ddev directory for your project. ddev will process any files using the docker-compose.[servicename].yaml naming convention and include them in executing docker-compose functionality. Optionally you can also create a docker-compose.override.yaml to override any configurations from the main .ddev/.ddev-docker-compose-base.yaml or any additional docker-compose files added to your project. !!!note Don't use or edit the .ddev-docker-compose-base.yaml or .ddev-docker-compose-full.yaml The main docker-compose file is named `.ddev/.ddev-docker-compose-base.yaml` and exclusively reserved for ddev's use; it is overwritten every time a project is started, so it should not be edited because edits will be lost. If you need to override configuration provided by .ddev/.ddev-docker-compose-base.yaml, use an additional file \"docker-compose.<whatever>.yaml\" to do so.","title":"Background"},{"location":"users/extend/custom-compose-files/#docker-composeyaml-examples","text":"Expose an additional port 9999 to host port 9999, in a file perhaps called docker-compose.ports.yaml : version : '3.6' services : someservice : ports : - \"9999:9999\" That approach usually isn't sustainable because two projects might want to use the same port, so we expose the additional port (to the docker network) and then use the ddev-router to bind it to the host. This works only for services with an http API, but results in having both http and https ports (9998 and 9999). version : '3.6' services : someservice : container_name : \"ddev-${DDEV_SITENAME}-someservice\" labels : com.ddev.site-name : ${DDEV_SITENAME} com.ddev.approot : ${DDEV_APPROOT} expose : - \"9999\" environment : - VIRTUAL_HOST=$DDEV_HOSTNAME - HTTP_EXPOSE=9998:9999 - HTTPS_EXPOSE=9999:9999","title":"docker-compose.*.yaml examples"},{"location":"users/extend/custom-compose-files/#confirming-docker-compose-configurations","text":"To better understand how ddev is parsing your custom docker-compose files, you can run ddev debug compose-config to print the final docker-compose configuration as generated by ddev when starting your project.","title":"Confirming docker-compose configurations"},{"location":"users/extend/custom-compose-files/#conventions-for-defining-additional-services","text":"When defining additional services for your project, we recommended you follow these conventions to ensure ddev handles your service the same way ddev handles default services. The container name should be ddev-${DDEV_SITENAME}-<servicename> Provide containers with required labels: labels : com.ddev.site-name : ${DDEV_SITENAME} com.ddev.approot : ${DDEV_APPROOT} Exposing ports for service: you can expose the port for a service to be accessible as projectname.ddev.site:portNum while your project is running. This is achieved by the following configurations for the container(s) being added: Define only the internal port in the expose section for docker-compose; use ports: only if the port will be bound directly to localhost, as may be required for non-http services. To expose a web interface to be accessible over HTTP, define the following environment variables in the environment section for docker-compose: VIRTUAL_HOST=$DDEV_HOSTNAME HTTP_EXPOSE=portNum The hostPort:containerPort convention may be used here to expose a container's port to a different external port. To expose multiple ports for a single container, define the ports as comma-separated values. HTTPS_EXPOSE=<exposedPortNumber>:portNum This will expose an https interface on <exposedPortNumber> to the host (and to the web container) as https://<project>.ddev.site:exposedPortNumber . To expose multiple ports for a single container, use comma-separated definitions, as in HTTPS_EXPOSE=9998:80,9999:81 , which would expose http port 80 from the container as https://<project>.ddev.site:9998 and http port 81 from the container as https://<project>.ddev.site:9999 .","title":"Conventions for defining additional services"},{"location":"users/extend/custom-compose-files/#interacting-with-additional-services","text":"ddev exec , ddev ssh , and ddev logs interact with containers on an individual basis. By default, these commands interact with the web container for a project. All of these commands, however, provide a --service or -s flag allowing you to specify the service name of the container you want to interact with. For example, if you added a service to provide Apache Solr, and the service was named solr , you would be able to run ddev logs --service solr to retrieve the logs of the Solr container.","title":"Interacting with additional services"},{"location":"users/extend/custom-tls-certificates/","text":"Custom TLS Certificates \u00b6 It is possible to use \"real\" TLS certificates that have been issued by a CA other than the local-development-oriented mkcert command. Obtain a certificate and key from a Let's Encrypt or another source. Install the certificate and key in your project's .ddev/custom_certs directory. Each cert must be named with the pattern f.q.d.n.crt and f.q.d.n.key . In other words, if you're working with a project \"example.ddev.site\", you would have example.ddev.site.crt and example.ddev.site.key in .ddev/custom_certs . There must be one cert-set for each FQDN handled by the project. ddev start and verify using a browser that you are using the right certificate.","title":"Custom TLS Certificates"},{"location":"users/extend/custom-tls-certificates/#custom-tls-certificates","text":"It is possible to use \"real\" TLS certificates that have been issued by a CA other than the local-development-oriented mkcert command. Obtain a certificate and key from a Let's Encrypt or another source. Install the certificate and key in your project's .ddev/custom_certs directory. Each cert must be named with the pattern f.q.d.n.crt and f.q.d.n.key . In other words, if you're working with a project \"example.ddev.site\", you would have example.ddev.site.crt and example.ddev.site.key in .ddev/custom_certs . There must be one cert-set for each FQDN handled by the project. ddev start and verify using a browser that you are using the right certificate.","title":"Custom TLS Certificates"},{"location":"users/extend/customization-extendibility/","text":"Extending and Customizing Environments \u00b6 ddev provides several ways in which the environment for a project using ddev can be customized and extended. Changing PHP version \u00b6 The project's .ddev/config.yaml file defines the PHP version to use. This can be changed, and the php_version can be set there to 5.6 , 7.0 , 7.1 , 7.2 , 7.3 , 7.4 , 8.0 or 8.1 . The current default is php 7.4. Older versions of PHP \u00b6 Support for older versions of PHP is available on ddev-contrib via custom Docker compose files . Changing webserver type \u00b6 DDEV-Local supports nginx with php-fpm by default (\"nginx-fpm\") and also apache2 with php-fpm (\"apache-fpm\"). These can be changed using the \"webserver_type\" value in .ddev/config.yaml, for example webserver_type: apache-fpm . Adding services to a project \u00b6 For most standard web applications, ddev provides everything you need to successfully provision and develop a web application on your local machine out of the box. More complex and sophisticated web applications, however, often require integration with services beyond the standard requirements of a web and database server. Examples of these additional services are Apache Solr, Redis, Varnish, etc. While ddev likely won't ever provide all of these additional services out of the box, it is designed to provide simple ways for the environment to be customized and extended to meet the needs of your project. A collection of vetted service configurations is available in the Additional Services Documentation . If you need to create a service configuration for your project, see Defining an additional service with Docker Compose Providing custom environment variables to a container \u00b6 Custom environment variables may be set in the project config.yaml or the ~/.ddev/global_config.yaml with the web_environment key, for example web_environment : - SOMEENV=someval - SOMEOTHERENV=someotherval You can also use ddev config global --web-environment-add=\"SOMEENV=someval\" or ddev config --web-environment-add=\"SOMEENV=someval\" for the same purpose. The command just sets the values in the configuration files. (The --web-environment option is also available, but it overwrites existing contents. Alternately, edit .ddev/config.yaml or ~/.ddev/global_config.yaml .) The docker-compose web environment can also provide env file support. To enable this you would create a new docker-compose yaml partial, for example .ddev/docker-compose.env-file.yaml with contents: services: web: env_file: - ../.env You would create the .env file in the project root and provide globals within it as such: SOMEENV='someval' SOMEOTHERENV='someotherval' The globals from the env file would be available on the next ddev start. It is important to note that typically the .env file should not be placed under source control, especially if it contains private API keys or passwords. Altering the in-container $PATH \u00b6 Because many things touch the $PATH environment variable, it's slightly harder to change it, but it's easy: Add a script to <project>/.ddev/homeadditions/.bashrc.d/ or (global) ~/.ddev/homeadditions/.bashrc.d/ that adds to the $PATH variable. For example, if your project vendor directory is not in the expected place ( /var/www/html/vendor/bin ) you can add a <project>/.ddev/homeadditions/.bashrc.d/path.sh with contents: export PATH = $PATH :/var/www/html/somewhereelse/vendor/bin Custom nginx configuration \u00b6 When you ddev start using the nginx-fpm webserver_type, ddev creates a configuration customized to your project type in .ddev/nginx_full/nginx-site.conf . You can edit and override the configuration by removing the #ddev-generated line and doing whatever you need with it. After each change, ddev start . You can also have more than one config file in the .ddev/nginx_full directory, they will all get loaded when ddev starts. This can be used for serving multiple docroots (advanced, below), or for any other technique. Troubleshooting nginx configuration \u00b6 Any errors in your configuration may cause the web container to fail and try to restart, so if you see that behavior, use ddev logs to diagnose it. You can ddev exec nginx -t to test whether your configuration is valid. (Or ddev ssh and run nginx -t ) You can reload the nginx configuration either with ddev start or ddev exec nginx -s reload The alias Alias \"/phpstatus\" \"/var/www/phpstatus.php\" is required for the healthcheck script to work. IMPORTANT : Changes to configuration take place on a ddev start , when the container is rebuilt for another reason, or when the nginx server receives the reload signal. Multiple docroots in nginx (advanced) \u00b6 It's easiest to have different webservers in different ddev projects and different ddev projects can easily communicate with each other , but some sites require more than one docroot for a single project codebase. Sometimes this is because there's an API built in the same codebase but using different code, or different code for different languages, etc. The generated .ddev/nginx_full/seconddocroot.conf.example demonstrates how to do this. You can create as many of these as you want, change the servername and the root and customize as you see fit. Nginx snippets \u00b6 To add an nginx snippet to the default config, add an nginx config file as .ddev/nginx/<something>.conf . This feature will be disabled in the future. Custom apache configuration \u00b6 If you're using webserver_type: apache-fpm in your .ddev/config.yaml, you can override the default site configuration by editing or replacing the ddev-provided .ddev/apache/apache-site.conf configuration. Edit the .ddev/apache/apache-site.conf . Add your configuration changes. Save your configuration file and run ddev start to reload the project. If you encounter issues with your configuration or the project fails to start, use ddev logs to inspect the logs for possible apache configuration errors. Use ddev exec apachectl -t to do a general apache syntax check. The alias Alias \"/phpstatus\" \"/var/www/phpstatus.php\" is required for the healthcheck script to work. Any errors in your configuration may cause the web container to fail, so if you see that behavior, use ddev logs to diagnose. IMPORTANT : Changes to .ddev/apache/apache-site.conf take place on a ddev start . You can also ddev exec apachectl -k graceful to reload the apache configuration. Providing custom PHP configuration (php.ini) \u00b6 You can provide additional PHP configuration for a project by creating a directory called .ddev/php/ and adding any number of php configuration ini files (they must be *.ini files). Normally, you should just override the specific option that you need to override. Note that any file that exists in .ddev/php/ will be copied into /etc/php/[version]/(cli|fpm)/conf.d , so it's possible to replace files that already exist in the container. Common usage is to put custom overrides in a file called my-php.ini . Make sure you include the section header that goes with each item (like [PHP] ) One interesting implication of this behavior is that it's possible to disable extensions by replacing the configuration file that loads them. For instance, if you were to create an empty file at .ddev/php/20-xdebug.ini , it would replace the configuration that loads xdebug, which would cause xdebug to not be loaded! To load the new configuration, just run a ddev restart . An example file in .ddev/php/my-php.ini might look like this: [PHP] max_execution_time = 240; Custom mysql/MariaDB configuration ( my.cnf ) \u00b6 You can provide additional MySQL configuration for a project by creating a directory called .ddev/mysql/ and adding any number of MySQL configuration files (these must have the suffix .cnf ). These files will be automatically included when MySQL is started. Make sure that the section header is included in the file An example file in .ddev/mysql/no_utf8mb4.cnf might be: [mysqld] collation-server = utf8_general_ci character-set-server = utf8 innodb_large_prefix=false To load the new configuration, run ddev restart . Custom Postgresql configuration \u00b6 If you are using Postgresql, a default posgresql.conf is provided in .ddev/postgres/postgresql.conf . If you need to alter it, remove the #ddev-generated line and ddev restart . Extending config.yaml with custom config.\\*.yaml files \u00b6 You may add additional config.*.yaml files to organize additional commands as you see fit for your project and team. For example, many teams commit their config.yaml and share it throughout the team, but some team members may require overrides to the checked-in version that are custom to their environment and should not be checked in. For example, a team member may want to use a router_http_port other than the team default due to a conflict in their development environment. In this case they could add the file .ddev/config.ports.yaml with the contents: # My machine can't use port 80 so override with port 8080, but don't check this in. router_http_port : 8080 config.*.yaml is by default omitted from git by the .ddev/.gitignore file. Extra config.*.yaml files are loaded in lexicographic order, so \"config.a.yaml\" will be overridden by \"config.b.yaml\". Teams may choose to use \"config.local.yaml\" or \"config.override.yaml\" for all local non-committed config changes, for example. config.*.yaml update configuration according to these rules: Simple fields like router_http_port or webserver_type are overwritten. Lists of strings like additional_hostnames or additional_fqdns are merged. The list of environment variables in web_environment are \"smart merged\": if you add the same environment variable with a different value, the value in the override file will replace the value from config.yaml. Hook specifications in the hooks variable are also merged.","title":"Extending and Customizing Environments"},{"location":"users/extend/customization-extendibility/#extending-and-customizing-environments","text":"ddev provides several ways in which the environment for a project using ddev can be customized and extended.","title":"Extending and Customizing Environments"},{"location":"users/extend/customization-extendibility/#changing-php-version","text":"The project's .ddev/config.yaml file defines the PHP version to use. This can be changed, and the php_version can be set there to 5.6 , 7.0 , 7.1 , 7.2 , 7.3 , 7.4 , 8.0 or 8.1 . The current default is php 7.4.","title":"Changing PHP version"},{"location":"users/extend/customization-extendibility/#older-versions-of-php","text":"Support for older versions of PHP is available on ddev-contrib via custom Docker compose files .","title":"Older versions of PHP"},{"location":"users/extend/customization-extendibility/#changing-webserver-type","text":"DDEV-Local supports nginx with php-fpm by default (\"nginx-fpm\") and also apache2 with php-fpm (\"apache-fpm\"). These can be changed using the \"webserver_type\" value in .ddev/config.yaml, for example webserver_type: apache-fpm .","title":"Changing webserver type"},{"location":"users/extend/customization-extendibility/#adding-services-to-a-project","text":"For most standard web applications, ddev provides everything you need to successfully provision and develop a web application on your local machine out of the box. More complex and sophisticated web applications, however, often require integration with services beyond the standard requirements of a web and database server. Examples of these additional services are Apache Solr, Redis, Varnish, etc. While ddev likely won't ever provide all of these additional services out of the box, it is designed to provide simple ways for the environment to be customized and extended to meet the needs of your project. A collection of vetted service configurations is available in the Additional Services Documentation . If you need to create a service configuration for your project, see Defining an additional service with Docker Compose","title":"Adding services to a project"},{"location":"users/extend/customization-extendibility/#providing-custom-environment-variables-to-a-container","text":"Custom environment variables may be set in the project config.yaml or the ~/.ddev/global_config.yaml with the web_environment key, for example web_environment : - SOMEENV=someval - SOMEOTHERENV=someotherval You can also use ddev config global --web-environment-add=\"SOMEENV=someval\" or ddev config --web-environment-add=\"SOMEENV=someval\" for the same purpose. The command just sets the values in the configuration files. (The --web-environment option is also available, but it overwrites existing contents. Alternately, edit .ddev/config.yaml or ~/.ddev/global_config.yaml .) The docker-compose web environment can also provide env file support. To enable this you would create a new docker-compose yaml partial, for example .ddev/docker-compose.env-file.yaml with contents: services: web: env_file: - ../.env You would create the .env file in the project root and provide globals within it as such: SOMEENV='someval' SOMEOTHERENV='someotherval' The globals from the env file would be available on the next ddev start. It is important to note that typically the .env file should not be placed under source control, especially if it contains private API keys or passwords.","title":"Providing custom environment variables to a container"},{"location":"users/extend/customization-extendibility/#altering-the-in-container-path","text":"Because many things touch the $PATH environment variable, it's slightly harder to change it, but it's easy: Add a script to <project>/.ddev/homeadditions/.bashrc.d/ or (global) ~/.ddev/homeadditions/.bashrc.d/ that adds to the $PATH variable. For example, if your project vendor directory is not in the expected place ( /var/www/html/vendor/bin ) you can add a <project>/.ddev/homeadditions/.bashrc.d/path.sh with contents: export PATH = $PATH :/var/www/html/somewhereelse/vendor/bin","title":"Altering the in-container $PATH"},{"location":"users/extend/customization-extendibility/#custom-nginx-configuration","text":"When you ddev start using the nginx-fpm webserver_type, ddev creates a configuration customized to your project type in .ddev/nginx_full/nginx-site.conf . You can edit and override the configuration by removing the #ddev-generated line and doing whatever you need with it. After each change, ddev start . You can also have more than one config file in the .ddev/nginx_full directory, they will all get loaded when ddev starts. This can be used for serving multiple docroots (advanced, below), or for any other technique.","title":"Custom nginx configuration"},{"location":"users/extend/customization-extendibility/#troubleshooting-nginx-configuration","text":"Any errors in your configuration may cause the web container to fail and try to restart, so if you see that behavior, use ddev logs to diagnose it. You can ddev exec nginx -t to test whether your configuration is valid. (Or ddev ssh and run nginx -t ) You can reload the nginx configuration either with ddev start or ddev exec nginx -s reload The alias Alias \"/phpstatus\" \"/var/www/phpstatus.php\" is required for the healthcheck script to work. IMPORTANT : Changes to configuration take place on a ddev start , when the container is rebuilt for another reason, or when the nginx server receives the reload signal.","title":"Troubleshooting nginx configuration"},{"location":"users/extend/customization-extendibility/#multiple-docroots-in-nginx-advanced","text":"It's easiest to have different webservers in different ddev projects and different ddev projects can easily communicate with each other , but some sites require more than one docroot for a single project codebase. Sometimes this is because there's an API built in the same codebase but using different code, or different code for different languages, etc. The generated .ddev/nginx_full/seconddocroot.conf.example demonstrates how to do this. You can create as many of these as you want, change the servername and the root and customize as you see fit.","title":"Multiple docroots in nginx (advanced)"},{"location":"users/extend/customization-extendibility/#nginx-snippets","text":"To add an nginx snippet to the default config, add an nginx config file as .ddev/nginx/<something>.conf . This feature will be disabled in the future.","title":"Nginx snippets"},{"location":"users/extend/customization-extendibility/#custom-apache-configuration","text":"If you're using webserver_type: apache-fpm in your .ddev/config.yaml, you can override the default site configuration by editing or replacing the ddev-provided .ddev/apache/apache-site.conf configuration. Edit the .ddev/apache/apache-site.conf . Add your configuration changes. Save your configuration file and run ddev start to reload the project. If you encounter issues with your configuration or the project fails to start, use ddev logs to inspect the logs for possible apache configuration errors. Use ddev exec apachectl -t to do a general apache syntax check. The alias Alias \"/phpstatus\" \"/var/www/phpstatus.php\" is required for the healthcheck script to work. Any errors in your configuration may cause the web container to fail, so if you see that behavior, use ddev logs to diagnose. IMPORTANT : Changes to .ddev/apache/apache-site.conf take place on a ddev start . You can also ddev exec apachectl -k graceful to reload the apache configuration.","title":"Custom apache configuration"},{"location":"users/extend/customization-extendibility/#providing-custom-php-configuration-phpini","text":"You can provide additional PHP configuration for a project by creating a directory called .ddev/php/ and adding any number of php configuration ini files (they must be *.ini files). Normally, you should just override the specific option that you need to override. Note that any file that exists in .ddev/php/ will be copied into /etc/php/[version]/(cli|fpm)/conf.d , so it's possible to replace files that already exist in the container. Common usage is to put custom overrides in a file called my-php.ini . Make sure you include the section header that goes with each item (like [PHP] ) One interesting implication of this behavior is that it's possible to disable extensions by replacing the configuration file that loads them. For instance, if you were to create an empty file at .ddev/php/20-xdebug.ini , it would replace the configuration that loads xdebug, which would cause xdebug to not be loaded! To load the new configuration, just run a ddev restart . An example file in .ddev/php/my-php.ini might look like this: [PHP] max_execution_time = 240;","title":"Providing custom PHP configuration (php.ini)"},{"location":"users/extend/customization-extendibility/#custom-mysqlmariadb-configuration-mycnf","text":"You can provide additional MySQL configuration for a project by creating a directory called .ddev/mysql/ and adding any number of MySQL configuration files (these must have the suffix .cnf ). These files will be automatically included when MySQL is started. Make sure that the section header is included in the file An example file in .ddev/mysql/no_utf8mb4.cnf might be: [mysqld] collation-server = utf8_general_ci character-set-server = utf8 innodb_large_prefix=false To load the new configuration, run ddev restart .","title":"Custom mysql/MariaDB configuration (my.cnf)"},{"location":"users/extend/customization-extendibility/#custom-postgresql-configuration","text":"If you are using Postgresql, a default posgresql.conf is provided in .ddev/postgres/postgresql.conf . If you need to alter it, remove the #ddev-generated line and ddev restart .","title":"Custom Postgresql configuration"},{"location":"users/extend/customization-extendibility/#extending-configyaml-with-custom-configyaml-files","text":"You may add additional config.*.yaml files to organize additional commands as you see fit for your project and team. For example, many teams commit their config.yaml and share it throughout the team, but some team members may require overrides to the checked-in version that are custom to their environment and should not be checked in. For example, a team member may want to use a router_http_port other than the team default due to a conflict in their development environment. In this case they could add the file .ddev/config.ports.yaml with the contents: # My machine can't use port 80 so override with port 8080, but don't check this in. router_http_port : 8080 config.*.yaml is by default omitted from git by the .ddev/.gitignore file. Extra config.*.yaml files are loaded in lexicographic order, so \"config.a.yaml\" will be overridden by \"config.b.yaml\". Teams may choose to use \"config.local.yaml\" or \"config.override.yaml\" for all local non-committed config changes, for example. config.*.yaml update configuration according to these rules: Simple fields like router_http_port or webserver_type are overwritten. Lists of strings like additional_hostnames or additional_fqdns are merged. The list of environment variables in web_environment are \"smart merged\": if you add the same environment variable with a different value, the value in the override file will replace the value from config.yaml. Hook specifications in the hooks variable are also merged.","title":"Extending config.yaml with custom config.\\*.yaml files"},{"location":"users/extend/customizing-images/","text":"Customizing Docker Images \u00b6 It's common to have a requirement for the web or db images which is not bundled in them by default. There are two easy ways to extend these docker images: webimage_extra_packages and dbimage_extra_packages in .ddev/config.yaml An add-on Dockerfile in your project's .ddev/web-build or .ddev/db-build Adding extra Debian packages with webimage_extra_packages and dbimage_extra_packages \u00b6 You can add extra Debian packages if that's all that is needed with lines like this in .ddev/config.yaml : webimage_extra_packages : [ php-yaml , php7.3-tidy ] dbimage_extra_packages : [ telnet , netcat ] Then the additional packages will be built into the containers during ddev start How to figure out what packages you need \u00b6 The web container is a Debian image, and its PHP distributions are packaged (thank you!) by deb.sury.org . If you need a PHP extension, most PHP extensions are built in the deb.sury.org distribution. You can google the extension you want, or download and search the Packages list from the sury distribution. For example, the bcmath PHP extension is provided by \"php-bcmath\". Many packages have version-specific names, for example php7.3-tidy . If you need a package that is not a PHP package, you can view and search standard Debian packages at packages.debian.org/stable , or just use google. To test that a package will do what you want, you can ddev ssh and then sudo apt-get update && sudo apt-get install <package> to verify that you can install it and you get what you need. A php extension may require killall -USR2 php-fpm to take effect. After you've tried that, you can add the package to webimage_extra_packages . Adding extra Dockerfiles for webimage and dbimage \u00b6 For more complex requirements, you can add: .ddev/web-build/Dockerfile .ddev/web-build/Dockerfile.* .ddev/db-build/Dockerfile .ddev/db-build/Dockerfile.* These files' content will be inserted into the constructed Dockerfile for each image. They are inserted after most of the rest of the things that are done to build the image, and are done in alpha order, so Dockerfile is inserted first, followed by Dockerfile.* in alpha order. For certain use cases, you might need to add stuff very early on the Dockerfile (i.e. proxy settings, SSL termination, etc.) you can also create: .ddev/web-build/pre.Dockerfile.* .ddev/db-build/pre.Dockerfile.* These are inserted before everything else. You can examine the resultant Dockerfile (which should not be changed as it is generated) at .ddev/.webimageBuild/Dockerfile and you can force a rebuild with ddev debug refresh . Examples of possible Dockerfiles are given in .ddev/web-build/Dockerfile.example and .ddev/db-build/Dockerfile.example (these examples are created in your project when you ddev config the project). You can use the .ddev/*-build directory as the Docker \"context\" directory as well. So for example if a file named README.txt exists in .ddev/web-build , you can use ADD README.txt / in the Dockerfile. An example web image .ddev/web-build/Dockerfile might be: RUN npm install -g gatsby-cli Another example would be installing phpcs globally (see Stack Overflow answer ): ENV COMPOSER_HOME = /usr/local/composer # We try to avoid when possible relying on composer to download global, so in PHPCS case we can use the phar. RUN curl -L https://squizlabs.github.io/PHP_CodeSniffer/phpcs.phar -o /usr/local/bin/phpcs && chmod +x /usr/local/bin/phpcs RUN curl -L https://squizlabs.github.io/PHP_CodeSniffer/phpcbf.phar -o /usr/local/bin/phpcbf && chmod +x /usr/local/bin/phpcbf # If however we need to download a package, we use `cgr` for that. RUN composer global require consolidation/cgr RUN $COMPOSER_HOME /vendor/bin/cgr drupal/coder:^8.3.1 RUN $COMPOSER_HOME /vendor/bin/cgr dealerdirect/phpcodesniffer-composer-installer # Register Drupal's code sniffer rules. RUN phpcs --config-set installed_paths $COMPOSER_HOME /global/drupal/coder/vendor/drupal/coder/coder_sniffer --verbose # Make Codesniffer config file writable for ordinary users in container. RUN chmod 666 /usr/local/bin/CodeSniffer.conf # Make COMPOSER_HOME writable if regular users need to use it. RUN chmod -R ugo+rw $COMPOSER_HOME # Now turn it off, because ordinary users will want to be using the default ENV COMPOSER_HOME = \"\" Remember that the Dockerfile is building a docker image that will be used later with ddev. At the time the Dockerfile is executing, your code is not mounted and the container is not running, it's just being built. So for example, an npm install in /var/www/html will not do anything useful because the code is not there at image building time. Debugging the Dockerfile build \u00b6 It can be complicated to figure out what's going on when building a Dockerfile, and even more complicated when you're seeing it go by as part of ddev start . Use ddev ssh first of all to pioneer the steps you want to take. You can just do all the things you need to do there, and see if it works. If doing something that affects PHP you may need to sudo killall -USR2 php-fpm for it to take effect. Put the steps you pioneered into .ddev/web-build/Dockerfile as above. If you can't figure out what's failing or why, then ~/.ddev/bin/docker-compose -f .ddev/.ddev-docker-compose-full.yaml build web --no-cache --progress=plain to see what's happening during the Dockerfile build.","title":"Customizing Docker Images"},{"location":"users/extend/customizing-images/#customizing-docker-images","text":"It's common to have a requirement for the web or db images which is not bundled in them by default. There are two easy ways to extend these docker images: webimage_extra_packages and dbimage_extra_packages in .ddev/config.yaml An add-on Dockerfile in your project's .ddev/web-build or .ddev/db-build","title":"Customizing Docker Images"},{"location":"users/extend/customizing-images/#adding-extra-debian-packages-with-webimage_extra_packages-and-dbimage_extra_packages","text":"You can add extra Debian packages if that's all that is needed with lines like this in .ddev/config.yaml : webimage_extra_packages : [ php-yaml , php7.3-tidy ] dbimage_extra_packages : [ telnet , netcat ] Then the additional packages will be built into the containers during ddev start","title":"Adding extra Debian packages with webimage_extra_packages and dbimage_extra_packages"},{"location":"users/extend/customizing-images/#how-to-figure-out-what-packages-you-need","text":"The web container is a Debian image, and its PHP distributions are packaged (thank you!) by deb.sury.org . If you need a PHP extension, most PHP extensions are built in the deb.sury.org distribution. You can google the extension you want, or download and search the Packages list from the sury distribution. For example, the bcmath PHP extension is provided by \"php-bcmath\". Many packages have version-specific names, for example php7.3-tidy . If you need a package that is not a PHP package, you can view and search standard Debian packages at packages.debian.org/stable , or just use google. To test that a package will do what you want, you can ddev ssh and then sudo apt-get update && sudo apt-get install <package> to verify that you can install it and you get what you need. A php extension may require killall -USR2 php-fpm to take effect. After you've tried that, you can add the package to webimage_extra_packages .","title":"How to figure out what packages you need"},{"location":"users/extend/customizing-images/#adding-extra-dockerfiles-for-webimage-and-dbimage","text":"For more complex requirements, you can add: .ddev/web-build/Dockerfile .ddev/web-build/Dockerfile.* .ddev/db-build/Dockerfile .ddev/db-build/Dockerfile.* These files' content will be inserted into the constructed Dockerfile for each image. They are inserted after most of the rest of the things that are done to build the image, and are done in alpha order, so Dockerfile is inserted first, followed by Dockerfile.* in alpha order. For certain use cases, you might need to add stuff very early on the Dockerfile (i.e. proxy settings, SSL termination, etc.) you can also create: .ddev/web-build/pre.Dockerfile.* .ddev/db-build/pre.Dockerfile.* These are inserted before everything else. You can examine the resultant Dockerfile (which should not be changed as it is generated) at .ddev/.webimageBuild/Dockerfile and you can force a rebuild with ddev debug refresh . Examples of possible Dockerfiles are given in .ddev/web-build/Dockerfile.example and .ddev/db-build/Dockerfile.example (these examples are created in your project when you ddev config the project). You can use the .ddev/*-build directory as the Docker \"context\" directory as well. So for example if a file named README.txt exists in .ddev/web-build , you can use ADD README.txt / in the Dockerfile. An example web image .ddev/web-build/Dockerfile might be: RUN npm install -g gatsby-cli Another example would be installing phpcs globally (see Stack Overflow answer ): ENV COMPOSER_HOME = /usr/local/composer # We try to avoid when possible relying on composer to download global, so in PHPCS case we can use the phar. RUN curl -L https://squizlabs.github.io/PHP_CodeSniffer/phpcs.phar -o /usr/local/bin/phpcs && chmod +x /usr/local/bin/phpcs RUN curl -L https://squizlabs.github.io/PHP_CodeSniffer/phpcbf.phar -o /usr/local/bin/phpcbf && chmod +x /usr/local/bin/phpcbf # If however we need to download a package, we use `cgr` for that. RUN composer global require consolidation/cgr RUN $COMPOSER_HOME /vendor/bin/cgr drupal/coder:^8.3.1 RUN $COMPOSER_HOME /vendor/bin/cgr dealerdirect/phpcodesniffer-composer-installer # Register Drupal's code sniffer rules. RUN phpcs --config-set installed_paths $COMPOSER_HOME /global/drupal/coder/vendor/drupal/coder/coder_sniffer --verbose # Make Codesniffer config file writable for ordinary users in container. RUN chmod 666 /usr/local/bin/CodeSniffer.conf # Make COMPOSER_HOME writable if regular users need to use it. RUN chmod -R ugo+rw $COMPOSER_HOME # Now turn it off, because ordinary users will want to be using the default ENV COMPOSER_HOME = \"\" Remember that the Dockerfile is building a docker image that will be used later with ddev. At the time the Dockerfile is executing, your code is not mounted and the container is not running, it's just being built. So for example, an npm install in /var/www/html will not do anything useful because the code is not there at image building time.","title":"Adding extra Dockerfiles for webimage and dbimage"},{"location":"users/extend/customizing-images/#debugging-the-dockerfile-build","text":"It can be complicated to figure out what's going on when building a Dockerfile, and even more complicated when you're seeing it go by as part of ddev start . Use ddev ssh first of all to pioneer the steps you want to take. You can just do all the things you need to do there, and see if it works. If doing something that affects PHP you may need to sudo killall -USR2 php-fpm for it to take effect. Put the steps you pioneered into .ddev/web-build/Dockerfile as above. If you can't figure out what's failing or why, then ~/.ddev/bin/docker-compose -f .ddev/.ddev-docker-compose-full.yaml build web --no-cache --progress=plain to see what's happening during the Dockerfile build.","title":"Debugging the Dockerfile build"},{"location":"users/extend/database_types/","text":"Database Server Types \u00b6 DDEV-Local supports most versions of MariaDB, MySQL, and Postgresql database servers. The default database type is MariaDB, and the default version is currently 10.3, but you can use nearly any MariaDB versions 5.5-10.7 MySQL 5.5-8.0), and Postgres 9-14. For example, you can use ddev config --database=mysql:5.7 , ddev config --database=mariadb:10.6 , ddev config --database=postgres:14 . In the config.yaml, either any of these, for example: database : type : mariadb version : 10.6 Caveats \u00b6 If you change the database type or version in an existing project, the existing database will not be compatible with your change, so you'll want to use ddev export-db to save a dump first. When you change database type, destroy the existing database using ddev delete --omit-snapshot before changing, then after ddev start use ddev import-db to import the db you exported. Snapshots are always per database type and database version. So if you have snapshots from MariaDB 10.2 and you switch to MariaDB 10.5, don't expect to be able to restore the old snapshot.","title":"Database Server Types"},{"location":"users/extend/database_types/#database-server-types","text":"DDEV-Local supports most versions of MariaDB, MySQL, and Postgresql database servers. The default database type is MariaDB, and the default version is currently 10.3, but you can use nearly any MariaDB versions 5.5-10.7 MySQL 5.5-8.0), and Postgres 9-14. For example, you can use ddev config --database=mysql:5.7 , ddev config --database=mariadb:10.6 , ddev config --database=postgres:14 . In the config.yaml, either any of these, for example: database : type : mariadb version : 10.6","title":"Database Server Types"},{"location":"users/extend/database_types/#caveats","text":"If you change the database type or version in an existing project, the existing database will not be compatible with your change, so you'll want to use ddev export-db to save a dump first. When you change database type, destroy the existing database using ddev delete --omit-snapshot before changing, then after ddev start use ddev import-db to import the db you exported. Snapshots are always per database type and database version. So if you have snapshots from MariaDB 10.2 and you switch to MariaDB 10.5, don't expect to be able to restore the old snapshot.","title":"Caveats"},{"location":"users/extend/in-container-configuration/","text":"In-Container home directory and shell configuration \u00b6 Custom shell configuration (bash or your preferred shell), your usual git configuration, a composer auth.json and more can be achieved within your containers. Place all your dotfiles in your global ~/.ddev/homeadditions or your project's .ddev/homeadditions directory and DDEV will use these in your project's web containers. (Note that there is also a hidden/transient .ddev/.homeadditions ; this is used for processing global homeadditions and should be ignored.) On ddev start , ddev attempts to create a user inside the web and db containers with the same name and use id as the one you have on the host. DDEV looks for the homeadditions directory either in ~/.ddev/homeadditions (the global .ddev directory) or the .ddev/homeadditions directory of a particular project, and will copy their contents recursively into the in-container home directory during ddev start . (Note that project homeadditions contents override the global homeadditions.) Usage examples: If you use git inside the container, you may want to symlink your ~/.gitconfig into ~/.ddev/homeadditions or the project's .ddev/homeadditions so that use of git inside the container will use your regular username and email, etc. For example, ln -s ~/.gitconfig ~/.ddev/homeadditions/.gitconfig . If you use ssh inside the container and want to use your .ssh/config , consider mkdir -p ~/.ddev/homeadditions/.ssh && ln -s ~/.ssh/config ~/.ddev/homeadditions/.ssh/config . Some people will be able to symlink their entire .ssh directory, ln -s ~/.ssh ~/.ddev/homeadditions/ssh . If you provide your own .ssh/config though, please make sure it includes these lines: UserKnownHostsFile=/home/.ssh-agent/known_hosts StrictHostKeyChecking=no If you need to add a script or other executable component into the project (or global configuration), you can put it in the project or global .ddev/homeadditions/bin directory and ~/bin/<script will be created inside the container. This is useful for adding a script to a project or to every project, or for overriding standard scripts, as ~/bin is first in the $PATH in the web container. If you use private password-protected composer repositories with satis, for example, and use a global auth.json, you might want to mkdir -p ~/.ddev/homeadditions/.composer && ln -s ~/.composer/auth.json ~/.ddev/homeadditions/.composer/auth.json , but be careful that you exclude it from getting checked in by using a .gitignore or equivalent. You can add small scripts to the .bashrc.d directory and they will be executed on ddev ssh . For example, add a ~/.ddev/homeadditions/.bashrc.d/whereami containing echo \"I am in the $(hostname) container\" and (after ddev restart ) when you ddev ssh that will be executed. If you have a favorite .bashrc, copy it in to either the global or project homeadditions. If you like the traditional ll bash alias for ls -l , add a .ddev/homeadditions/.bash_aliases with these contents: alias ll=\"ls -lhA\"","title":"In-Container home directory and shell configuration"},{"location":"users/extend/in-container-configuration/#in-container-home-directory-and-shell-configuration","text":"Custom shell configuration (bash or your preferred shell), your usual git configuration, a composer auth.json and more can be achieved within your containers. Place all your dotfiles in your global ~/.ddev/homeadditions or your project's .ddev/homeadditions directory and DDEV will use these in your project's web containers. (Note that there is also a hidden/transient .ddev/.homeadditions ; this is used for processing global homeadditions and should be ignored.) On ddev start , ddev attempts to create a user inside the web and db containers with the same name and use id as the one you have on the host. DDEV looks for the homeadditions directory either in ~/.ddev/homeadditions (the global .ddev directory) or the .ddev/homeadditions directory of a particular project, and will copy their contents recursively into the in-container home directory during ddev start . (Note that project homeadditions contents override the global homeadditions.) Usage examples: If you use git inside the container, you may want to symlink your ~/.gitconfig into ~/.ddev/homeadditions or the project's .ddev/homeadditions so that use of git inside the container will use your regular username and email, etc. For example, ln -s ~/.gitconfig ~/.ddev/homeadditions/.gitconfig . If you use ssh inside the container and want to use your .ssh/config , consider mkdir -p ~/.ddev/homeadditions/.ssh && ln -s ~/.ssh/config ~/.ddev/homeadditions/.ssh/config . Some people will be able to symlink their entire .ssh directory, ln -s ~/.ssh ~/.ddev/homeadditions/ssh . If you provide your own .ssh/config though, please make sure it includes these lines: UserKnownHostsFile=/home/.ssh-agent/known_hosts StrictHostKeyChecking=no If you need to add a script or other executable component into the project (or global configuration), you can put it in the project or global .ddev/homeadditions/bin directory and ~/bin/<script will be created inside the container. This is useful for adding a script to a project or to every project, or for overriding standard scripts, as ~/bin is first in the $PATH in the web container. If you use private password-protected composer repositories with satis, for example, and use a global auth.json, you might want to mkdir -p ~/.ddev/homeadditions/.composer && ln -s ~/.composer/auth.json ~/.ddev/homeadditions/.composer/auth.json , but be careful that you exclude it from getting checked in by using a .gitignore or equivalent. You can add small scripts to the .bashrc.d directory and they will be executed on ddev ssh . For example, add a ~/.ddev/homeadditions/.bashrc.d/whereami containing echo \"I am in the $(hostname) container\" and (after ddev restart ) when you ddev ssh that will be executed. If you have a favorite .bashrc, copy it in to either the global or project homeadditions. If you like the traditional ll bash alias for ls -l , add a .ddev/homeadditions/.bash_aliases with these contents: alias ll=\"ls -lhA\"","title":"In-Container home directory and shell configuration"},{"location":"users/install/","text":"Installation \u00b6 Despite the fact that there are many ways to install and many platforms where DDEV can be installed, it's not hard. This section explains how to install Docker or Colima and then install DDEV on whatever platform you're on. You'll want to read about performance issues and enable Mutagen on macOS. And it's easy to enable shell auto-completion .","title":"Installation"},{"location":"users/install/#installation","text":"Despite the fact that there are many ways to install and many platforms where DDEV can be installed, it's not hard. This section explains how to install Docker or Colima and then install DDEV on whatever platform you're on. You'll want to read about performance issues and enable Mutagen on macOS. And it's easy to enable shell auto-completion .","title":"Installation"},{"location":"users/install/ddev-installation/","text":"DDEV Installation \u00b6 Docker or an alternative is required before anything will work with DDEV. This is pretty easy on most environments; see the docker installation page to help sort out the details. macOS Linux Windows WSL2 Traditional Windows Gitpod.io Manual macOS \u00b6 Homebrew \u00b6 For macOS (both amd64 and arm64) users, Homebrew is the easiest way to install and maintain DDEV: brew install drud/ddev/ddev . As a one-time initialization, run mkcert -install . Later, to upgrade to a newer version of DDEV-Local, run brew upgrade ddev . install_ddev.sh install script \u00b6 On macOS, Linux and Windows WSL2 you can use the install_ddev.sh script Use this line on your terminal to download, verify, and install (or upgrade) ddev using the install_ddev.sh script . Note that this works with both amd64 and arm64 architectures, including Surface Pro X with WSL2 and 64-bit Raspberry Pi OS. It also works with macOS Apple Silicon M1 machines. curl -LO https://raw.githubusercontent.com/drud/ddev/master/scripts/install_ddev.sh && bash install_ddev.sh The installation script can also take a version argument in order to install a specific version or a prerelease version. For example, curl -LO https://raw.githubusercontent.com/drud/ddev/master/scripts/install_ddev.sh && bash install_ddev.sh v1.19.2 To upgrade DDEV to the latest stable version, just run the script again. Linux \u00b6 Apt packages for Debian-based systems \u00b6 DDEV has Debian and RPM packages that work with both apt and yum repositories, and on most any variant that uses those, including Windows WSL2. Debian/Ubuntu and derivative distros - Install the ddev apt repositories with: curl https://apt.fury.io/drud/gpg.key | sudo apt-key add - echo \"deb https://apt.fury.io/drud/ * *\" | sudo tee -a /etc/apt/sources.list.d/ddev.list sudo apt update && sudo apt install -y ddev In the future you can update as usual, with sudo apt update && sudo apt upgrade . If you previously used install_ddev.sh to install DDEV, you can just sudo rm -f /usr/local/bin/ddev /usr/local/bin/mkcert /usr/local/bin/*ddev_nfs_setup.sh to remove the previous version. If you previously used homebrew to install DDEV, you can just brew unlink ddev to get rid of the homebrew version. Yum/RPM packages for Fedora, RedHat, etc. \u00b6 echo '[ddev] name=DDEV Repo baseurl=https://yum.fury.io/drud/ enabled=1 gpgcheck=0' | sudo tee -a /etc/yum.repos.d/ddev.repo sudo dnf install --refresh ddev In the future you can update as usual, with sudo dnf upgrade ddev . (Signed repo support will be added in the near future.) Arch systems \u00b6 For Arch-based systems including Arch Linux , EndeavourOS and Manjaro we maintain the ddev-bin package in AUR. As a one-time initialization, run mkcert -install . Alternate installation approaches: homebrew and install_ddev.sh script \u00b6 You can also use the homebrew and install_ddev.sh script techniques exactly on macOS. Windows WSL2 \u00b6 This is the recommended installation method for all Windows users . All Windows 10/11 editions (including Windows 10 Home) support WSL2 . If you're already familiar with DDEV on Windows, you might have been using NFS for better filesystem performance. You won't need NFS anymore once you switch to WSL2 , since it provides awesome filesystem performance out of the box. The WSL2 install process involves: Installing Chocolatey package manager (optional). One time initialization of mkcert. Installing WSL2 and installing a distro like Ubuntu. Installing or upgrading to the latest Docker Desktop for Windows with WSL2 enabled. Installing DDEV inside your distro. We'll walk through these in more detail. You may prefer other techniques of installation or may not need some steps, but this is the full recipe: Chocolatey: We recommend using Chocolatey for installing required Windows apps like mkcert. In an administrative PowerShell, Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')) In an administrative PowerShell: choco install -y mkcert In an administrative PowerShell, run mkcert -install and answer the prompt allowing the installation of the Certificate Authority. In an administrative PowerShell, run the command setx CAROOT \"$(mkcert -CAROOT)\"; If ($Env:WSLENV -notlike \"*CAROOT/up:*\") { setx WSLENV \"CAROOT/up:$Env:WSLENV\" } . This will set WSL2 to use the Certificate Authority installed on the Windows side. In administrative PowerShell, run the command wsl --install . This will install WSL2 and Ubuntu for you. Reboot when this is done. Docker Desktop for Windows: If you already have the latest Docker Desktop, configure it in the General Settings to use the WSL2-based engine. Otherwise install the latest Docker Desktop for Windows and select the WSL2-based engine (not legacy Hyper-V) when installing. Install via Chocolatey with choco install docker-desktop or it can be downloaded from desktop.docker.com . Start Docker. It may prompt you to log out and log in again, or reboot. Go to Docker Desktop settings > Resources > WSL integration > enable integration for your distro (now docker commands will be available from within your WSL2 distro). Double-check in PowerShell: wsl -l -v should show three distros, and your Ubuntu should be the default. All three should be WSL version 2. Double-check in Ubuntu (or your distro): echo $CAROOT should show something like /mnt/c/Users/<you>/AppData/Local/mkcert Check that docker is working inside Ubuntu (or your distro): docker ps Optional: If you prefer to use the traditional Windows ddev instead of working inside WSL2, install it with choco install -y ddev . The Windows ddev works fine with the WSL2-based Docker engine. However, the WSL2 ddev setup is vastly preferable and at least 10 times as fast. Support for the traditional Windows approach will eventually be dropped. Open the WSL2 terminal, for example Ubuntu from the Windows start menu. Install ddev with curl -LO https://raw.githubusercontent.com/drud/ddev/master/scripts/install_ddev.sh && bash install_ddev.sh sudo apt-get update && sudo apt-get install -y certutil xdg-utils to install the xdg-utils package that allows ddev launch to work. In WSL2 run mkcert -install . That's it! You have now installed DDEV on WSL2. If you're using WSL2 for DDEV (recommended), remember to run all ddev commands inside the WSL2 distro. Follow the instructions in the Linux apt/yum section. Projects go in /home, not on the Windows filesystem Make sure you put your projects in the Linux filesystem (e.g. /home/<your_username> ), not in the Windows filesystem ( /mnt/c ), because you'll get vastly superior performance on the Linux filesystem. You will be very unhappy if you put your project in /mnt/c . Path to certificates Note the prompt Installing to the system store is not yet supported on this Linux , which can be a simple result of not having /usr/sbin in the path so that /usr/sbin/update-ca-certificates can be found.) Traditional Windows \u00b6 DDEV does work fine on the Windows side, although it's quite a bit slower than WSL2 by default, but good results have been reported by users who enabled mutagen, ddev config global --mutagen-enabled . If you use chocolatey (recommended), then you can just choco install ddev git from an administrative shell. Upgrades are just ddev poweroff && choco upgrade ddev . A windows installer is provided in each ddev release ( ddev_windows_installer.<version>.exe ). Run that and it will do the full installation for you. Open a new git-bash or PowerShell or cmd window and start using ddev. Most people interact with ddev on Windows using git-bash, part of the Windows git suite . Although ddev does work with cmd and PowerShell, it's more at home in bash. You can install it with chocolatey using choco install -y git . For performance, many users enable mutagen, ddev config global --mutagen-enabled (global) or ddev config --mutagen-enabled just for one project. Windows Firefox trusted CA The mkcert -install step on Windows does not work for the Firefox browser. You need to add the created root certificate authority to the security configuration by your self: Run mkcert -install (you can use the shortcut from the start menu for that) Run mkcert -CAROOT to see the local folder used for the newly created root certificate authority Open Firefox Preferences (about:preferences#privacy) Enter certificates into the search box on the top Click View Certificates... Select the tab Authorities Click to Import... Go to the folder where your root certificate authority was stored Select the file rootCA.pem Click to Open You should now see your CA under mkcert development CA . Gitpod.io \u00b6 DDEV is fully supported in Gitpod.io, and there are many ways to use it. You don't have to install anything to use it, not Docker, and not DDEV, it's all done for you. Just open any repository using gitpod and brew install drud/ddev/ddev and use ddev as you would normally use it. To use ddev launch you'll need to sudo apt-get update && sudo apt-get install -y xdg-utils . You can just install your web app there, or import a database. You may want to implement one of the ddev pull provider integrations to pull from a hosting provider or an upstream source. Use ddev-gitpod-launcher form to launch a repository. See the actual instructions on the repository . You just click the button and it opens a fully-set-up environment. If a companion artifacts repository with the suffix -artifacts is available, then the db.sql.gz and files.tgz from it will be automatically loaded. Save the following link, Github -> ddev-gitpod , to your bookmark bar; the \"drag-and-drop\" method is easiest. When you are on a git repository, click the new bookmark to open DDEV Gitpod. It does the same thing as the second option, but it works on non-chrome browsers and native browser keyboard shortcuts can be used. It can be complicated to get private databases and files into Gitpod, so in addition to the launchers, The git provider example shows how you can pull database and files without complex setup or permissions. This was created explicitly for Gitpod integration, because in Gitpod you typically already have access to private git repositories, which are a fine place to put a starter database and files. Although ddev-gitpod-launcher and the web extension provide the capability, you may want to integrate a git provider for each project (or, of course, one of the other providers ). Manual installation \u00b6 You can also easily perform the installation or upgrade manually if preferred. DDEV is just a single executable, no special installation is actually required, so for all operating systems, the installation is just copying DDEV into place where it's in the system path. ddev poweroff if upgrading Download and extract the latest ddev release for your architecture. Move ddev to /usr/local/bin: mv ddev /usr/local/bin/ (may require sudo), or another directory in your $PATH as preferred. Run ddev to test your installation. You should see DDEV's command usage output. As a one-time initialization, run mkcert -install , which may require your sudo password. If you don't have mkcert installed, you can install it from https://github.com/FiloSottile/mkcert/releases . Download the version for the correct architecture and sudo mv <downloaded_file> /usr/local/bin/mkcert && sudo chmod +x /usr/local/bin/mkcert .","title":"DDEV Installation"},{"location":"users/install/ddev-installation/#ddev-installation","text":"Docker or an alternative is required before anything will work with DDEV. This is pretty easy on most environments; see the docker installation page to help sort out the details. macOS Linux Windows WSL2 Traditional Windows Gitpod.io Manual","title":"DDEV Installation"},{"location":"users/install/ddev-installation/#macos","text":"","title":"macOS"},{"location":"users/install/ddev-installation/#homebrew","text":"For macOS (both amd64 and arm64) users, Homebrew is the easiest way to install and maintain DDEV: brew install drud/ddev/ddev . As a one-time initialization, run mkcert -install . Later, to upgrade to a newer version of DDEV-Local, run brew upgrade ddev .","title":"Homebrew"},{"location":"users/install/ddev-installation/#install_ddevsh-install-script","text":"On macOS, Linux and Windows WSL2 you can use the install_ddev.sh script Use this line on your terminal to download, verify, and install (or upgrade) ddev using the install_ddev.sh script . Note that this works with both amd64 and arm64 architectures, including Surface Pro X with WSL2 and 64-bit Raspberry Pi OS. It also works with macOS Apple Silicon M1 machines. curl -LO https://raw.githubusercontent.com/drud/ddev/master/scripts/install_ddev.sh && bash install_ddev.sh The installation script can also take a version argument in order to install a specific version or a prerelease version. For example, curl -LO https://raw.githubusercontent.com/drud/ddev/master/scripts/install_ddev.sh && bash install_ddev.sh v1.19.2 To upgrade DDEV to the latest stable version, just run the script again.","title":"install_ddev.sh install script"},{"location":"users/install/ddev-installation/#linux","text":"","title":"Linux"},{"location":"users/install/ddev-installation/#apt-packages-for-debian-based-systems","text":"DDEV has Debian and RPM packages that work with both apt and yum repositories, and on most any variant that uses those, including Windows WSL2. Debian/Ubuntu and derivative distros - Install the ddev apt repositories with: curl https://apt.fury.io/drud/gpg.key | sudo apt-key add - echo \"deb https://apt.fury.io/drud/ * *\" | sudo tee -a /etc/apt/sources.list.d/ddev.list sudo apt update && sudo apt install -y ddev In the future you can update as usual, with sudo apt update && sudo apt upgrade . If you previously used install_ddev.sh to install DDEV, you can just sudo rm -f /usr/local/bin/ddev /usr/local/bin/mkcert /usr/local/bin/*ddev_nfs_setup.sh to remove the previous version. If you previously used homebrew to install DDEV, you can just brew unlink ddev to get rid of the homebrew version.","title":"Apt packages for Debian-based systems"},{"location":"users/install/ddev-installation/#yumrpm-packages-for-fedora-redhat-etc","text":"echo '[ddev] name=DDEV Repo baseurl=https://yum.fury.io/drud/ enabled=1 gpgcheck=0' | sudo tee -a /etc/yum.repos.d/ddev.repo sudo dnf install --refresh ddev In the future you can update as usual, with sudo dnf upgrade ddev . (Signed repo support will be added in the near future.)","title":"Yum/RPM packages for Fedora, RedHat, etc."},{"location":"users/install/ddev-installation/#arch-systems","text":"For Arch-based systems including Arch Linux , EndeavourOS and Manjaro we maintain the ddev-bin package in AUR. As a one-time initialization, run mkcert -install .","title":"Arch systems"},{"location":"users/install/ddev-installation/#alternate-installation-approaches-homebrew-and-install_ddevsh-script","text":"You can also use the homebrew and install_ddev.sh script techniques exactly on macOS.","title":"Alternate installation approaches: homebrew and install_ddev.sh script"},{"location":"users/install/ddev-installation/#windows-wsl2","text":"This is the recommended installation method for all Windows users . All Windows 10/11 editions (including Windows 10 Home) support WSL2 . If you're already familiar with DDEV on Windows, you might have been using NFS for better filesystem performance. You won't need NFS anymore once you switch to WSL2 , since it provides awesome filesystem performance out of the box. The WSL2 install process involves: Installing Chocolatey package manager (optional). One time initialization of mkcert. Installing WSL2 and installing a distro like Ubuntu. Installing or upgrading to the latest Docker Desktop for Windows with WSL2 enabled. Installing DDEV inside your distro. We'll walk through these in more detail. You may prefer other techniques of installation or may not need some steps, but this is the full recipe: Chocolatey: We recommend using Chocolatey for installing required Windows apps like mkcert. In an administrative PowerShell, Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')) In an administrative PowerShell: choco install -y mkcert In an administrative PowerShell, run mkcert -install and answer the prompt allowing the installation of the Certificate Authority. In an administrative PowerShell, run the command setx CAROOT \"$(mkcert -CAROOT)\"; If ($Env:WSLENV -notlike \"*CAROOT/up:*\") { setx WSLENV \"CAROOT/up:$Env:WSLENV\" } . This will set WSL2 to use the Certificate Authority installed on the Windows side. In administrative PowerShell, run the command wsl --install . This will install WSL2 and Ubuntu for you. Reboot when this is done. Docker Desktop for Windows: If you already have the latest Docker Desktop, configure it in the General Settings to use the WSL2-based engine. Otherwise install the latest Docker Desktop for Windows and select the WSL2-based engine (not legacy Hyper-V) when installing. Install via Chocolatey with choco install docker-desktop or it can be downloaded from desktop.docker.com . Start Docker. It may prompt you to log out and log in again, or reboot. Go to Docker Desktop settings > Resources > WSL integration > enable integration for your distro (now docker commands will be available from within your WSL2 distro). Double-check in PowerShell: wsl -l -v should show three distros, and your Ubuntu should be the default. All three should be WSL version 2. Double-check in Ubuntu (or your distro): echo $CAROOT should show something like /mnt/c/Users/<you>/AppData/Local/mkcert Check that docker is working inside Ubuntu (or your distro): docker ps Optional: If you prefer to use the traditional Windows ddev instead of working inside WSL2, install it with choco install -y ddev . The Windows ddev works fine with the WSL2-based Docker engine. However, the WSL2 ddev setup is vastly preferable and at least 10 times as fast. Support for the traditional Windows approach will eventually be dropped. Open the WSL2 terminal, for example Ubuntu from the Windows start menu. Install ddev with curl -LO https://raw.githubusercontent.com/drud/ddev/master/scripts/install_ddev.sh && bash install_ddev.sh sudo apt-get update && sudo apt-get install -y certutil xdg-utils to install the xdg-utils package that allows ddev launch to work. In WSL2 run mkcert -install . That's it! You have now installed DDEV on WSL2. If you're using WSL2 for DDEV (recommended), remember to run all ddev commands inside the WSL2 distro. Follow the instructions in the Linux apt/yum section. Projects go in /home, not on the Windows filesystem Make sure you put your projects in the Linux filesystem (e.g. /home/<your_username> ), not in the Windows filesystem ( /mnt/c ), because you'll get vastly superior performance on the Linux filesystem. You will be very unhappy if you put your project in /mnt/c . Path to certificates Note the prompt Installing to the system store is not yet supported on this Linux , which can be a simple result of not having /usr/sbin in the path so that /usr/sbin/update-ca-certificates can be found.)","title":"Windows WSL2"},{"location":"users/install/ddev-installation/#traditional-windows","text":"DDEV does work fine on the Windows side, although it's quite a bit slower than WSL2 by default, but good results have been reported by users who enabled mutagen, ddev config global --mutagen-enabled . If you use chocolatey (recommended), then you can just choco install ddev git from an administrative shell. Upgrades are just ddev poweroff && choco upgrade ddev . A windows installer is provided in each ddev release ( ddev_windows_installer.<version>.exe ). Run that and it will do the full installation for you. Open a new git-bash or PowerShell or cmd window and start using ddev. Most people interact with ddev on Windows using git-bash, part of the Windows git suite . Although ddev does work with cmd and PowerShell, it's more at home in bash. You can install it with chocolatey using choco install -y git . For performance, many users enable mutagen, ddev config global --mutagen-enabled (global) or ddev config --mutagen-enabled just for one project. Windows Firefox trusted CA The mkcert -install step on Windows does not work for the Firefox browser. You need to add the created root certificate authority to the security configuration by your self: Run mkcert -install (you can use the shortcut from the start menu for that) Run mkcert -CAROOT to see the local folder used for the newly created root certificate authority Open Firefox Preferences (about:preferences#privacy) Enter certificates into the search box on the top Click View Certificates... Select the tab Authorities Click to Import... Go to the folder where your root certificate authority was stored Select the file rootCA.pem Click to Open You should now see your CA under mkcert development CA .","title":"Traditional Windows"},{"location":"users/install/ddev-installation/#gitpodio","text":"DDEV is fully supported in Gitpod.io, and there are many ways to use it. You don't have to install anything to use it, not Docker, and not DDEV, it's all done for you. Just open any repository using gitpod and brew install drud/ddev/ddev and use ddev as you would normally use it. To use ddev launch you'll need to sudo apt-get update && sudo apt-get install -y xdg-utils . You can just install your web app there, or import a database. You may want to implement one of the ddev pull provider integrations to pull from a hosting provider or an upstream source. Use ddev-gitpod-launcher form to launch a repository. See the actual instructions on the repository . You just click the button and it opens a fully-set-up environment. If a companion artifacts repository with the suffix -artifacts is available, then the db.sql.gz and files.tgz from it will be automatically loaded. Save the following link, Github -> ddev-gitpod , to your bookmark bar; the \"drag-and-drop\" method is easiest. When you are on a git repository, click the new bookmark to open DDEV Gitpod. It does the same thing as the second option, but it works on non-chrome browsers and native browser keyboard shortcuts can be used. It can be complicated to get private databases and files into Gitpod, so in addition to the launchers, The git provider example shows how you can pull database and files without complex setup or permissions. This was created explicitly for Gitpod integration, because in Gitpod you typically already have access to private git repositories, which are a fine place to put a starter database and files. Although ddev-gitpod-launcher and the web extension provide the capability, you may want to integrate a git provider for each project (or, of course, one of the other providers ).","title":"Gitpod.io"},{"location":"users/install/ddev-installation/#manual-installation","text":"You can also easily perform the installation or upgrade manually if preferred. DDEV is just a single executable, no special installation is actually required, so for all operating systems, the installation is just copying DDEV into place where it's in the system path. ddev poweroff if upgrading Download and extract the latest ddev release for your architecture. Move ddev to /usr/local/bin: mv ddev /usr/local/bin/ (may require sudo), or another directory in your $PATH as preferred. Run ddev to test your installation. You should see DDEV's command usage output. As a one-time initialization, run mkcert -install , which may require your sudo password. If you don't have mkcert installed, you can install it from https://github.com/FiloSottile/mkcert/releases . Download the version for the correct architecture and sudo mv <downloaded_file> /usr/local/bin/mkcert && sudo chmod +x /usr/local/bin/mkcert .","title":"Manual installation"},{"location":"users/install/docker-installation/","text":"Docker Installation \u00b6 macOS Windows Linux Gitpod.io macOS \u00b6 The two easy docker providers for macOS are Colima and Docker Desktop for Mac. You only need one of them. Colima \u00b6 Colima the preferred docker provider for macOS. Colima is an open-source project that bundles the container management tool lima with a docker (linux) back-end. This is similar to what Docker Desktop actually does, but Colima and Lima are entirely open-source and just focused on running containers. They work on both amd64 and arm64 (M1) macs. Colima does not require installation of Docker Desktop, or does it require paying a license fee to Docker, Inc., and it seems to be the most stable alternative at this time. Reasons to use Colima include: Preferring to use open-source software (Docker Desktop, unlike Docker, is proprietary software). Working for an organization that due to its size requires a paid Docker plan to use Docker Desktop, and wanting to avoid that cost and business relationship. Preferring a CLI-focused approach to Docker Desktop's GUI focus. Stability Install the docker client if you need it If you don't have the docker client installed, you'll need to install it. (If docker help returns an error, you don't have it.) Use brew install docker to install it. Install colima with brew install colima using homebrew or see the other installation options . Configure your system to use mutagen, which is nearly essential for Colima. ddev config global --mutagen-enabled . Start colima: colima start --cpu 4 --memory 4 will set up a colima instance with 4 CPUs and 4GB of memory allocated. Your needs may vary. After the first start you can just use colima start . Use colima start -e to edit the configuration file. colima status will show colima's status. After a computer restart you'll need to colima start again. This will eventually be automated in later versions of colima. Docker contexts let the docker client point at the right docker server Colima activates its own docker context in order to not conflict with Docker Desktop, so if you docker context ls you'll see a list of available contexts with currently active context indicated with an \"*\" (which will be \"colima\" after you've started colima). You can change to the default (Docker Desktop) with docker context use default or change back with docker context use colima . This means you can actually run Docker Desktop and Colima at the same time... but be careful which context you're pointing at. DDEV has extensive automated test coverage for colima on macOS, but of course Colima is young, so please share your results and open issues or contact us for help. Moving projects from Docker Desktop to Colima \u00b6 To move project databases from Docker Desktop to Colima: Make sure all your projects are listed in ddev list In Docker Desktop, ddev snapshot --all After starting Colima, start each project as needed and ddev snapshot restore --latest Docker Desktop for Mac \u00b6 Docker Desktop for Mac can be installed via Homebrew ( brew install homebrew/cask/docker ) or can be downloaded from docker.com . It has long been supported by DDEV and has extensive automated testing. Windows \u00b6 On Windows, you can install Docker Desktop, which works with both traditional Windows and WSL2, or if you're working inside WSL2 (recommended) you can just install docker engine (docker-ce) inside WSL2. Docker Desktop for Windows \u00b6 Docker Desktop for Windows can be downloaded via Chocolatey with choco install docker-desktop or it can be downloaded from docker.com . It has extensive automated testing with DDEV, and works with DDEV both on traditional Windows and in WSL2. Windows WSL2: Docker-ce installed inside WSL2\" \u00b6 Although the traditional approach on Windows/WSL2 has been to use Docker Desktop, a number of people have moved away from using Docker Desktop and just installing the Docker-provided open-source docker-ce package inside WSL2. This uses entirely open-source software and does not require a license fee to Docker, Inc. Most of the installation is the same as on Linux, but it can be summarized as: If you don't already have WSL2, install it with wsl --install , which will likely require a reboot. wsl --set-default-version 2 Install a distro. Ubuntu 20.04 is recommended, wsl -s Ubuntu-20.04 . Install docker-ce in WSL2 using the normal Linux instructions, for Debian/Ubuntu follow these instructions inside the WSL2 distro: sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get update && sudo apt-get install ca-certificates curl gnupg lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \"deb [arch= $( dpkg --print-architecture ) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null sudo apt-get update && sudo apt-get install docker-ce docker-ce-cli containerd.io sudo groupadd docker && sudo usermod -aG docker $USER You have to start docker-ce yourself on login, or use a script to do it. To have it start on entry to git-bash, a startup line to your (windows-side) ~/.bashrc with: echo \"wsl.exe -u root service docker status > /dev/null || wsl.exe -u root service docker start > /dev/null\" >> ~/.bashrc You can then source ~/.bashrc to start immediately, or it should start the next time you open git-bash. Install mkcert on the Windows side; this may be easiest with Chocolatey : In an administrative PowerShell, Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')) In an administrative PowerShell: choco install -y mkcert In an administrative PowerShell, run mkcert -install and answer the prompt allowing the installation of the Certificate Authority. In an administrative PowerShell, run the command setx CAROOT \"$(mkcert -CAROOT)\"; If ($Env:WSLENV -notlike \"*CAROOT/up:*\") { setx WSLENV \"CAROOT/up:$Env:WSLENV\" } . This will set WSL2 to use the Certificate Authority installed on the Windows side. Double-check in Ubuntu (or your distro): echo $CAROOT should show something like /mnt/c/Users/<you>/AppData/Local/mkcert Inside your WSL2 distro, mkcert -install . Linux \u00b6 Don't forget the Docker-ce post-install steps Please don't forget that Linux installation absolutely requires post-install steps (below). Don't use sudo with the docker command Please don't use sudo with docker. If you're needing it, you haven't finished the installation. Don't use sudo with ddev, except the rare case where you need the ddev hostname command. Docker Desktop for Linux is not yet mature enough to use The release of Docker Desktop for Linux in 2022 was welcomed by many, but the system does not yet seem stable enough for predictable use, and has some of the problems of Docker Desktop on other platforms. We recommend that you stay with the traditional docker-ce installation described here. Docker installation on Linux depends on what flavor you're using. Where possible the Ubuntu/Deb/yum repository is the preferred technique. Ubuntu CentOS Debian Fedora binaries One-time post-installation step Required post-installation steps: See Docker's post-installation steps . You need to add your linux user to the \"docker\" group and configure the docker daemon to start on boot. sudo groupadd docker sudo usermod -aG docker $USER On systems that do not include systemd or equivalent (mostly if installing inside WSL2) you'll need to manually start docker with service docker start or the equivalent in your distro. You can add this into your ~/.profile or equivalent. Gitpod.io \u00b6 With gitpod.io you don't have to install anything at all. Docker is all set up for you. Testing and Troubleshooting Your Docker Installation \u00b6 Docker needs to be able to do a few things for ddev to work: Mount the project code directory from the host into the container; the project code directory is usually somewhere in a subdirectory of your home directory. Access TCP ports on the host to serve HTTP and HTTPS. These are ports 80 and 443 by default, but they can be changed on a per-project basis. We can use a single docker command to make sure that docker is set up to do what we want: In your project directory run docker run --rm -t -p 80:80 -p 443:443 -v \"//$PWD:/tmp/projdir\" busybox sh -c \"echo ---- Project Directory && ls /tmp/projdir\" - you should see the files in your project directory displayed. (On Windows, make sure you run this using git-bash.) If that fails (if you get an error, or you don't see the contents of your project directory and your home directory) you'll need to troubleshoot: \"port is already allocated\": See troubleshooting . invalid mount config for type \"bind\": bind mount source path does not exist: <some path> means the filesystem isn't successfully shared into the docker container. \"The path ... is not shared and is not known to Docker\": Visit docker's preferences/settings->File sharing and share the appropriate path or drive. Error response from daemon: Get https://registry-1.docker.io/v2/ - Docker may not be running (restart it) or you may not have any access to the internet. \"403 authentication required\" when trying to ddev start : Try docker logout and do it again. Docker authentication is not required for any normal ddev action.","title":"Docker Installation"},{"location":"users/install/docker-installation/#docker-installation","text":"macOS Windows Linux Gitpod.io","title":"Docker Installation"},{"location":"users/install/docker-installation/#macos","text":"The two easy docker providers for macOS are Colima and Docker Desktop for Mac. You only need one of them.","title":"macOS"},{"location":"users/install/docker-installation/#colima","text":"Colima the preferred docker provider for macOS. Colima is an open-source project that bundles the container management tool lima with a docker (linux) back-end. This is similar to what Docker Desktop actually does, but Colima and Lima are entirely open-source and just focused on running containers. They work on both amd64 and arm64 (M1) macs. Colima does not require installation of Docker Desktop, or does it require paying a license fee to Docker, Inc., and it seems to be the most stable alternative at this time. Reasons to use Colima include: Preferring to use open-source software (Docker Desktop, unlike Docker, is proprietary software). Working for an organization that due to its size requires a paid Docker plan to use Docker Desktop, and wanting to avoid that cost and business relationship. Preferring a CLI-focused approach to Docker Desktop's GUI focus. Stability Install the docker client if you need it If you don't have the docker client installed, you'll need to install it. (If docker help returns an error, you don't have it.) Use brew install docker to install it. Install colima with brew install colima using homebrew or see the other installation options . Configure your system to use mutagen, which is nearly essential for Colima. ddev config global --mutagen-enabled . Start colima: colima start --cpu 4 --memory 4 will set up a colima instance with 4 CPUs and 4GB of memory allocated. Your needs may vary. After the first start you can just use colima start . Use colima start -e to edit the configuration file. colima status will show colima's status. After a computer restart you'll need to colima start again. This will eventually be automated in later versions of colima. Docker contexts let the docker client point at the right docker server Colima activates its own docker context in order to not conflict with Docker Desktop, so if you docker context ls you'll see a list of available contexts with currently active context indicated with an \"*\" (which will be \"colima\" after you've started colima). You can change to the default (Docker Desktop) with docker context use default or change back with docker context use colima . This means you can actually run Docker Desktop and Colima at the same time... but be careful which context you're pointing at. DDEV has extensive automated test coverage for colima on macOS, but of course Colima is young, so please share your results and open issues or contact us for help.","title":"Colima"},{"location":"users/install/docker-installation/#moving-projects-from-docker-desktop-to-colima","text":"To move project databases from Docker Desktop to Colima: Make sure all your projects are listed in ddev list In Docker Desktop, ddev snapshot --all After starting Colima, start each project as needed and ddev snapshot restore --latest","title":"Moving projects from Docker Desktop to Colima"},{"location":"users/install/docker-installation/#docker-desktop-for-mac","text":"Docker Desktop for Mac can be installed via Homebrew ( brew install homebrew/cask/docker ) or can be downloaded from docker.com . It has long been supported by DDEV and has extensive automated testing.","title":"Docker Desktop for Mac"},{"location":"users/install/docker-installation/#windows","text":"On Windows, you can install Docker Desktop, which works with both traditional Windows and WSL2, or if you're working inside WSL2 (recommended) you can just install docker engine (docker-ce) inside WSL2.","title":"Windows"},{"location":"users/install/docker-installation/#docker-desktop-for-windows","text":"Docker Desktop for Windows can be downloaded via Chocolatey with choco install docker-desktop or it can be downloaded from docker.com . It has extensive automated testing with DDEV, and works with DDEV both on traditional Windows and in WSL2.","title":"Docker Desktop for Windows"},{"location":"users/install/docker-installation/#windows-wsl2-docker-ce-installed-inside-wsl2","text":"Although the traditional approach on Windows/WSL2 has been to use Docker Desktop, a number of people have moved away from using Docker Desktop and just installing the Docker-provided open-source docker-ce package inside WSL2. This uses entirely open-source software and does not require a license fee to Docker, Inc. Most of the installation is the same as on Linux, but it can be summarized as: If you don't already have WSL2, install it with wsl --install , which will likely require a reboot. wsl --set-default-version 2 Install a distro. Ubuntu 20.04 is recommended, wsl -s Ubuntu-20.04 . Install docker-ce in WSL2 using the normal Linux instructions, for Debian/Ubuntu follow these instructions inside the WSL2 distro: sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get update && sudo apt-get install ca-certificates curl gnupg lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \"deb [arch= $( dpkg --print-architecture ) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null sudo apt-get update && sudo apt-get install docker-ce docker-ce-cli containerd.io sudo groupadd docker && sudo usermod -aG docker $USER You have to start docker-ce yourself on login, or use a script to do it. To have it start on entry to git-bash, a startup line to your (windows-side) ~/.bashrc with: echo \"wsl.exe -u root service docker status > /dev/null || wsl.exe -u root service docker start > /dev/null\" >> ~/.bashrc You can then source ~/.bashrc to start immediately, or it should start the next time you open git-bash. Install mkcert on the Windows side; this may be easiest with Chocolatey : In an administrative PowerShell, Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')) In an administrative PowerShell: choco install -y mkcert In an administrative PowerShell, run mkcert -install and answer the prompt allowing the installation of the Certificate Authority. In an administrative PowerShell, run the command setx CAROOT \"$(mkcert -CAROOT)\"; If ($Env:WSLENV -notlike \"*CAROOT/up:*\") { setx WSLENV \"CAROOT/up:$Env:WSLENV\" } . This will set WSL2 to use the Certificate Authority installed on the Windows side. Double-check in Ubuntu (or your distro): echo $CAROOT should show something like /mnt/c/Users/<you>/AppData/Local/mkcert Inside your WSL2 distro, mkcert -install .","title":"Windows WSL2: Docker-ce installed inside WSL2\""},{"location":"users/install/docker-installation/#linux","text":"Don't forget the Docker-ce post-install steps Please don't forget that Linux installation absolutely requires post-install steps (below). Don't use sudo with the docker command Please don't use sudo with docker. If you're needing it, you haven't finished the installation. Don't use sudo with ddev, except the rare case where you need the ddev hostname command. Docker Desktop for Linux is not yet mature enough to use The release of Docker Desktop for Linux in 2022 was welcomed by many, but the system does not yet seem stable enough for predictable use, and has some of the problems of Docker Desktop on other platforms. We recommend that you stay with the traditional docker-ce installation described here. Docker installation on Linux depends on what flavor you're using. Where possible the Ubuntu/Deb/yum repository is the preferred technique. Ubuntu CentOS Debian Fedora binaries One-time post-installation step Required post-installation steps: See Docker's post-installation steps . You need to add your linux user to the \"docker\" group and configure the docker daemon to start on boot. sudo groupadd docker sudo usermod -aG docker $USER On systems that do not include systemd or equivalent (mostly if installing inside WSL2) you'll need to manually start docker with service docker start or the equivalent in your distro. You can add this into your ~/.profile or equivalent.","title":"Linux"},{"location":"users/install/docker-installation/#gitpodio","text":"With gitpod.io you don't have to install anything at all. Docker is all set up for you.","title":"Gitpod.io"},{"location":"users/install/docker-installation/#testing-and-troubleshooting-your-docker-installation","text":"Docker needs to be able to do a few things for ddev to work: Mount the project code directory from the host into the container; the project code directory is usually somewhere in a subdirectory of your home directory. Access TCP ports on the host to serve HTTP and HTTPS. These are ports 80 and 443 by default, but they can be changed on a per-project basis. We can use a single docker command to make sure that docker is set up to do what we want: In your project directory run docker run --rm -t -p 80:80 -p 443:443 -v \"//$PWD:/tmp/projdir\" busybox sh -c \"echo ---- Project Directory && ls /tmp/projdir\" - you should see the files in your project directory displayed. (On Windows, make sure you run this using git-bash.) If that fails (if you get an error, or you don't see the contents of your project directory and your home directory) you'll need to troubleshoot: \"port is already allocated\": See troubleshooting . invalid mount config for type \"bind\": bind mount source path does not exist: <some path> means the filesystem isn't successfully shared into the docker container. \"The path ... is not shared and is not known to Docker\": Visit docker's preferences/settings->File sharing and share the appropriate path or drive. Error response from daemon: Get https://registry-1.docker.io/v2/ - Docker may not be running (restart it) or you may not have any access to the internet. \"403 authentication required\" when trying to ddev start : Try docker logout and do it again. Docker authentication is not required for any normal ddev action.","title":"Testing and Troubleshooting Your Docker Installation"},{"location":"users/install/performance/","text":"Performance and Mutagen \u00b6 Every developer wants both fast startup of the environment and quick response to web page requests. DDEV is always focused on improving performance. However, both Docker Desktop on macOS and Windows has significant performance problems with mounted filesystems (like the mounted project where code can be edited either inside the container or on the host). Folks are usually happy with webserving performance right away on Linux, which includes Windows WSL2 and Gitpod.io, so there's not usually anything to do. On macOS and traditional Windows, the Docker environment has performance problems getting files synced between the host and the container, and that causes slowdowns in webserving. Currently, most people are using Mutagen on macOS. It's fast, requires no installation or configuration (besides turning it on with ddev config --mutagen-enabled ), and although there are caveats below it has worked really, really well. In the past, lots of folks configured NFS on macOS and Windows to speed things up, and it helped, but nowhere near as much as Mutagen, and there is some manual system configuration required. Instructions for Mutagen and NFS are below. Mutagen NFS Mutagen \u00b6 TL;DR: If you're on macOS or Windows just enable mutagen. ddev config global --mutagen-enabled . You'll be glad you did. The Mutagen asynchronous caching feature offers advanced performance experiences and is recommended for most projects. It's now the preferred way to get great webserving performance on macOS and Windows. Unlike the NFS feature, it requires no pre-configuration or installation. You do not need to (and should not) install mutagen. It can also be significantly faster than NFS and massively faster than plain vanilla Docker or Colima. In addition, it makes filesystem watchers (fsnotify/inotify) work correctly. Mutagen can offer massive webserver performance speedups on macOS and traditional Windows; it works fine (and has automated tests) on Linux or Windows WSL2, but the speedup you see may not be worth turning it on, since Linux/WSL2 are already so fast. Docker bind-mounts (the traditional approach to getting your code into the DDEV web container) can be slow on macOS and Windows, even with NFS. The reason is that every file access has to be checked against the file on the host, and Docker's setup to do this on macOS and Windows offers is not very performant. (On Linux and Linux-like systems, Docker provides native file-access performance.) Mutagen works by decoupling reads and writes inside the container from reads and writes on the host. If something changes on the host, it gets changed \"pretty soon\" in the container, and if something changes inside the container it gets updated \"pretty soon\" on the host. This means that the webserver inside the web container does not have to wait for slow file reads or writes, and gets near-native file speeds. However, it also means that at any given moment, the files on the host may not exactly match the files inside the container, and if files are changed both places, conflicts may result. Another major advantage of Mutagen over NFS is that it supports filesystem notifications, so file-watchers on both the host and inside the container will be notified when changes occur. This is a great advantage for many development tools, which had to poll for changes in the past, but now will be notified via normal inotify/fsnotify techniques. If you trouble with the Mutagen feature, please try to recreate it and report via one of the support channels . Enabling Mutagen \u00b6 Do not separately install mutagen Do not separately install the mutagen binary. It's better if you don't have it installed. DDEV does the installation and upgrades when needed. To begin using Mutagen, just ddev stop and then ddev config --mutagen-enabled and start the project again. If the mutagen binary needs to be downloaded, it will be downloaded automatically. To stop using Mutagen on a project, ddev mutagen reset && ddev config --mutagen-enabled=false . You can also enable mutagen globally (recommended) with ddev config global --mutagen-enabled Note that the nfs-mount-enabled feature is automatically turned off if you're using mutagen. You can run mutagen on all your projects, there's no limit. To configure it globally, ddev config global --mutagen-enabled , but you cannot disable mutagen on individual projects if it's enabled globally (the global configuration wins). Caveats about Mutagen Integration \u00b6 Most people have an excellent experience with Mutagen, but it's good to understand how it works and what the trade-offs are: Not for every project : Mutagen is not the right choice for every project. If filesystem consistency is your highest priority (as opposed to performance) then there are reasons to be cautious, although people have had excellent experiences: there haven't been major issues reported, but two-way sync is a very difficult computational problem, and problems may surface. Only one mutagen version on machine please : DDEV installs its own mutagen. You do not need to install mutagen. Multiple mutagen versions can't coexist on one machine, so please stop any running mutagen. On macOS, killall mutagen . If you absolutely have to have mutagen installed via homebrew or another technique (for another project) make sure it's the same version as you get with ddev version . Works everywhere, best on macOS and Windows : This is mostly for macOS and traditional Windows users. WSL2 is already the preferred environment for Windows users, but if you're still using traditional Windows this makes a huge difference. Although DDEV with mutagen is fully supported and tested on traditional Windows and Linux/WSL2, enabling mutagen on Linux/WSL2 may not be your first choice, since it adds some complexity and very little performance. Increased disk usage : Mutagen integration increases the size of your project code disk usage, because the code exists both on your computer and also inside a docker volume. (As of v1.19+, this does not include your file upload directory, so normally it's not too intrusive.) So take care that you have enough overall disk space, and also (on macOS) that you have enough file space set up in Docker Desktop. For projects before v1.19, if you have a large amount of data like user-generated content that does not need syncing (i.e. fileadmin for TYPO3 or sites/default/files for Drupal), you can exclude specific directories from getting synced and use regular docker mount for them instead. See below for Advanced Mutagen configuration options . As of v1.19, this is handled automatically and these files are not mutagen-synced. If your project is likely to change the same file on both the host and inside the container, you may be at risk for conflicts. Massive changes to either the host or the container are the most likely to introduce issues. This integration has been tested extensively with major changes introduced by ddev composer and ddev composer create but be aware of this issue. Changing git branches, npm install , yarn install , or a script that deletes huge sections of the synced data are related behaviors that should raise caution. If you ddev stop and then change a git branch and then ddev start you are almost certain to get misbehavior, because mutagen didn't know you made those changes while it wasn't running, so tries to merge the results. If you have to do this, do a ddev mutagen reset before restarting the project, so that only the host side will have contents. Mutagen is asynchronous : If you make a massive change on either the host or inside the container, you may not see the results for a little while. In studying situations like this, use ddev mutagen monitor to watch what's going on on your computer. ddev mutagen sync : You can cause an explicit sync with ddev mutagen sync and see syncing status with ddev mutagen status . Note that both ddev start and ddev stop automatically force a mutagen sync. Composer : If you do composer actions inside the container (with ddev ssh ) you'll probably want to do a ddev mutagen sync to make sure they get synced as soon as possible, although most people won't ever notice the difference and mutagen will get it synced soon enough. Big git operations (like switching branches) are best done on the host side, rather than inside the container, and you may want to do an explicit ddev mutagen sync command after doing something like that. Do them with the project running, rather than when it is stopped. Project with users who don't want mutagen : If you share a project with some users (perhaps on macOS) that want mutagen and other users (perhaps on WSL2) that don't want or need it, then don't check in the mutagen_enabled: true in the .ddev/config.yaml . Instead, you can either use global mutagen configuration or add a not-checked-in project-level .ddev/config.mutagen.yaml that just has mutagen_enabled: true in it. Then only users that have that will have mutagen enabled. Mutagen restrictions on Windows symlinks : On macOS and Linux (including WSL2) the default .ddev/mutagen/mutagen.yml chooses the posix-raw type of symlink handling (See mutagen docs ). This basically means that any symlink created will try to sync, regardless of whether it's valid in the other environment. However, Mutagen does not support posix-raw on traditional Windows, so ddev uses the portable symlink mode. So on Windows with Mutagen symlinks have to be strictly limited to relative links that are inside the mutagen section of the project. Backups!!! : Keep backups. Syncing after git checkout \u00b6 In general, it's best practice on most projects to do significant git operations on the host, but they can be disruptive to the sync. It's easy to add a git post-checkout hook to do a ddev mutagen sync operation though. Add the file .git/hooks/post-checkout to your project and set it to be executable ( chmod +x .git/hooks/post-checkout ): #!/bin/bash ddev mutagen sync || true Syncing after yarn, npm, pnpm actions \u00b6 Actions by those programs can also set off massive filesystem changes. You should run ddev mutagen sync in order to get things into sync, or simply wait. Advanced Mutagen configuration options \u00b6 The Mutagen project provides extensive configuration options that are documented on the mutagen.io site . Each project by default already has a .ddev/mutagen/mutagen.yml file with basic defaults which you can override if you remove the #ddev-generated line at the beginning of the file. Remember if you edit the .ddev/mutagen/mutagen.yml file: Remove the #ddev-generated line Execute a ddev mutagen reset to avoid the situation where the docker volume still has files from an older configuration. The most likely thing you'll want to do is to exclude a path from mutagen syncing, which you can do in the paths: section of the ignore: stanza in the .ddev/mutagen/mutagen.yml . It is possible to exclude mutagen syncing from a path and then bind-mount something from the host or a different volume on that path with a docker-compose.*.yaml file. So if you have an extremely heavyweight subdirectory in your project (lots of fonts or user-generated content for example), you could exclude that subdirectory in the .ddev/mutagen/mutagen.yml and then add a docker-compose.exclude.yaml. For example, if you want the stored-binaries subdirectory of the project to be available inside the container, but do not need mutagen to be syncing it, you can use normal docker bind-mounting for that subdirectory with this procedure: Take over the .ddev/mutagen/mutagen.yml by removing the #ddev-generated line Add /stored-binaries to the excluded paths: ignore : paths : - \"/stored-binaries\" Add a .ddev/docker-compose.bindmount.yaml something like this: version : \"3.6\" services : web : volumes : - \"./stored-binaries:/var/www/html/stored-binaries\" Troubleshooting Mutagen Sync Issues \u00b6 Please make sure that DDEV projects work without mutagen before troubleshooting mutagen. ddev config --mutagen-enabled=false && ddev restart . DDEV's mutagen may not be compatible with an existing mutagen on your system. Please make sure that any mutagen installs you have are not running, or stop them. You may want to brew uninstall mutagen-io/mutagen/mutagen mutagen-io/mutagen/mutagen-beta to get rid of brew-installed versions. DDEV's mutagen is installed in ~/.ddev/bin/mutagen . You can use all the features of mutagen by running that, including ~/.ddev/bin/mutagen sync list and ~/.ddev/bin/mutagen daemon stop . You can run the script diagnose_mutagen.sh to gather some information about the setup of mutagen. Please report its output when creating an issue or otherwise seeking support. Try ~/.ddev/bin/mutagen daemon stop && ~/.ddev/bin/mutagen daemon start to restart the mutagen daemon if you suspect it's hanging. Use ddev mutagen reset if you suspect trouble (and always after changing the .ddev/mutagen/mutagen.yml . This restarts everything from scratch, including the docker volume that's used to store your project inside the container.) ddev mutagen monitor can help watch mutagen behavior. It's the same as ~/.ddev/bin/mutagen sync monitor <syncname> ddev debug mutagen will let you run any mutagen command using the binary in ~/.ddev/bin/mutagen . If you're working on the host and expecting things to show up immediately inside the container, you can learn a lot by running ddev mutagen monitor in a separate window as you work. You'll see when mutagen responds to your changes and get an idea about how much delay there is. Consider ddev stop before massive file change operations (like moving a directory, etc.) If you get in real trouble, ddev stop , reset your files with git, and then ddev mutagen reset to throw away the docker volume (which may already have incorrect files on it.) If you're having trouble, we really want to hear from you to learn and try to sort it out. See the Support channels . Advanced Mutagen Troubleshooting \u00b6 Most people get all the information they need about mutagen by running ddev mutagen monitor to see the results. However, Mutagen has full logging. Here's how to run it: killall mutagen export MUTAGEN_LOG_LEVEL=debug or export MUTAGEN_LOG_LEVEL=trace ~/.ddev/bin/mutagen daemon run Work with your project various actions and watch the output. When you're done, you can ddev poweroff and <ctrl-c> the running mutagen daemon to get back to normal. Mutagen Strategies and Design Considerations \u00b6 Mutagen provides enormous speed boosts in everyday usage, but of course it's trying desperately under the hood to keep everything that changes in the container updated in the host, and vice versa. DDEV mounts a fast Docker volume onto /var/www/html inside the web container and then delegates to the mutagen daemon (on the host) the job of keeping all the contents of the project on the host in sync with the contents of the docker volume. The strategy in the DDEV integration is to try to make sure that at key points everything is completely in sync (consistent). Consistency is a really high priority for this integration. The life cycle of the mutagen daemon and sync sessions are something like this: On ddev start the mutagen agent will be started if it's not already running. If there is already a sync session for this project it's stopped and recreated. On ddev stop and ddev pause the sync session is flushed (made completely consistent) and then terminated. In addition, a synchronous flush is performed after any ddev composer command, because composer may cause massive changes to the filesystem inside the container, and those need to be synced before operation continues. If you need to reset everything for a project, you can do it with ddev mutagen reset which starts the mutagen session from scratch and removes the docker volume so it can be recreated from scratch. Interaction with other usages of Mutagen \u00b6 DDEV requires and provides a specific version of Mutagen, which you can see with ddev version . Mutagen does not guarantee interoperability between different mutagen versions, so you may have trouble if you have another version of mutagen installed. You can find out what version of mutagen you may have installed outside of DDEV with mutagen version . You'll want your system version of mutagen to be the same as the one provided with DDEV. If you're using mutagen for anything else, see the Mutagen installation instructions and install the required version. Using NFS to Mount the Project into the Web Container \u00b6 NFS (Network File System) is a classic, mature Unix technique to mount a filesystem from one device to another. It provides significantly improved webserver performance on macOS and Windows. DDEV-Local supports this technique, but it does require a small amount of pre-configuration on your host computer. DDEV-Local doesn't make changes to your computer's configuration without your involvement and approval, so this is done with a setup script that you run and that asks you for your sudo password. The steps to set up NFS mounting on any operating system are: Make sure DDEV-Local is already working and you can use it. Configure the NFS server and exports files using the provided scripts for each operating system. Test that NFS is working correctly by using ddev debug nfsmount in a project directory. The first line should report something like \"Successfully accessed NFS mount of /path/to/project\" Enable NFS mounting globally with ddev config global --nfs-mount-enabled (You can also configure NFS mounting on a per-project basis with ddev config --nfs-mount-enabled in the project directory, but this is unusual. If nfs mounting is turned on globally it overrides any local project settings for NFS.) ddev start your project and make sure it works OK. Use ddev describe to verify that NFS mounting is being used. The NFS status is near the top of the output of ddev describe . Note that you can use the NFS setup described for each operating system below (and the scripts provided) or you can set up NFS any way that works for you. For example, if you're already using NFS with vagrant on macOS, and you already have a number of exports, the default export here (your home directory) won't work, because you'll have overlaps in your /etc/exports . Or on Windows, you may want to use an NFS server other than Winnfsd , for example the Allegro NFS Server . The setups provided below and the scripts provided below are only intended to get you started if you don't already use NFS. Note that NFS does not really add to performance on Linux, so it is not recommended. macOS NFS Setup Windows NFS Setup Download, inspect, make executable, and run the macos_ddev_nfs_setup.sh script. Use curl -O https://raw.githubusercontent.com/drud/ddev/master/scripts/macos_ddev_nfs_setup.sh && chmod +x macos_ddev_nfs_setup.sh && ./macos_ddev_nfs_setup.sh . This stops running ddev projects, adds your home directory to the /etc/exports config file that nfsd uses, and enables nfsd to run on your computer. This is a one-time setup. Note that this shares your home directory via NFS to any NFS client on your computer, so it's critical to consider security issues; It's easy to make the shares in /etc/exports more limited as well, as long as they don't overlap (NFS doesn't allow overlapping exports). If your DDEV-Local projects are set up outside your home directory, you'll need to edit /etc/exports to add a line for that share as well. sudo vi /etc/exports and copy the line the script has just created ( /System/Volumes/Data/Users/username -alldirs -mapall=<your_user_id>:20 localhost ), editing it with the additional path, e.g: /Volumes/SomeExternalDrive -alldirs -mapall=<your_uid>:20 localhost . macOS and the Documents directory If your projects are in a subdirectory of the ~/Documents directory or on an external drive, it may necessary to grant the \"Full Disk Access\" permission to the /sbin/nfsd binary. Full details are below . macOS Full Disk Access for Special Directories \u00b6 If you are on macOS, and your projects are in a subdirectory of the ~/Documents or ~/Desktop directories or on an external drive, you must grant \"Full Disk Access\" privilege to /sbin/nfsd in the Privacy settings in the System Preferences. On the \"Full disk access\" section, click the \"+\" and add /sbin/nfsd as shown here: You should then see nfsd in the list as shown: . sudo nfsd restart Use ddev debug nfsmount in a project directory to make sure it gives successful output like macOS-specific NFS debugging \u00b6 Please temporarily disable any firewall or VPN. Use showmount -e to find out what is exported via NFS. If you don't see a parent of your project directory in there, then NFS can't work. If nothing is showing, use nfsd checkexports and read carefully for errors Use ps -ef | grep nfsd to make sure nfsd is running Restart nfsd with sudo nfsd restart Add the following to your /etc/nfs.conf: nfs.server.mount.require_resv_port = 0 nfs.server.verbose = 3 Run Console.app and put \"nfsd\" in the search box at the top. sudo nfsd restart and read the messages carefully. Attempt to ddev debug nfsmount the problematic project directory. $ ddev debug nfsmount Successfully accessed NFS mount of /Users/rfay/workspace/d8composer TARGET SOURCE FSTYPE OPTIONS /nfsmount :/System/Volumes/Data/Users/rfay/workspace/d8composer nfs rw,relatime,vers = 3 ,rsize = 65536 ,wsize = 65536 ,namlen = 255 ,hard,nolock,proto = tcp,timeo = 600 ,retrans = 2 ,sec = sys,mountaddr = 192 .168.65.2,mountvers = 3 ,mountproto = tcp,local_lock = all,addr = 192 .168.65.2 /nfsmount/.ddev The executable components required for Windows NFS (winnfsd and nssm) are packaged with the DDEV Windows Installer in each release, so if you've used the windows installer, they're available already. To enable winnfsd as a service, please download, inspect and run the script \"windows_ddev_nfs_setup.sh\" installed by the installer in C:\\Program Files\\ddev\\windows_ddev_nfs_setup.sh (or download from windows_ddev_nfs_setup.sh ) in a git-bash session on windows. If your DDEV-Local projects are set up outside your home directory, you'll need to edit the ~/.ddev/nfs_exports.txt created by the script and then restart the service with sudo nssm restart nfsd . Firewall Issues On Windows 10/11 you will likely run afoul of the Windows Defender Firewall, and it will be necessary to allow winnfsd to bypass it. If you're getting a timeout with no information after ddev start , try going to \"Windows Defender Firewall\" -> \"Allow an app or feature through Windows Defender Firewall\", \"Change Settings\", \"Allow another app\". Then choose C:\\Program Files\\ddev\\winnfsd.exe, assuming that's where winnfsd is installed. Debugging ddev start failures with nfs_mount_enabled: true \u00b6 There are a number of reasons that the NFS mount can fail on ddev start : Firewall issues NFS Server not running Trying to start more than one NFS server. NFS exports overlap. This is typically an issue if you've had another NFS client setup (like vagrant). You'll need to reconfigure your exports paths so they don't overlap. Path of project not shared in /etc/exports (or ~/.ddev/nfs_exports.txt on Windows) Project is in the ~/Documents directory or an external drive on macOS Catalina or higher (see macOS information below) Tools to debug and solve permission problems: Try ddev debug nfsmount in a project directory to see if basic NFS mounting is working. If that works, it's likely that everything else will. When debugging, please do ddev restart in between each change. Otherwise, you can have stale mounts inside the container and you'll miss any benefit you may find in the debugging process. Inspect the /etc/exports (or ~/.ddev/nfs_exports.txt on Windows). Restart the server ( sudo nfsd restart on macOS, sudo nssm restart nfsd on Windows). showmount -e on macOS will show the shared mounts. Windows-specific NFS debugging \u00b6 Please temporarily disable any firewall or VPN. You can only have one NFS daemon running, so if another application has installed one, you'll want to use that NFS daemon and reconfigure it to allow NFS mounts of your projects. Stop the running winnfsd service: sudo nssm stop nfsd Run winnfsd manually in the foreground: winnfsd \"C:\\\\\" . If it returns to the shell prompt immediately there's likely another nfsd service running. In another window, in a ddev project directory, ddev debug nfsmount to see if it can mount successfully. (The project need not be started.). ddev debug nfsmount is successful, then everything is probably going to work. After verifying that ~/.ddev/nfs_exports.txt has a line that includes your project directories, sudo nssm start nfsd and nssm status nfsd . The status command should show SERVICE_RUNNING. These nssm commands may be useful: nssm help , sudo nssm start nfsd , sudo nssm stop nfsd , nssm status nfsd , sudo nssm edit nfsd (pops up a window that may be hidden), and sudo nssm remove nfsd (also pops up a window, doesn't work predictably if you haven't already stopped the service). nssm logs failures and what it's doing to the system event log. Run \"Event Viewer\" and filter events as in the image below: . Please make sure you have excluded winnfsd from the Windows Defender Firewall, as described in the installation instructions above. On Windows 10/11 Pro you can \"Turn Windows features on or off\" and enable \"Services for NFS\"-> \"Client for NFS\". The showmount -e command will then show available exports on the current machine. This can help find out if a conflicting server is running or exactly what the problem with exports may be. Freeing Up System Resources \u00b6 Every project you run uses system resources, and may compete for those resources. A reasonable practice is to stop projects that aren't currently in use, or stop all projects with ddev poweroff and then start the one that you're actually working on. ddev list will show you the projects you're working on. Docker Desktop for Mac Settings \u00b6 Docker Desktop for Mac has a number of settings that you'll want to pay attention to. Under \"Advanced\" in the \"Resources\" section in \"Preferences\", you can adjust the amount of memory, disk, and CPUs allocated to Docker. While the defaults work well for a small project or two, you may want to adjust these upward based on your experience. The default memory allocation is 2GB, but many people raise it to 4-5GB or even higher. The disk allocation almost always needs to be raised to accommodate increased downloaded images. Your experience will determine what to do with CPUs.","title":"Performance and Mutagen"},{"location":"users/install/performance/#performance-and-mutagen","text":"Every developer wants both fast startup of the environment and quick response to web page requests. DDEV is always focused on improving performance. However, both Docker Desktop on macOS and Windows has significant performance problems with mounted filesystems (like the mounted project where code can be edited either inside the container or on the host). Folks are usually happy with webserving performance right away on Linux, which includes Windows WSL2 and Gitpod.io, so there's not usually anything to do. On macOS and traditional Windows, the Docker environment has performance problems getting files synced between the host and the container, and that causes slowdowns in webserving. Currently, most people are using Mutagen on macOS. It's fast, requires no installation or configuration (besides turning it on with ddev config --mutagen-enabled ), and although there are caveats below it has worked really, really well. In the past, lots of folks configured NFS on macOS and Windows to speed things up, and it helped, but nowhere near as much as Mutagen, and there is some manual system configuration required. Instructions for Mutagen and NFS are below. Mutagen NFS","title":"Performance and Mutagen"},{"location":"users/install/performance/#mutagen","text":"TL;DR: If you're on macOS or Windows just enable mutagen. ddev config global --mutagen-enabled . You'll be glad you did. The Mutagen asynchronous caching feature offers advanced performance experiences and is recommended for most projects. It's now the preferred way to get great webserving performance on macOS and Windows. Unlike the NFS feature, it requires no pre-configuration or installation. You do not need to (and should not) install mutagen. It can also be significantly faster than NFS and massively faster than plain vanilla Docker or Colima. In addition, it makes filesystem watchers (fsnotify/inotify) work correctly. Mutagen can offer massive webserver performance speedups on macOS and traditional Windows; it works fine (and has automated tests) on Linux or Windows WSL2, but the speedup you see may not be worth turning it on, since Linux/WSL2 are already so fast. Docker bind-mounts (the traditional approach to getting your code into the DDEV web container) can be slow on macOS and Windows, even with NFS. The reason is that every file access has to be checked against the file on the host, and Docker's setup to do this on macOS and Windows offers is not very performant. (On Linux and Linux-like systems, Docker provides native file-access performance.) Mutagen works by decoupling reads and writes inside the container from reads and writes on the host. If something changes on the host, it gets changed \"pretty soon\" in the container, and if something changes inside the container it gets updated \"pretty soon\" on the host. This means that the webserver inside the web container does not have to wait for slow file reads or writes, and gets near-native file speeds. However, it also means that at any given moment, the files on the host may not exactly match the files inside the container, and if files are changed both places, conflicts may result. Another major advantage of Mutagen over NFS is that it supports filesystem notifications, so file-watchers on both the host and inside the container will be notified when changes occur. This is a great advantage for many development tools, which had to poll for changes in the past, but now will be notified via normal inotify/fsnotify techniques. If you trouble with the Mutagen feature, please try to recreate it and report via one of the support channels .","title":"Mutagen"},{"location":"users/install/performance/#enabling-mutagen","text":"Do not separately install mutagen Do not separately install the mutagen binary. It's better if you don't have it installed. DDEV does the installation and upgrades when needed. To begin using Mutagen, just ddev stop and then ddev config --mutagen-enabled and start the project again. If the mutagen binary needs to be downloaded, it will be downloaded automatically. To stop using Mutagen on a project, ddev mutagen reset && ddev config --mutagen-enabled=false . You can also enable mutagen globally (recommended) with ddev config global --mutagen-enabled Note that the nfs-mount-enabled feature is automatically turned off if you're using mutagen. You can run mutagen on all your projects, there's no limit. To configure it globally, ddev config global --mutagen-enabled , but you cannot disable mutagen on individual projects if it's enabled globally (the global configuration wins).","title":"Enabling Mutagen"},{"location":"users/install/performance/#caveats-about-mutagen-integration","text":"Most people have an excellent experience with Mutagen, but it's good to understand how it works and what the trade-offs are: Not for every project : Mutagen is not the right choice for every project. If filesystem consistency is your highest priority (as opposed to performance) then there are reasons to be cautious, although people have had excellent experiences: there haven't been major issues reported, but two-way sync is a very difficult computational problem, and problems may surface. Only one mutagen version on machine please : DDEV installs its own mutagen. You do not need to install mutagen. Multiple mutagen versions can't coexist on one machine, so please stop any running mutagen. On macOS, killall mutagen . If you absolutely have to have mutagen installed via homebrew or another technique (for another project) make sure it's the same version as you get with ddev version . Works everywhere, best on macOS and Windows : This is mostly for macOS and traditional Windows users. WSL2 is already the preferred environment for Windows users, but if you're still using traditional Windows this makes a huge difference. Although DDEV with mutagen is fully supported and tested on traditional Windows and Linux/WSL2, enabling mutagen on Linux/WSL2 may not be your first choice, since it adds some complexity and very little performance. Increased disk usage : Mutagen integration increases the size of your project code disk usage, because the code exists both on your computer and also inside a docker volume. (As of v1.19+, this does not include your file upload directory, so normally it's not too intrusive.) So take care that you have enough overall disk space, and also (on macOS) that you have enough file space set up in Docker Desktop. For projects before v1.19, if you have a large amount of data like user-generated content that does not need syncing (i.e. fileadmin for TYPO3 or sites/default/files for Drupal), you can exclude specific directories from getting synced and use regular docker mount for them instead. See below for Advanced Mutagen configuration options . As of v1.19, this is handled automatically and these files are not mutagen-synced. If your project is likely to change the same file on both the host and inside the container, you may be at risk for conflicts. Massive changes to either the host or the container are the most likely to introduce issues. This integration has been tested extensively with major changes introduced by ddev composer and ddev composer create but be aware of this issue. Changing git branches, npm install , yarn install , or a script that deletes huge sections of the synced data are related behaviors that should raise caution. If you ddev stop and then change a git branch and then ddev start you are almost certain to get misbehavior, because mutagen didn't know you made those changes while it wasn't running, so tries to merge the results. If you have to do this, do a ddev mutagen reset before restarting the project, so that only the host side will have contents. Mutagen is asynchronous : If you make a massive change on either the host or inside the container, you may not see the results for a little while. In studying situations like this, use ddev mutagen monitor to watch what's going on on your computer. ddev mutagen sync : You can cause an explicit sync with ddev mutagen sync and see syncing status with ddev mutagen status . Note that both ddev start and ddev stop automatically force a mutagen sync. Composer : If you do composer actions inside the container (with ddev ssh ) you'll probably want to do a ddev mutagen sync to make sure they get synced as soon as possible, although most people won't ever notice the difference and mutagen will get it synced soon enough. Big git operations (like switching branches) are best done on the host side, rather than inside the container, and you may want to do an explicit ddev mutagen sync command after doing something like that. Do them with the project running, rather than when it is stopped. Project with users who don't want mutagen : If you share a project with some users (perhaps on macOS) that want mutagen and other users (perhaps on WSL2) that don't want or need it, then don't check in the mutagen_enabled: true in the .ddev/config.yaml . Instead, you can either use global mutagen configuration or add a not-checked-in project-level .ddev/config.mutagen.yaml that just has mutagen_enabled: true in it. Then only users that have that will have mutagen enabled. Mutagen restrictions on Windows symlinks : On macOS and Linux (including WSL2) the default .ddev/mutagen/mutagen.yml chooses the posix-raw type of symlink handling (See mutagen docs ). This basically means that any symlink created will try to sync, regardless of whether it's valid in the other environment. However, Mutagen does not support posix-raw on traditional Windows, so ddev uses the portable symlink mode. So on Windows with Mutagen symlinks have to be strictly limited to relative links that are inside the mutagen section of the project. Backups!!! : Keep backups.","title":"Caveats about Mutagen Integration"},{"location":"users/install/performance/#syncing-after-git-checkout","text":"In general, it's best practice on most projects to do significant git operations on the host, but they can be disruptive to the sync. It's easy to add a git post-checkout hook to do a ddev mutagen sync operation though. Add the file .git/hooks/post-checkout to your project and set it to be executable ( chmod +x .git/hooks/post-checkout ): #!/bin/bash ddev mutagen sync || true","title":"Syncing after git checkout"},{"location":"users/install/performance/#syncing-after-yarn-npm-pnpm-actions","text":"Actions by those programs can also set off massive filesystem changes. You should run ddev mutagen sync in order to get things into sync, or simply wait.","title":"Syncing after yarn, npm, pnpm actions"},{"location":"users/install/performance/#advanced-mutagen-configuration-options","text":"The Mutagen project provides extensive configuration options that are documented on the mutagen.io site . Each project by default already has a .ddev/mutagen/mutagen.yml file with basic defaults which you can override if you remove the #ddev-generated line at the beginning of the file. Remember if you edit the .ddev/mutagen/mutagen.yml file: Remove the #ddev-generated line Execute a ddev mutagen reset to avoid the situation where the docker volume still has files from an older configuration. The most likely thing you'll want to do is to exclude a path from mutagen syncing, which you can do in the paths: section of the ignore: stanza in the .ddev/mutagen/mutagen.yml . It is possible to exclude mutagen syncing from a path and then bind-mount something from the host or a different volume on that path with a docker-compose.*.yaml file. So if you have an extremely heavyweight subdirectory in your project (lots of fonts or user-generated content for example), you could exclude that subdirectory in the .ddev/mutagen/mutagen.yml and then add a docker-compose.exclude.yaml. For example, if you want the stored-binaries subdirectory of the project to be available inside the container, but do not need mutagen to be syncing it, you can use normal docker bind-mounting for that subdirectory with this procedure: Take over the .ddev/mutagen/mutagen.yml by removing the #ddev-generated line Add /stored-binaries to the excluded paths: ignore : paths : - \"/stored-binaries\" Add a .ddev/docker-compose.bindmount.yaml something like this: version : \"3.6\" services : web : volumes : - \"./stored-binaries:/var/www/html/stored-binaries\"","title":"Advanced Mutagen configuration options"},{"location":"users/install/performance/#troubleshooting-mutagen-sync-issues","text":"Please make sure that DDEV projects work without mutagen before troubleshooting mutagen. ddev config --mutagen-enabled=false && ddev restart . DDEV's mutagen may not be compatible with an existing mutagen on your system. Please make sure that any mutagen installs you have are not running, or stop them. You may want to brew uninstall mutagen-io/mutagen/mutagen mutagen-io/mutagen/mutagen-beta to get rid of brew-installed versions. DDEV's mutagen is installed in ~/.ddev/bin/mutagen . You can use all the features of mutagen by running that, including ~/.ddev/bin/mutagen sync list and ~/.ddev/bin/mutagen daemon stop . You can run the script diagnose_mutagen.sh to gather some information about the setup of mutagen. Please report its output when creating an issue or otherwise seeking support. Try ~/.ddev/bin/mutagen daemon stop && ~/.ddev/bin/mutagen daemon start to restart the mutagen daemon if you suspect it's hanging. Use ddev mutagen reset if you suspect trouble (and always after changing the .ddev/mutagen/mutagen.yml . This restarts everything from scratch, including the docker volume that's used to store your project inside the container.) ddev mutagen monitor can help watch mutagen behavior. It's the same as ~/.ddev/bin/mutagen sync monitor <syncname> ddev debug mutagen will let you run any mutagen command using the binary in ~/.ddev/bin/mutagen . If you're working on the host and expecting things to show up immediately inside the container, you can learn a lot by running ddev mutagen monitor in a separate window as you work. You'll see when mutagen responds to your changes and get an idea about how much delay there is. Consider ddev stop before massive file change operations (like moving a directory, etc.) If you get in real trouble, ddev stop , reset your files with git, and then ddev mutagen reset to throw away the docker volume (which may already have incorrect files on it.) If you're having trouble, we really want to hear from you to learn and try to sort it out. See the Support channels .","title":"Troubleshooting Mutagen Sync Issues"},{"location":"users/install/performance/#advanced-mutagen-troubleshooting","text":"Most people get all the information they need about mutagen by running ddev mutagen monitor to see the results. However, Mutagen has full logging. Here's how to run it: killall mutagen export MUTAGEN_LOG_LEVEL=debug or export MUTAGEN_LOG_LEVEL=trace ~/.ddev/bin/mutagen daemon run Work with your project various actions and watch the output. When you're done, you can ddev poweroff and <ctrl-c> the running mutagen daemon to get back to normal.","title":"Advanced Mutagen Troubleshooting"},{"location":"users/install/performance/#mutagen-strategies-and-design-considerations","text":"Mutagen provides enormous speed boosts in everyday usage, but of course it's trying desperately under the hood to keep everything that changes in the container updated in the host, and vice versa. DDEV mounts a fast Docker volume onto /var/www/html inside the web container and then delegates to the mutagen daemon (on the host) the job of keeping all the contents of the project on the host in sync with the contents of the docker volume. The strategy in the DDEV integration is to try to make sure that at key points everything is completely in sync (consistent). Consistency is a really high priority for this integration. The life cycle of the mutagen daemon and sync sessions are something like this: On ddev start the mutagen agent will be started if it's not already running. If there is already a sync session for this project it's stopped and recreated. On ddev stop and ddev pause the sync session is flushed (made completely consistent) and then terminated. In addition, a synchronous flush is performed after any ddev composer command, because composer may cause massive changes to the filesystem inside the container, and those need to be synced before operation continues. If you need to reset everything for a project, you can do it with ddev mutagen reset which starts the mutagen session from scratch and removes the docker volume so it can be recreated from scratch.","title":"Mutagen Strategies and Design Considerations"},{"location":"users/install/performance/#interaction-with-other-usages-of-mutagen","text":"DDEV requires and provides a specific version of Mutagen, which you can see with ddev version . Mutagen does not guarantee interoperability between different mutagen versions, so you may have trouble if you have another version of mutagen installed. You can find out what version of mutagen you may have installed outside of DDEV with mutagen version . You'll want your system version of mutagen to be the same as the one provided with DDEV. If you're using mutagen for anything else, see the Mutagen installation instructions and install the required version.","title":"Interaction with other usages of Mutagen"},{"location":"users/install/performance/#using-nfs-to-mount-the-project-into-the-web-container","text":"NFS (Network File System) is a classic, mature Unix technique to mount a filesystem from one device to another. It provides significantly improved webserver performance on macOS and Windows. DDEV-Local supports this technique, but it does require a small amount of pre-configuration on your host computer. DDEV-Local doesn't make changes to your computer's configuration without your involvement and approval, so this is done with a setup script that you run and that asks you for your sudo password. The steps to set up NFS mounting on any operating system are: Make sure DDEV-Local is already working and you can use it. Configure the NFS server and exports files using the provided scripts for each operating system. Test that NFS is working correctly by using ddev debug nfsmount in a project directory. The first line should report something like \"Successfully accessed NFS mount of /path/to/project\" Enable NFS mounting globally with ddev config global --nfs-mount-enabled (You can also configure NFS mounting on a per-project basis with ddev config --nfs-mount-enabled in the project directory, but this is unusual. If nfs mounting is turned on globally it overrides any local project settings for NFS.) ddev start your project and make sure it works OK. Use ddev describe to verify that NFS mounting is being used. The NFS status is near the top of the output of ddev describe . Note that you can use the NFS setup described for each operating system below (and the scripts provided) or you can set up NFS any way that works for you. For example, if you're already using NFS with vagrant on macOS, and you already have a number of exports, the default export here (your home directory) won't work, because you'll have overlaps in your /etc/exports . Or on Windows, you may want to use an NFS server other than Winnfsd , for example the Allegro NFS Server . The setups provided below and the scripts provided below are only intended to get you started if you don't already use NFS. Note that NFS does not really add to performance on Linux, so it is not recommended. macOS NFS Setup Windows NFS Setup Download, inspect, make executable, and run the macos_ddev_nfs_setup.sh script. Use curl -O https://raw.githubusercontent.com/drud/ddev/master/scripts/macos_ddev_nfs_setup.sh && chmod +x macos_ddev_nfs_setup.sh && ./macos_ddev_nfs_setup.sh . This stops running ddev projects, adds your home directory to the /etc/exports config file that nfsd uses, and enables nfsd to run on your computer. This is a one-time setup. Note that this shares your home directory via NFS to any NFS client on your computer, so it's critical to consider security issues; It's easy to make the shares in /etc/exports more limited as well, as long as they don't overlap (NFS doesn't allow overlapping exports). If your DDEV-Local projects are set up outside your home directory, you'll need to edit /etc/exports to add a line for that share as well. sudo vi /etc/exports and copy the line the script has just created ( /System/Volumes/Data/Users/username -alldirs -mapall=<your_user_id>:20 localhost ), editing it with the additional path, e.g: /Volumes/SomeExternalDrive -alldirs -mapall=<your_uid>:20 localhost . macOS and the Documents directory If your projects are in a subdirectory of the ~/Documents directory or on an external drive, it may necessary to grant the \"Full Disk Access\" permission to the /sbin/nfsd binary. Full details are below .","title":"Using NFS to Mount the Project into the Web Container"},{"location":"users/install/performance/#macos-full-disk-access-for-special-directories","text":"If you are on macOS, and your projects are in a subdirectory of the ~/Documents or ~/Desktop directories or on an external drive, you must grant \"Full Disk Access\" privilege to /sbin/nfsd in the Privacy settings in the System Preferences. On the \"Full disk access\" section, click the \"+\" and add /sbin/nfsd as shown here: You should then see nfsd in the list as shown: . sudo nfsd restart Use ddev debug nfsmount in a project directory to make sure it gives successful output like","title":"macOS Full Disk Access for Special Directories"},{"location":"users/install/performance/#macos-specific-nfs-debugging","text":"Please temporarily disable any firewall or VPN. Use showmount -e to find out what is exported via NFS. If you don't see a parent of your project directory in there, then NFS can't work. If nothing is showing, use nfsd checkexports and read carefully for errors Use ps -ef | grep nfsd to make sure nfsd is running Restart nfsd with sudo nfsd restart Add the following to your /etc/nfs.conf: nfs.server.mount.require_resv_port = 0 nfs.server.verbose = 3 Run Console.app and put \"nfsd\" in the search box at the top. sudo nfsd restart and read the messages carefully. Attempt to ddev debug nfsmount the problematic project directory. $ ddev debug nfsmount Successfully accessed NFS mount of /Users/rfay/workspace/d8composer TARGET SOURCE FSTYPE OPTIONS /nfsmount :/System/Volumes/Data/Users/rfay/workspace/d8composer nfs rw,relatime,vers = 3 ,rsize = 65536 ,wsize = 65536 ,namlen = 255 ,hard,nolock,proto = tcp,timeo = 600 ,retrans = 2 ,sec = sys,mountaddr = 192 .168.65.2,mountvers = 3 ,mountproto = tcp,local_lock = all,addr = 192 .168.65.2 /nfsmount/.ddev The executable components required for Windows NFS (winnfsd and nssm) are packaged with the DDEV Windows Installer in each release, so if you've used the windows installer, they're available already. To enable winnfsd as a service, please download, inspect and run the script \"windows_ddev_nfs_setup.sh\" installed by the installer in C:\\Program Files\\ddev\\windows_ddev_nfs_setup.sh (or download from windows_ddev_nfs_setup.sh ) in a git-bash session on windows. If your DDEV-Local projects are set up outside your home directory, you'll need to edit the ~/.ddev/nfs_exports.txt created by the script and then restart the service with sudo nssm restart nfsd . Firewall Issues On Windows 10/11 you will likely run afoul of the Windows Defender Firewall, and it will be necessary to allow winnfsd to bypass it. If you're getting a timeout with no information after ddev start , try going to \"Windows Defender Firewall\" -> \"Allow an app or feature through Windows Defender Firewall\", \"Change Settings\", \"Allow another app\". Then choose C:\\Program Files\\ddev\\winnfsd.exe, assuming that's where winnfsd is installed.","title":"macOS-specific NFS debugging"},{"location":"users/install/performance/#debugging-ddev-start-failures-with-nfs_mount_enabled-true","text":"There are a number of reasons that the NFS mount can fail on ddev start : Firewall issues NFS Server not running Trying to start more than one NFS server. NFS exports overlap. This is typically an issue if you've had another NFS client setup (like vagrant). You'll need to reconfigure your exports paths so they don't overlap. Path of project not shared in /etc/exports (or ~/.ddev/nfs_exports.txt on Windows) Project is in the ~/Documents directory or an external drive on macOS Catalina or higher (see macOS information below) Tools to debug and solve permission problems: Try ddev debug nfsmount in a project directory to see if basic NFS mounting is working. If that works, it's likely that everything else will. When debugging, please do ddev restart in between each change. Otherwise, you can have stale mounts inside the container and you'll miss any benefit you may find in the debugging process. Inspect the /etc/exports (or ~/.ddev/nfs_exports.txt on Windows). Restart the server ( sudo nfsd restart on macOS, sudo nssm restart nfsd on Windows). showmount -e on macOS will show the shared mounts.","title":"Debugging ddev start failures with nfs_mount_enabled: true"},{"location":"users/install/performance/#windows-specific-nfs-debugging","text":"Please temporarily disable any firewall or VPN. You can only have one NFS daemon running, so if another application has installed one, you'll want to use that NFS daemon and reconfigure it to allow NFS mounts of your projects. Stop the running winnfsd service: sudo nssm stop nfsd Run winnfsd manually in the foreground: winnfsd \"C:\\\\\" . If it returns to the shell prompt immediately there's likely another nfsd service running. In another window, in a ddev project directory, ddev debug nfsmount to see if it can mount successfully. (The project need not be started.). ddev debug nfsmount is successful, then everything is probably going to work. After verifying that ~/.ddev/nfs_exports.txt has a line that includes your project directories, sudo nssm start nfsd and nssm status nfsd . The status command should show SERVICE_RUNNING. These nssm commands may be useful: nssm help , sudo nssm start nfsd , sudo nssm stop nfsd , nssm status nfsd , sudo nssm edit nfsd (pops up a window that may be hidden), and sudo nssm remove nfsd (also pops up a window, doesn't work predictably if you haven't already stopped the service). nssm logs failures and what it's doing to the system event log. Run \"Event Viewer\" and filter events as in the image below: . Please make sure you have excluded winnfsd from the Windows Defender Firewall, as described in the installation instructions above. On Windows 10/11 Pro you can \"Turn Windows features on or off\" and enable \"Services for NFS\"-> \"Client for NFS\". The showmount -e command will then show available exports on the current machine. This can help find out if a conflicting server is running or exactly what the problem with exports may be.","title":"Windows-specific NFS debugging"},{"location":"users/install/performance/#freeing-up-system-resources","text":"Every project you run uses system resources, and may compete for those resources. A reasonable practice is to stop projects that aren't currently in use, or stop all projects with ddev poweroff and then start the one that you're actually working on. ddev list will show you the projects you're working on.","title":"Freeing Up System Resources"},{"location":"users/install/performance/#docker-desktop-for-mac-settings","text":"Docker Desktop for Mac has a number of settings that you'll want to pay attention to. Under \"Advanced\" in the \"Resources\" section in \"Preferences\", you can adjust the amount of memory, disk, and CPUs allocated to Docker. While the defaults work well for a small project or two, you may want to adjust these upward based on your experience. The default memory allocation is 2GB, but many people raise it to 4-5GB or even higher. The disk allocation almost always needs to be raised to accommodate increased downloaded images. Your experience will determine what to do with CPUs.","title":"Docker Desktop for Mac Settings"},{"location":"users/install/shell-completion/","text":"Shell Completion & Autocomplete \u00b6 Most people like to have shell completion on the command line. In other words, when you're typing a command, you can hit <TAB> and the shell will show you what the options are. For example, if you type ddev <TAB> , you'll see all the possible commands. ddev debug <TAB> will show you the options for the command. And ddev list -<TAB> will show you all the flags available for ddev list . Shells like bash and zsh need help to do this though, they have to know what the options are. DDEV-Local provides the necessary hint scripts, and if you use homebrew, they get installed automatically. But if you use oh-my-zsh, for example, you may have to manually install the hint script. Bash with Homebrew Bash without Homebrew Zsh Completion with Homebrew Oh-My-Zsh Fish Git-bash PowerShell The easiest way to use bash completion on either macOS or Linux is to install with homebrew. brew install bash-completion . When you install it though, it will warn you with something like this, which may vary on your system. Add the following line to your ~/.bash_profile : [[ -r \"/usr/local/etc/profile.d/bash_completion.sh\" ]] && . \"/usr/local/etc/profile.d/bash_completion.sh\" Bash profile You do have to add the include to your .bash_profile or .profile or nothing will work. Use source ~/.bash_profile or source ~/.profile to make it take effect immediately. Link completions with brew completions link . If you're installing DDEV via homebrew, each new release will automatically get a refreshed completions script. The completion script is exactly the same, it's just that you have to install it yourself. Each system may have a slightly different technique, and you'll need to figure it out. On Debian/Ubuntu, you would use these instructions to enable bash-completion, and then sudo mkdir -p /etc/bash_completion.d && sudo cp ddev_bash_completion.sh /etc/bash_completion.d . This deploys the ddev_bash_completion.sh script where it needs to be. Again, every Linux distro has a different technique, and you may have to figure yours out. This works exactly the same as bash completion. brew install zsh-completions . You'll get instructions something like this: if type brew & >/dev/null ; then FPATH = $( brew --prefix ) /share/zsh-completions: $FPATH autoload -Uz compinit compinit fi You may also need to force rebuild zcompdump : rm -f ~/.zcompdump ; compinit Additionally, if you receive \"zsh compinit: insecure directories\" warnings when attempting to load these completions, you may need to run this: chmod go-w '/usr/local/share' So follow those instructions and your zsh should be set up. If you installed zsh with homebrew, ddev's completions will be automatically installed when you brew install drud/ddev/ddev . Otherwise, Oh-My-Zsh may be set up very differently in different places, so as a power zsh user you'll need to put ddev_bash_completion.sh (see tar archive download above) where it belongs. echo $fpath will show you the places that it's most likely to belong. An obvious choice is ~/.oh-my-zsh/completions if that exists, so you can mkdir -p ~/.oh-my-zsh/completions && cp ddev_zsh_completion.sh ~/.oh-my-zsh/completions/_ddev and then autoload -Uz compinit && compinit . The fish shell's completions are also supported and are automatically installed into /usr/local/share/fish/vendor_completions.d/ when you install ddev via Homebrew. If you have installed fish without homebrew, you can extract the fish completions from the ddev_shell_completion_scripts tarball that is included with each release. Completions in git-bash are sourced from at least ~/bash_completion.d so you can use mkdir -p ~/bash_completion.d && tar -C ~/.bash_completion.d -zxf /z/Downloads/ddev_shell_completion_scripts.v1.15.0-rc3.tar.gz ddev_bash_completion.sh && mv ~/bash_completion.d/ddev_bash_completion.sh ~/bash_completion.d/ddev.bash to extract the bash completions and put them where they belong. PowerShell completions are also provided in the ddev_shell_completions tarball included with each release. You can run the ddev_powershell_completion.ps1 script manually or install it so it will be run whenever PS is opened using the technique at Run PowerShell Script When You Open PowerShell tar Archive of Completion Scripts for Manual Deployment \u00b6 Although most people will use techniques like homebrew for installation, a tar archive of the shell completion scripts is available in each release, called ddev_shell_completion_scripts.<version>.tar.gz . If you need to manually install, you can download and untar the scripts, then copy them as needed to where they have to go. For example, sudo cp ddev_bash_completion.sh /etc/bash_completion.d/ddev . Note that scripts for the fish shell and Windows PowerShell are also provided, but no instructions are given here for deploying them.","title":"Shell Completion & Autocomplete"},{"location":"users/install/shell-completion/#shell-completion-autocomplete","text":"Most people like to have shell completion on the command line. In other words, when you're typing a command, you can hit <TAB> and the shell will show you what the options are. For example, if you type ddev <TAB> , you'll see all the possible commands. ddev debug <TAB> will show you the options for the command. And ddev list -<TAB> will show you all the flags available for ddev list . Shells like bash and zsh need help to do this though, they have to know what the options are. DDEV-Local provides the necessary hint scripts, and if you use homebrew, they get installed automatically. But if you use oh-my-zsh, for example, you may have to manually install the hint script. Bash with Homebrew Bash without Homebrew Zsh Completion with Homebrew Oh-My-Zsh Fish Git-bash PowerShell The easiest way to use bash completion on either macOS or Linux is to install with homebrew. brew install bash-completion . When you install it though, it will warn you with something like this, which may vary on your system. Add the following line to your ~/.bash_profile : [[ -r \"/usr/local/etc/profile.d/bash_completion.sh\" ]] && . \"/usr/local/etc/profile.d/bash_completion.sh\" Bash profile You do have to add the include to your .bash_profile or .profile or nothing will work. Use source ~/.bash_profile or source ~/.profile to make it take effect immediately. Link completions with brew completions link . If you're installing DDEV via homebrew, each new release will automatically get a refreshed completions script. The completion script is exactly the same, it's just that you have to install it yourself. Each system may have a slightly different technique, and you'll need to figure it out. On Debian/Ubuntu, you would use these instructions to enable bash-completion, and then sudo mkdir -p /etc/bash_completion.d && sudo cp ddev_bash_completion.sh /etc/bash_completion.d . This deploys the ddev_bash_completion.sh script where it needs to be. Again, every Linux distro has a different technique, and you may have to figure yours out. This works exactly the same as bash completion. brew install zsh-completions . You'll get instructions something like this: if type brew & >/dev/null ; then FPATH = $( brew --prefix ) /share/zsh-completions: $FPATH autoload -Uz compinit compinit fi You may also need to force rebuild zcompdump : rm -f ~/.zcompdump ; compinit Additionally, if you receive \"zsh compinit: insecure directories\" warnings when attempting to load these completions, you may need to run this: chmod go-w '/usr/local/share' So follow those instructions and your zsh should be set up. If you installed zsh with homebrew, ddev's completions will be automatically installed when you brew install drud/ddev/ddev . Otherwise, Oh-My-Zsh may be set up very differently in different places, so as a power zsh user you'll need to put ddev_bash_completion.sh (see tar archive download above) where it belongs. echo $fpath will show you the places that it's most likely to belong. An obvious choice is ~/.oh-my-zsh/completions if that exists, so you can mkdir -p ~/.oh-my-zsh/completions && cp ddev_zsh_completion.sh ~/.oh-my-zsh/completions/_ddev and then autoload -Uz compinit && compinit . The fish shell's completions are also supported and are automatically installed into /usr/local/share/fish/vendor_completions.d/ when you install ddev via Homebrew. If you have installed fish without homebrew, you can extract the fish completions from the ddev_shell_completion_scripts tarball that is included with each release. Completions in git-bash are sourced from at least ~/bash_completion.d so you can use mkdir -p ~/bash_completion.d && tar -C ~/.bash_completion.d -zxf /z/Downloads/ddev_shell_completion_scripts.v1.15.0-rc3.tar.gz ddev_bash_completion.sh && mv ~/bash_completion.d/ddev_bash_completion.sh ~/bash_completion.d/ddev.bash to extract the bash completions and put them where they belong. PowerShell completions are also provided in the ddev_shell_completions tarball included with each release. You can run the ddev_powershell_completion.ps1 script manually or install it so it will be run whenever PS is opened using the technique at Run PowerShell Script When You Open PowerShell","title":"Shell Completion &amp; Autocomplete"},{"location":"users/install/shell-completion/#tar-archive-of-completion-scripts-for-manual-deployment","text":"Although most people will use techniques like homebrew for installation, a tar archive of the shell completion scripts is available in each release, called ddev_shell_completion_scripts.<version>.tar.gz . If you need to manually install, you can download and untar the scripts, then copy them as needed to where they have to go. For example, sudo cp ddev_bash_completion.sh /etc/bash_completion.d/ddev . Note that scripts for the fish shell and Windows PowerShell are also provided, but no instructions are given here for deploying them.","title":"tar Archive of Completion Scripts for Manual Deployment"},{"location":"users/providers/","text":"Hosting Provider Integration \u00b6 DDEV offers hosting provider integration and sample integrations for Pantheon.io, Platform.sh and Acquia hosting, along with other examples. The best part of this is you can change them and adapt them in any way you need to, they're all short scripted recipes. There are several example recipes created in the .ddev/providers directory of every project or see them in the code . ddev provides the pull command with whatever recipes you have configured. For example, ddev pull acquia if you have created .ddev/providers/acquia.yaml . ddev also provides the push command to push database and files to upstream. This is very dangerous to your upstream site and should only be used when completely appropriate. It's recommended not even to implement the push stanzas in your yaml file, but if it fits your workflow, use it well. Each provider recipe is a yaml file that can be named any way you want to name it. The examples are mostly named after the hosting providers, but they could be named \"upstream.yaml\" or \"live.yaml\", so you could ddev pull upstream or ddev pull live . If you wanted different upstream environments to pull from, you could name one \"prod\" and one \"dev\" and ddev pull prod and ddev pull dev . Example recipes are provided for Acquia , Local files (like Dropbox, for example), Pantheon.io , Platform.sh , and rsync . We know that you'll find improvements to these examples and will have lots to contribute for other hosting providers, and we look forward to your contributions as pull requests here or in ddev-contrib . Each provider recipe is a file named <provider>.yaml and consists of several mostly-optional stanzas: environment_variables : Environment variables will be created in the web container for each of these during pull or push operations. They're used to provide context (project id, environment name, etc.) for each of the other stanzas. db_pull_command : A script that determines how ddev should obtain a database. It's job is to create a gzipped database dump in /var/www/html/.ddev/.downloads/db.sql.gz. This is optional; if nothing has to be done to obtain the database dump, this step can be omitted. db_import_command : (optional) A script that imports the downloaded database. This is for advanced usages like multiple databases. The default behavior only imports a single database into the db database. The localfile example uses this technique. files_pull_command : A script that determines how ddev can get user-generated files from upstream. Its job is to copy the files from upstream to /var/www/html/.ddev/.downloads/files. If nothing has to be done to obtain the files, this step can simply run true . files_import_command : (optional) A script that imports the downloaded files. There are a number of situations where it's just messy to push a directory of files around, and one can just put it directly where it's needed. The localfile example uses this technique. db_push_command : A script that determines how ddev should push a database. It's job is to take a gzipped database dump from /var/www/html/.ddev/.downloads/db.sql.gz and load it on the hosting provider. files_push_command : A script that determines how ddev push user-generated files to upstream. Its job is to copy the files from the project's user-files directory ($DDEV_FILES_DIR) to the correct place on the upstream provider. The environment variables provided to custom commands are also available for use in these recipes. Example Integrations and Hints \u00b6 All of the supplied integrations are really just examples of what you can do. You can name a provider anything you want. For example, an Acquia integration doesn't have to be named \"acquia\", it can be named \"upstream\", for example. This is a great technique for downloading a particular multisite Provider Debugging \u00b6 You can uncomment the set -x in each stanza to see more of what's going on. It really helps. Watch it as you do a ddev pull <whatever> . Although the various commands could be executed on the host or in other containers if configured that way, most commands are executed in the web container. So the best thing to do is to ddev ssh and manually execute each command you want to use. When you have it right, use it in the yaml file.","title":"Hosting Provider Integration"},{"location":"users/providers/#hosting-provider-integration","text":"DDEV offers hosting provider integration and sample integrations for Pantheon.io, Platform.sh and Acquia hosting, along with other examples. The best part of this is you can change them and adapt them in any way you need to, they're all short scripted recipes. There are several example recipes created in the .ddev/providers directory of every project or see them in the code . ddev provides the pull command with whatever recipes you have configured. For example, ddev pull acquia if you have created .ddev/providers/acquia.yaml . ddev also provides the push command to push database and files to upstream. This is very dangerous to your upstream site and should only be used when completely appropriate. It's recommended not even to implement the push stanzas in your yaml file, but if it fits your workflow, use it well. Each provider recipe is a yaml file that can be named any way you want to name it. The examples are mostly named after the hosting providers, but they could be named \"upstream.yaml\" or \"live.yaml\", so you could ddev pull upstream or ddev pull live . If you wanted different upstream environments to pull from, you could name one \"prod\" and one \"dev\" and ddev pull prod and ddev pull dev . Example recipes are provided for Acquia , Local files (like Dropbox, for example), Pantheon.io , Platform.sh , and rsync . We know that you'll find improvements to these examples and will have lots to contribute for other hosting providers, and we look forward to your contributions as pull requests here or in ddev-contrib . Each provider recipe is a file named <provider>.yaml and consists of several mostly-optional stanzas: environment_variables : Environment variables will be created in the web container for each of these during pull or push operations. They're used to provide context (project id, environment name, etc.) for each of the other stanzas. db_pull_command : A script that determines how ddev should obtain a database. It's job is to create a gzipped database dump in /var/www/html/.ddev/.downloads/db.sql.gz. This is optional; if nothing has to be done to obtain the database dump, this step can be omitted. db_import_command : (optional) A script that imports the downloaded database. This is for advanced usages like multiple databases. The default behavior only imports a single database into the db database. The localfile example uses this technique. files_pull_command : A script that determines how ddev can get user-generated files from upstream. Its job is to copy the files from upstream to /var/www/html/.ddev/.downloads/files. If nothing has to be done to obtain the files, this step can simply run true . files_import_command : (optional) A script that imports the downloaded files. There are a number of situations where it's just messy to push a directory of files around, and one can just put it directly where it's needed. The localfile example uses this technique. db_push_command : A script that determines how ddev should push a database. It's job is to take a gzipped database dump from /var/www/html/.ddev/.downloads/db.sql.gz and load it on the hosting provider. files_push_command : A script that determines how ddev push user-generated files to upstream. Its job is to copy the files from the project's user-files directory ($DDEV_FILES_DIR) to the correct place on the upstream provider. The environment variables provided to custom commands are also available for use in these recipes.","title":"Hosting Provider Integration"},{"location":"users/providers/#example-integrations-and-hints","text":"All of the supplied integrations are really just examples of what you can do. You can name a provider anything you want. For example, an Acquia integration doesn't have to be named \"acquia\", it can be named \"upstream\", for example. This is a great technique for downloading a particular multisite","title":"Example Integrations and Hints"},{"location":"users/providers/#provider-debugging","text":"You can uncomment the set -x in each stanza to see more of what's going on. It really helps. Watch it as you do a ddev pull <whatever> . Although the various commands could be executed on the host or in other containers if configured that way, most commands are executed in the web container. So the best thing to do is to ddev ssh and manually execute each command you want to use. When you have it right, use it in the yaml file.","title":"Provider Debugging"},{"location":"users/providers/acquia/","text":"Acquia Integration \u00b6 ddev provides integration with the Acquia Cloud Platform , which allows Acquia users to quickly download and provision a project from Acquia in a local ddev-managed environment. ddev's Acquia integration pulls database and files from an existing project into your local system so you can develop locally. Acquia Quickstart \u00b6 Get your Acquia API token from your Account Settings->API Tokens. Make sure your ssh key is authorized on your Acquia account at Account Settings->SSH Keys ddev auth ssh (this typically needs only be done once per ddev session, not every pull.) Add / update the web_environment section in ~/.ddev/global_config.yaml with the API keys: web_environment : - ACQUIA_API_KEY=xxxxxxxx - ACQUIA_API_SECRET=xxxxx Copy .ddev/providers/acquia.yaml.example to .ddev/providers/acquia.yaml. Update the project_id and database corresponding to the environment you want to work with. If you have acli install, you can use the following command: acli remote:aliases:list Or, on the Acquia Cloud Platform navigate to the environments page, click on the header and look for the \"SSH URL\" line. E.g. project1.dev@cool-projects.acquia-sites.com would have a project ID of project1.dev Your project must include drush; ddev composer require drush/drush if it isn't there already. ddev restart Use ddev pull acquia to pull the project database and files. Optionally use ddev push acquia to push local files and database to Acquia. Note that ddev push is a command that can potentially damage your production site, so this is not recommended. Usage \u00b6 ddev pull acquia will connect to the Acquia Cloud Platform to download database and files. To skip downloading and importing either file or database assets, use the --skip-files and --skip-db flags.","title":"Acquia Integration"},{"location":"users/providers/acquia/#acquia-integration","text":"ddev provides integration with the Acquia Cloud Platform , which allows Acquia users to quickly download and provision a project from Acquia in a local ddev-managed environment. ddev's Acquia integration pulls database and files from an existing project into your local system so you can develop locally.","title":"Acquia Integration"},{"location":"users/providers/acquia/#acquia-quickstart","text":"Get your Acquia API token from your Account Settings->API Tokens. Make sure your ssh key is authorized on your Acquia account at Account Settings->SSH Keys ddev auth ssh (this typically needs only be done once per ddev session, not every pull.) Add / update the web_environment section in ~/.ddev/global_config.yaml with the API keys: web_environment : - ACQUIA_API_KEY=xxxxxxxx - ACQUIA_API_SECRET=xxxxx Copy .ddev/providers/acquia.yaml.example to .ddev/providers/acquia.yaml. Update the project_id and database corresponding to the environment you want to work with. If you have acli install, you can use the following command: acli remote:aliases:list Or, on the Acquia Cloud Platform navigate to the environments page, click on the header and look for the \"SSH URL\" line. E.g. project1.dev@cool-projects.acquia-sites.com would have a project ID of project1.dev Your project must include drush; ddev composer require drush/drush if it isn't there already. ddev restart Use ddev pull acquia to pull the project database and files. Optionally use ddev push acquia to push local files and database to Acquia. Note that ddev push is a command that can potentially damage your production site, so this is not recommended.","title":"Acquia Quickstart"},{"location":"users/providers/acquia/#usage","text":"ddev pull acquia will connect to the Acquia Cloud Platform to download database and files. To skip downloading and importing either file or database assets, use the --skip-files and --skip-db flags.","title":"Usage"},{"location":"users/providers/pantheon/","text":"Pantheon Integration \u00b6 ddev provides configurable integration with the Pantheon Website Management Platform , which allows Pantheon users to quickly download and provision a project from Pantheon in a local ddev-managed environment. ddev's Pantheon integration pulls an existing backup from an existing Pantheon site/environment into your local system. Of course that means you must already have a Pantheon site with a backup in order to use it. Pantheon Quickstart \u00b6 If you have ddev installed, and have an active Pantheon account with an active site, you can follow this guide to spin up a Pantheon project locally. Get your Pantheon.io machine token: a. Login to your Pantheon Dashboard, and Generate a Machine Token for ddev to use. b. Add the API token to the web_environment section in your global ddev configuration at ~/.ddev/global_config.yaml web_environment: - TERMINUS_MACHINE_TOKEN=abcdeyourtoken Choose a Pantheon site and environment you want to use with ddev. You can usually use the site name, but in some environments you may need the site ID, which is the long 3 rd component of your site dashboard URL. So if the site dashboard is at https://dashboard.pantheon.io/sites/009a2cda-2c22-4eee-8f9d-96f017321555#dev/ , the site ID is 009a2cda-2c22-4eee-8f9d-96f017321555 . On the pantheon dashboard for the site, make sure that at least one backup has been created. (When you need to refresh what you pull, create a new backup.) Make sure your public ssh key is configured in Pantheon (Account->SSH Keys) Check out the project codebase from Pantheon. Enable the \"Git Connection Mode\" and use git clone to check out the code locally. Configure the local checkout for ddev using ddev config If using Drupal 8+, verify that drush is installed in your project, ddev composer require drush/drush . If using Drupal 6 or 7, drush8 is already provided in the web container's /usr/local/bin/drush, so you can skip this step. In your project's .ddev/providers directory, copy pantheon.yaml.example to pantheon.yaml ( Note that this refers to your project .ddev folder and not the global .ddev folder ). Edit the project environment variable under environment_variables . It will be in the format <projectname>.<environment> , for example yourprojectname.dev or (in cases of ambiguity) <project_uuid>.<environment> , for example 009a2cda-2c22-4eee-8f9d-96f017321555.dev . ddev restart Run ddev pull pantheon . The ddev environment download the Pantheon database and files, and import the database and files into the ddev environment. You should now be able to access the project locally. Optionally use ddev push pantheon to push local files and database to Pantheon. Note that ddev push is a command that can potentially damage your production site, so this is not recommended.","title":"Pantheon Integration"},{"location":"users/providers/pantheon/#pantheon-integration","text":"ddev provides configurable integration with the Pantheon Website Management Platform , which allows Pantheon users to quickly download and provision a project from Pantheon in a local ddev-managed environment. ddev's Pantheon integration pulls an existing backup from an existing Pantheon site/environment into your local system. Of course that means you must already have a Pantheon site with a backup in order to use it.","title":"Pantheon Integration"},{"location":"users/providers/pantheon/#pantheon-quickstart","text":"If you have ddev installed, and have an active Pantheon account with an active site, you can follow this guide to spin up a Pantheon project locally. Get your Pantheon.io machine token: a. Login to your Pantheon Dashboard, and Generate a Machine Token for ddev to use. b. Add the API token to the web_environment section in your global ddev configuration at ~/.ddev/global_config.yaml web_environment: - TERMINUS_MACHINE_TOKEN=abcdeyourtoken Choose a Pantheon site and environment you want to use with ddev. You can usually use the site name, but in some environments you may need the site ID, which is the long 3 rd component of your site dashboard URL. So if the site dashboard is at https://dashboard.pantheon.io/sites/009a2cda-2c22-4eee-8f9d-96f017321555#dev/ , the site ID is 009a2cda-2c22-4eee-8f9d-96f017321555 . On the pantheon dashboard for the site, make sure that at least one backup has been created. (When you need to refresh what you pull, create a new backup.) Make sure your public ssh key is configured in Pantheon (Account->SSH Keys) Check out the project codebase from Pantheon. Enable the \"Git Connection Mode\" and use git clone to check out the code locally. Configure the local checkout for ddev using ddev config If using Drupal 8+, verify that drush is installed in your project, ddev composer require drush/drush . If using Drupal 6 or 7, drush8 is already provided in the web container's /usr/local/bin/drush, so you can skip this step. In your project's .ddev/providers directory, copy pantheon.yaml.example to pantheon.yaml ( Note that this refers to your project .ddev folder and not the global .ddev folder ). Edit the project environment variable under environment_variables . It will be in the format <projectname>.<environment> , for example yourprojectname.dev or (in cases of ambiguity) <project_uuid>.<environment> , for example 009a2cda-2c22-4eee-8f9d-96f017321555.dev . ddev restart Run ddev pull pantheon . The ddev environment download the Pantheon database and files, and import the database and files into the ddev environment. You should now be able to access the project locally. Optionally use ddev push pantheon to push local files and database to Pantheon. Note that ddev push is a command that can potentially damage your production site, so this is not recommended.","title":"Pantheon Quickstart"},{"location":"users/providers/platform/","text":"Platform.sh Integration \u00b6 ddev provides integration with the Platform.sh Website Management Platform , which allows Platform.sh users to quickly download and provision a project from Platform.sh in a local ddev-managed environment. ddev's Platform.sh integration pulls database and files from an existing Platform.sh site/environment into your local system so you can develop locally. Platform.sh Quickstart \u00b6 Check out the site from platform.sh and then configure it with ddev config . You'll want to use ddev start and make sure the basic functionality is working. Obtain and configure an API token. a. Login to the Platform.sh Dashboard and go to Account->API Tokens to create an API token for ddev to use. b. Add the API token to the web_environment section in your global ddev configuration at ~/.ddev/global_config.yaml: web_environment : - PLATFORMSH_CLI_TOKEN=abcdeyourtoken ddev restart Obtain your project id with ddev exec platform . The platform tool should show you all the information about your account and project. In your project's .ddev/providers directory, copy platform.yaml.example to platform.yaml and edit the project_id and environment_name . Run ddev pull platform . After you agree to the prompt, the current upstream database and files will be downloaded. Optionally use ddev push platform to push local files and database to Platform.sh. Note that ddev push is a command that can potentially damage your production site, so this is not recommended. Usage \u00b6 ddev pull platform will connect to Platform.sh to download database and files. To skip downloading and importing either file or database assets, use the --skip-files and --skip-db flags.","title":"Platform.sh Integration"},{"location":"users/providers/platform/#platformsh-integration","text":"ddev provides integration with the Platform.sh Website Management Platform , which allows Platform.sh users to quickly download and provision a project from Platform.sh in a local ddev-managed environment. ddev's Platform.sh integration pulls database and files from an existing Platform.sh site/environment into your local system so you can develop locally.","title":"Platform.sh Integration"},{"location":"users/providers/platform/#platformsh-quickstart","text":"Check out the site from platform.sh and then configure it with ddev config . You'll want to use ddev start and make sure the basic functionality is working. Obtain and configure an API token. a. Login to the Platform.sh Dashboard and go to Account->API Tokens to create an API token for ddev to use. b. Add the API token to the web_environment section in your global ddev configuration at ~/.ddev/global_config.yaml: web_environment : - PLATFORMSH_CLI_TOKEN=abcdeyourtoken ddev restart Obtain your project id with ddev exec platform . The platform tool should show you all the information about your account and project. In your project's .ddev/providers directory, copy platform.yaml.example to platform.yaml and edit the project_id and environment_name . Run ddev pull platform . After you agree to the prompt, the current upstream database and files will be downloaded. Optionally use ddev push platform to push local files and database to Platform.sh. Note that ddev push is a command that can potentially damage your production site, so this is not recommended.","title":"Platform.sh Quickstart"},{"location":"users/providers/platform/#usage","text":"ddev pull platform will connect to Platform.sh to download database and files. To skip downloading and importing either file or database assets, use the --skip-files and --skip-db flags.","title":"Usage"},{"location":"users/topics/cms_specific_help/","text":"Controlling CMS Settings Files in DDEV \u00b6 One DDEV feature that lots of people love is its creation and management of CMS-specific settings files. This makes starting and installing a new project a breeze, and is a fantastic time-saver for many users. People can follow one of the many DDEV-Local Quickstart Guides and have a project up and installed in no time. To make this happen, DDEV-Local does a quite a bit of settings management for explicitly supported CMSs. DDEV will: Create a main settings file if none exists (like Drupal's settings.php). Create a specialty config file with DDEV-specific settings (like AdditionalSettings.php for TYPO3 or settings.ddev.php for Drupal). Add an include of the specialty file if needed (like adding settings.ddev.php include to the bottom of settings.php for Drupal. This really helps new users and people who are kicking the tires on a CMS. Plus it's helpful for many developers in their regular workflow. However, there are plenty of you who have sophisticated team and project workflows and don't want DDEV to manage settings files, or prefer to manage your own. DDEV has always tried to give you control as needed: If you don't want DDEV to touch a file, remove the #ddev-generated line from that file, empty it or put your own contents in it, and check it into version control. DDEV will then ignore that file and not try to regenerate it. If you later want DDEV to take that file over again, just remove the one that you edited and ddev start and ddev will create its own version. (You may have to remove it from your git project if you added it). If you don't want DDEV to even know what kind of CMS (or other project) you have, just use type: php in your .ddev/config.yaml (or run ddev config --project-type=php ). DDEV will no longer create or tweak any settings files, you're now on your own (The one drawback of this approach is that you don't get the nginx configuration which has been tweaked for your CMS. But, as always, you can create your own nginx or apache configurations.) ( docs ). If you want DDEV to know about the project type, but not create settings files, use disable_settings_management: true . If you want DDEV to use the CMS-specific nginx configuration, but don't want it to touch anything else, you can put disable_settings_management: true in your .ddev/config.yaml (or run ddev config --disable-settings-management ) and DDEV won't try to create any of the CMS-specific settings files. There is also an environment variable $IS_DDEV_PROJECT that can be used to fence off DDEV-specific behavior. For example, with $IS_DDEV_PROJECT empty, the important parts of settings.ddev.php and AdditionalSettings.php (for TYPO3) are not executed. This means that DDEV's settings.ddev.php won't be invoked if it somehow ends up in a production environment or in a non-DDEV local development environment. The .ddev/.gitignore is created by ddev start because it gitignores itself. So the intention is that you should not check in the .ddev/.gitignore and it will be created on start if disable_settings_management is false. This helps teams to share .ddev folder checked in by git, even if the .ddev/.gitignore changes with different versions. CMS-Specific Help and Techniques \u00b6 Drupal Specifics \u00b6 Settings Files : By default, DDEV will create settings files for your project that make it \"just work\" out of the box. It creates a sites/default/settings.ddev.php and adds an include in sites/default/settings.php to bring that in. There are guards to prevent the settings.ddev.php from being active when the project is not running under DDEV, but it still should not be checked in and is gitignored. TYPO3 Specifics \u00b6 Settings Files : On ddev start , DDEV creates a public/typo3conf/AdditionalConfiguration.php with database configuration in it. Setup a Base Variant (since TYPO3 9.5) \u00b6 Since TYPO3 9.5 you have to setup a Site Configuration for each site you like to serve. To be able to browse the site on your local environment you have to setup a Base Variant in your Site Configuration depending on your local context. In this example we assume a Application Context Development/DDEV which can be set in the DDEV's config.yaml : web_environment : - TYPO3_CONTEXT=Development/DDEV This variable will be available after the project start or restart. Afterwards add a Base Variant to your Site Configuration : baseVariants : - base : 'https://example.com.ddev.site/' condition : 'applicationContext == \"Development/DDEV\"' See also TYPO3 Documentation . Running any PHP App with DDEV \u00b6 Nearly any PHP app will run fine with DDEV, and lots of others. If your project type is not one of the explicitly supported project types, that's fine. Just set the project type to 'php' and go about setting up settings files or .env as you normally would.","title":"Controlling CMS Settings Files in DDEV"},{"location":"users/topics/cms_specific_help/#controlling-cms-settings-files-in-ddev","text":"One DDEV feature that lots of people love is its creation and management of CMS-specific settings files. This makes starting and installing a new project a breeze, and is a fantastic time-saver for many users. People can follow one of the many DDEV-Local Quickstart Guides and have a project up and installed in no time. To make this happen, DDEV-Local does a quite a bit of settings management for explicitly supported CMSs. DDEV will: Create a main settings file if none exists (like Drupal's settings.php). Create a specialty config file with DDEV-specific settings (like AdditionalSettings.php for TYPO3 or settings.ddev.php for Drupal). Add an include of the specialty file if needed (like adding settings.ddev.php include to the bottom of settings.php for Drupal. This really helps new users and people who are kicking the tires on a CMS. Plus it's helpful for many developers in their regular workflow. However, there are plenty of you who have sophisticated team and project workflows and don't want DDEV to manage settings files, or prefer to manage your own. DDEV has always tried to give you control as needed: If you don't want DDEV to touch a file, remove the #ddev-generated line from that file, empty it or put your own contents in it, and check it into version control. DDEV will then ignore that file and not try to regenerate it. If you later want DDEV to take that file over again, just remove the one that you edited and ddev start and ddev will create its own version. (You may have to remove it from your git project if you added it). If you don't want DDEV to even know what kind of CMS (or other project) you have, just use type: php in your .ddev/config.yaml (or run ddev config --project-type=php ). DDEV will no longer create or tweak any settings files, you're now on your own (The one drawback of this approach is that you don't get the nginx configuration which has been tweaked for your CMS. But, as always, you can create your own nginx or apache configurations.) ( docs ). If you want DDEV to know about the project type, but not create settings files, use disable_settings_management: true . If you want DDEV to use the CMS-specific nginx configuration, but don't want it to touch anything else, you can put disable_settings_management: true in your .ddev/config.yaml (or run ddev config --disable-settings-management ) and DDEV won't try to create any of the CMS-specific settings files. There is also an environment variable $IS_DDEV_PROJECT that can be used to fence off DDEV-specific behavior. For example, with $IS_DDEV_PROJECT empty, the important parts of settings.ddev.php and AdditionalSettings.php (for TYPO3) are not executed. This means that DDEV's settings.ddev.php won't be invoked if it somehow ends up in a production environment or in a non-DDEV local development environment. The .ddev/.gitignore is created by ddev start because it gitignores itself. So the intention is that you should not check in the .ddev/.gitignore and it will be created on start if disable_settings_management is false. This helps teams to share .ddev folder checked in by git, even if the .ddev/.gitignore changes with different versions.","title":"Controlling CMS Settings Files in DDEV"},{"location":"users/topics/cms_specific_help/#cms-specific-help-and-techniques","text":"","title":"CMS-Specific Help and Techniques"},{"location":"users/topics/cms_specific_help/#drupal-specifics","text":"Settings Files : By default, DDEV will create settings files for your project that make it \"just work\" out of the box. It creates a sites/default/settings.ddev.php and adds an include in sites/default/settings.php to bring that in. There are guards to prevent the settings.ddev.php from being active when the project is not running under DDEV, but it still should not be checked in and is gitignored.","title":"Drupal Specifics"},{"location":"users/topics/cms_specific_help/#typo3-specifics","text":"Settings Files : On ddev start , DDEV creates a public/typo3conf/AdditionalConfiguration.php with database configuration in it.","title":"TYPO3 Specifics"},{"location":"users/topics/cms_specific_help/#setup-a-base-variant-since-typo3-95","text":"Since TYPO3 9.5 you have to setup a Site Configuration for each site you like to serve. To be able to browse the site on your local environment you have to setup a Base Variant in your Site Configuration depending on your local context. In this example we assume a Application Context Development/DDEV which can be set in the DDEV's config.yaml : web_environment : - TYPO3_CONTEXT=Development/DDEV This variable will be available after the project start or restart. Afterwards add a Base Variant to your Site Configuration : baseVariants : - base : 'https://example.com.ddev.site/' condition : 'applicationContext == \"Development/DDEV\"' See also TYPO3 Documentation .","title":"Setup a Base Variant (since TYPO3 9.5)"},{"location":"users/topics/cms_specific_help/#running-any-php-app-with-ddev","text":"Nearly any PHP app will run fine with DDEV, and lots of others. If your project type is not one of the explicitly supported project types, that's fine. Just set the project type to 'php' and go about setting up settings files or .env as you normally would.","title":"Running any PHP App with DDEV"},{"location":"users/topics/phpstorm/","text":"PhpStorm Configuration and Integration \u00b6 Full Integration with Docker, DDEV, and PhpStorm \u00b6 This explores how to add full PhpStorm integration with a DDEV project, including composer and phpunit. It works on all OS platforms, including macOS and WSL2. This is based on the wonderful article by Susanne Moog , and couldn't have been done without it, but since PhpStorm has fixed some things and DDEV has worked around others, this is far easier now. It works on macOS, Linux, Windows with WSL2 and Windows traditional. You'll end up with PhpStorm actually using the PHP interpreter inside the ddev-webserver container of your project, and able to use composer and phpunit inside there as well. Requirements \u00b6 PhpStorm 2021.3 or higher You may need to add the PHP Docker plugin. You need to enable Compose V2 Support in PHPStorm. This can be done in Settings/Preferences | Build, Execution, Deployment | Docker | Tools by either set the bundled docker-compose binary as Docker Compose executable which can be found in ~/.ddev/bin . (Suggested for WSL) enabling Use Compose V2 in PHPStorm and your Docker installation. Any OS platform, but if you're using Windows PhpStorm with WSL2 the path mappings are slightly more complex. WSL2 instructions are provided where necessary. Setup Technique \u00b6 Open a DDEV project. In this example, the project name is \"d9\" and the site is \"d9.ddev.site\". If you're on Windows, running PhpStorm on the Windows side but using WSL2 for your DDEV project, open the project as a WSL2 project. In other words, in the \"Open\" dialog, browse to \\\\wsl$\\Ubuntu\\home\\rfay\\workspace\\d9 (in this example). (If you're running PhpStorm inside WSL2, there are no special instructions.) Set up your project to do normal Xdebug, as described in the Step Debugging section . This will result in a PhpStorm \"Server\" with the proper name, normally the same as the FQDN of the project. In this example, \"d9.ddev.site\". (All you have to do here is click the little telephone to \"Start listening for PHP Debug Connections\", then ddev xdebug on , then visit a web page and choose the correct mapping from host to server. ) Under File\u2192Settings\u2192PHP (Windows) or Preferences\u2192PHP (macOS), click the \"...\" to the right of \"CLI Interpreter\" Use the \"+\" to select \"From Docker, Vagrant, VM...\" Choose \"Docker Compose\" Create a server; the default name is \"docker\", but since the \"server\" for each project will be different, name it for the project, for example \"DDEV d9\". Choose \"Docker for Windows\" or \"Docker for Mac\" In the \"Path mappings\" of the \"Server\" you may have to map the local paths (which on WSL2 means /home/...) to the in-container paths, especially if you have mutagen enabled. So \"Virtual Machine Path\" would be \"/var/www/html\" and \"Local path\" would be something like /Users/rfay/workspace/d9 (on macOS) or \\\\wsl$\\Ubuntu\\home\\rfay\\workspace\\d9 on Windows using WSL2. Now back in the \"Configure Remote PHP Interpreter\" for \"Configuration files\" use .ddev/.ddev-docker-compose-full.yaml . On macOS, you may need to use <cmd><shift>. , (Command+Shift+Dot) to show hidden dotfiles. Service: web Add an environment variable COMPOSE_PROJECT_NAME=ddev-<projectname> . In this case, it's ddev-d9 . (Note that DDEV project names that contain dots do not currently work due to a PhpStorm bug . You'll need to rename your project to get these instructions to work.) In the CLI interpreter \"Lifecycle\" select \"Connect to existing container\" In the PHP Interpreter path, you can just put php if you're using the default PHP version (currently 7.4). Due to a PhpStorm bug you'll want to put the full name of the binary, like php8.0 if you're not using the default version. Here's an example filled out In the main PHP setup dialog, add an entry to the path mappings, as it doesn't correctly derive the full path mapping. Add an entry that maps your project location to /var/www/html. So in this example, the Local Path is /Users/rfay/workspace/d9 and the Remote Path is /var/www/html. Configure composer under PHP\u2192Composer. Use \"remote interpreter\" CLI Interpreter will be \"web\" Under \"Test Frameworks\" click the \"+\" to add phpunit PHPUnit by remote interpreter Interpreter \"web\" Choose \"Path to phpunit.phar\" and use /var/www/html/vendor/bin/phpunit (or wherever your phpunit is inside the container). You need phpunit properly composer-installed for your CMS. For example, for Drupal 9, ddev composer require --dev --with-all-dependencies drupal/core-dev:^9 and ddev composer require --dev phpspec/prophecy-phpunit:^2 Default configuration file: /var/www/html/web/core/phpunit.xml or wherever yours is inside the container. Open Run/Debug configurations and use the \"+\" to add a phpunit configuration. Give it a name Test scope (as you wish, by directory or class or whatever) Interpreter: \"web\" (the one we set up) Enable Xdebug if you want to debug tests. ddev xdebug on Run the runner that you created. Notes: This was developed with input from many others in https://github.com/drud/ddev/issues/3130 ( @eojthebrave ) has a great explanation of the whole thing, including Chromedriver and focused on Drupal in the excellent Drupalize.me article Debug any of Drupal's PHPUnit tests in PhpStorm with a DDEV-Local Environment PhpStorm Basic Setup on Windows WSL2 \u00b6 It is possible right now to use PHPStorm with DDEV-Local on WSL2 in at least two different ways: Run PhPStorm in Windows as usual, opening the project on the WSL2 filesystem at \\\\wsl$\\<distro> (for example, \\\\wsl$\\Ubuntu ). PHPStorm is slow to index files and is slow to respond to file changes in this mode. Enabling X11 on Windows and running PHPStorm inside WSL2 as a Linux app. PHPStorm works fine this way, but it\u2019s yet another complexity to manage and requires enabling X11 (easy) on your Windows system. We\u2019ll walk through both of these approaches. (JetBrains is really working to catch up with the slick WSL2 support of vscode. A third option is the Projector app, which runs PhpStorm on WSL2 (or anywhere else) but displays it in a browser.) Basics \u00b6 Start with a working DDEV/WSL2 setup as described in the docs . Until that\u2019s all working it doesn\u2019t help to go farther. If you haven\u2019t used Xdebug with DDEV-Local and PHPStorm before, you\u2019ll want to read the step debugging instructions . For good performance, you want your project to be in /home inside WSL2, which is on the Linux filesystem. Although you can certainly keep your project on the Windows filesystem and access it in WSL2 via /mnt/c, the performance is even worse than native Windows. It does work though, but don't do it. You'll be miserable. PhpStorm Running On Windows Side \u00b6 Your working project should be on the /home partition, so you\u2019ll open it using Windows PHPStorm as \\\\wsl$\\Ubuntu\\home\\<username>\\...\\<projectdir> . On some systems and some projects it may take a very long time for PHPStorm to index the files. At one point I got frustrated and moved to a faster computer. File changes are noticed only by polling, and PHPStorm will complain about this in the lower right, \u201cExternal file changes sync may be slow\u201d. Turn off your Windows firewall temporarily. When you have everything working you can turn it back on again. Use ddev start and ddev xdebug on Click the Xdebug listen button on PHPStorm (the little phone icon) to make it start listening. Set a breakpoint on or near the first line of your index.php Visit the project with a web browser or curl. You should get a popup asking for mapping of the host-side files to the in-container files. You\u2019ll want to make sure that /home/<you>/.../<yourproject> gets mapped to /var/www/html Debugging should be working! You can step through your code, set breakpoints, view variables, etc. (Nice to have) I set the PHPStorm terminal path (Settings\u2192Tools\u2192Terminal\u2192Shell Path) to C:\\Windows\\System32\\wsl.exe. That way when I use the terminal Window in WSL2 it\u2019s using the wonderful bash shell in WSL2. PHPStorm inside WSL2 in Linux \u00b6 On Windows 11 you don't need to install an X11 server, because WSLg is included by default. On older Windows 10, Install X410 from the Microsoft Store, launch it, configure in the system tray with \u201cWindowed Apps\u201d, \u201cAllow public access\u201d, \u201cDPI Scaling\u201d\u2192\u201dHigh quality\u201d. Obviously you can any other X11 server, but this is the one I\u2019ve used. Temporarily disable your Windows firewall. You can re-enable it after you get everything working. If you're on older Windows 10, in the WSL2 terminal export DISPLAY=$(awk '/^nameserver/ {print $2; exit;}' </etc/resolv.conf):0.0 (You\u2019ll want to add this to your .profile in WSL2). This sets the X11 DISPLAY variable to point to your Windows host side. On Windows 11 this \"just works\" and you don't need to do anything here. On Windows 11, sudo apt-get update && sudo apt-get install xdg-utils . On older Windows 10, sudo apt-get update && sudo apt-get install libatk1.0 libatk-bridge2.0 libxtst6 libxi6 libpangocairo-1.0 libcups2 libnss3 xdg-utils x11-apps On older Windows 10, run xeyes \u2013 you should see the classic X11 play app \u201cxeyes\u201d on the screen. to exit. This is just a test to make sure X11 is working. Download and untar PHPStorm for Linux from Jetbrains \u2013 you need the Linux app. Run bin/phpstorm.sh & In PHPStorm, under Help\u2192 Edit Custom VM Options, add an additional line: -Djava.net.preferIPv4Stack=true This makes PHPStorm listen for Xdebug using IPV4; for some reason the Linux version of PHPStorm defaults to using only IPV6, and Docker Desktop doesn't support IPV6. Restart PHPStorm ( File\u2192Exit and then bin/phpstorm.sh & again. Use ddev start and ddev xdebug on Click the Xdebug listen button in PHPStorm (the little phone icon) to make it start listening. Set a breakpoint on or near the first line of your index.php Visit the project with a web browser or curl. You should get a popup asking for mapping of the host-side files to the in-container files. You\u2019ll want to make sure that /home/<you>/.../<yourproject> gets mapped to /var/www/html . Debugging should be working! You can step through your code, set breakpoints, view variables, etc.","title":"PhpStorm Configuration and Integration"},{"location":"users/topics/phpstorm/#phpstorm-configuration-and-integration","text":"","title":"PhpStorm Configuration and Integration"},{"location":"users/topics/phpstorm/#full-integration-with-docker-ddev-and-phpstorm","text":"This explores how to add full PhpStorm integration with a DDEV project, including composer and phpunit. It works on all OS platforms, including macOS and WSL2. This is based on the wonderful article by Susanne Moog , and couldn't have been done without it, but since PhpStorm has fixed some things and DDEV has worked around others, this is far easier now. It works on macOS, Linux, Windows with WSL2 and Windows traditional. You'll end up with PhpStorm actually using the PHP interpreter inside the ddev-webserver container of your project, and able to use composer and phpunit inside there as well.","title":"Full Integration with Docker, DDEV, and PhpStorm"},{"location":"users/topics/phpstorm/#requirements","text":"PhpStorm 2021.3 or higher You may need to add the PHP Docker plugin. You need to enable Compose V2 Support in PHPStorm. This can be done in Settings/Preferences | Build, Execution, Deployment | Docker | Tools by either set the bundled docker-compose binary as Docker Compose executable which can be found in ~/.ddev/bin . (Suggested for WSL) enabling Use Compose V2 in PHPStorm and your Docker installation. Any OS platform, but if you're using Windows PhpStorm with WSL2 the path mappings are slightly more complex. WSL2 instructions are provided where necessary.","title":"Requirements"},{"location":"users/topics/phpstorm/#setup-technique","text":"Open a DDEV project. In this example, the project name is \"d9\" and the site is \"d9.ddev.site\". If you're on Windows, running PhpStorm on the Windows side but using WSL2 for your DDEV project, open the project as a WSL2 project. In other words, in the \"Open\" dialog, browse to \\\\wsl$\\Ubuntu\\home\\rfay\\workspace\\d9 (in this example). (If you're running PhpStorm inside WSL2, there are no special instructions.) Set up your project to do normal Xdebug, as described in the Step Debugging section . This will result in a PhpStorm \"Server\" with the proper name, normally the same as the FQDN of the project. In this example, \"d9.ddev.site\". (All you have to do here is click the little telephone to \"Start listening for PHP Debug Connections\", then ddev xdebug on , then visit a web page and choose the correct mapping from host to server. ) Under File\u2192Settings\u2192PHP (Windows) or Preferences\u2192PHP (macOS), click the \"...\" to the right of \"CLI Interpreter\" Use the \"+\" to select \"From Docker, Vagrant, VM...\" Choose \"Docker Compose\" Create a server; the default name is \"docker\", but since the \"server\" for each project will be different, name it for the project, for example \"DDEV d9\". Choose \"Docker for Windows\" or \"Docker for Mac\" In the \"Path mappings\" of the \"Server\" you may have to map the local paths (which on WSL2 means /home/...) to the in-container paths, especially if you have mutagen enabled. So \"Virtual Machine Path\" would be \"/var/www/html\" and \"Local path\" would be something like /Users/rfay/workspace/d9 (on macOS) or \\\\wsl$\\Ubuntu\\home\\rfay\\workspace\\d9 on Windows using WSL2. Now back in the \"Configure Remote PHP Interpreter\" for \"Configuration files\" use .ddev/.ddev-docker-compose-full.yaml . On macOS, you may need to use <cmd><shift>. , (Command+Shift+Dot) to show hidden dotfiles. Service: web Add an environment variable COMPOSE_PROJECT_NAME=ddev-<projectname> . In this case, it's ddev-d9 . (Note that DDEV project names that contain dots do not currently work due to a PhpStorm bug . You'll need to rename your project to get these instructions to work.) In the CLI interpreter \"Lifecycle\" select \"Connect to existing container\" In the PHP Interpreter path, you can just put php if you're using the default PHP version (currently 7.4). Due to a PhpStorm bug you'll want to put the full name of the binary, like php8.0 if you're not using the default version. Here's an example filled out In the main PHP setup dialog, add an entry to the path mappings, as it doesn't correctly derive the full path mapping. Add an entry that maps your project location to /var/www/html. So in this example, the Local Path is /Users/rfay/workspace/d9 and the Remote Path is /var/www/html. Configure composer under PHP\u2192Composer. Use \"remote interpreter\" CLI Interpreter will be \"web\" Under \"Test Frameworks\" click the \"+\" to add phpunit PHPUnit by remote interpreter Interpreter \"web\" Choose \"Path to phpunit.phar\" and use /var/www/html/vendor/bin/phpunit (or wherever your phpunit is inside the container). You need phpunit properly composer-installed for your CMS. For example, for Drupal 9, ddev composer require --dev --with-all-dependencies drupal/core-dev:^9 and ddev composer require --dev phpspec/prophecy-phpunit:^2 Default configuration file: /var/www/html/web/core/phpunit.xml or wherever yours is inside the container. Open Run/Debug configurations and use the \"+\" to add a phpunit configuration. Give it a name Test scope (as you wish, by directory or class or whatever) Interpreter: \"web\" (the one we set up) Enable Xdebug if you want to debug tests. ddev xdebug on Run the runner that you created. Notes: This was developed with input from many others in https://github.com/drud/ddev/issues/3130 ( @eojthebrave ) has a great explanation of the whole thing, including Chromedriver and focused on Drupal in the excellent Drupalize.me article Debug any of Drupal's PHPUnit tests in PhpStorm with a DDEV-Local Environment","title":"Setup Technique"},{"location":"users/topics/phpstorm/#phpstorm-basic-setup-on-windows-wsl2","text":"It is possible right now to use PHPStorm with DDEV-Local on WSL2 in at least two different ways: Run PhPStorm in Windows as usual, opening the project on the WSL2 filesystem at \\\\wsl$\\<distro> (for example, \\\\wsl$\\Ubuntu ). PHPStorm is slow to index files and is slow to respond to file changes in this mode. Enabling X11 on Windows and running PHPStorm inside WSL2 as a Linux app. PHPStorm works fine this way, but it\u2019s yet another complexity to manage and requires enabling X11 (easy) on your Windows system. We\u2019ll walk through both of these approaches. (JetBrains is really working to catch up with the slick WSL2 support of vscode. A third option is the Projector app, which runs PhpStorm on WSL2 (or anywhere else) but displays it in a browser.)","title":"PhpStorm Basic Setup on Windows WSL2"},{"location":"users/topics/phpstorm/#basics","text":"Start with a working DDEV/WSL2 setup as described in the docs . Until that\u2019s all working it doesn\u2019t help to go farther. If you haven\u2019t used Xdebug with DDEV-Local and PHPStorm before, you\u2019ll want to read the step debugging instructions . For good performance, you want your project to be in /home inside WSL2, which is on the Linux filesystem. Although you can certainly keep your project on the Windows filesystem and access it in WSL2 via /mnt/c, the performance is even worse than native Windows. It does work though, but don't do it. You'll be miserable.","title":"Basics"},{"location":"users/topics/phpstorm/#phpstorm-running-on-windows-side","text":"Your working project should be on the /home partition, so you\u2019ll open it using Windows PHPStorm as \\\\wsl$\\Ubuntu\\home\\<username>\\...\\<projectdir> . On some systems and some projects it may take a very long time for PHPStorm to index the files. At one point I got frustrated and moved to a faster computer. File changes are noticed only by polling, and PHPStorm will complain about this in the lower right, \u201cExternal file changes sync may be slow\u201d. Turn off your Windows firewall temporarily. When you have everything working you can turn it back on again. Use ddev start and ddev xdebug on Click the Xdebug listen button on PHPStorm (the little phone icon) to make it start listening. Set a breakpoint on or near the first line of your index.php Visit the project with a web browser or curl. You should get a popup asking for mapping of the host-side files to the in-container files. You\u2019ll want to make sure that /home/<you>/.../<yourproject> gets mapped to /var/www/html Debugging should be working! You can step through your code, set breakpoints, view variables, etc. (Nice to have) I set the PHPStorm terminal path (Settings\u2192Tools\u2192Terminal\u2192Shell Path) to C:\\Windows\\System32\\wsl.exe. That way when I use the terminal Window in WSL2 it\u2019s using the wonderful bash shell in WSL2.","title":"PhpStorm Running On Windows Side"},{"location":"users/topics/phpstorm/#phpstorm-inside-wsl2-in-linux","text":"On Windows 11 you don't need to install an X11 server, because WSLg is included by default. On older Windows 10, Install X410 from the Microsoft Store, launch it, configure in the system tray with \u201cWindowed Apps\u201d, \u201cAllow public access\u201d, \u201cDPI Scaling\u201d\u2192\u201dHigh quality\u201d. Obviously you can any other X11 server, but this is the one I\u2019ve used. Temporarily disable your Windows firewall. You can re-enable it after you get everything working. If you're on older Windows 10, in the WSL2 terminal export DISPLAY=$(awk '/^nameserver/ {print $2; exit;}' </etc/resolv.conf):0.0 (You\u2019ll want to add this to your .profile in WSL2). This sets the X11 DISPLAY variable to point to your Windows host side. On Windows 11 this \"just works\" and you don't need to do anything here. On Windows 11, sudo apt-get update && sudo apt-get install xdg-utils . On older Windows 10, sudo apt-get update && sudo apt-get install libatk1.0 libatk-bridge2.0 libxtst6 libxi6 libpangocairo-1.0 libcups2 libnss3 xdg-utils x11-apps On older Windows 10, run xeyes \u2013 you should see the classic X11 play app \u201cxeyes\u201d on the screen. to exit. This is just a test to make sure X11 is working. Download and untar PHPStorm for Linux from Jetbrains \u2013 you need the Linux app. Run bin/phpstorm.sh & In PHPStorm, under Help\u2192 Edit Custom VM Options, add an additional line: -Djava.net.preferIPv4Stack=true This makes PHPStorm listen for Xdebug using IPV4; for some reason the Linux version of PHPStorm defaults to using only IPV6, and Docker Desktop doesn't support IPV6. Restart PHPStorm ( File\u2192Exit and then bin/phpstorm.sh & again. Use ddev start and ddev xdebug on Click the Xdebug listen button in PHPStorm (the little phone icon) to make it start listening. Set a breakpoint on or near the first line of your index.php Visit the project with a web browser or curl. You should get a popup asking for mapping of the host-side files to the in-container files. You\u2019ll want to make sure that /home/<you>/.../<yourproject> gets mapped to /var/www/html . Debugging should be working! You can step through your code, set breakpoints, view variables, etc.","title":"PHPStorm inside WSL2 in Linux"},{"location":"users/topics/sharing/","text":"Sharing your project with others \u00b6 Even though DDEV is intended for local development on a single machine, not as a public server, there are a number of reasons you might want to expose your work in progress more broadly: Testing with a mobile device Sharing on a local network so that everybody on the local network can see your project Some CI applications There are at least three different ways to share a running DDEV-Local project outside the local developer machine: ddev share (using ngrok to share over the internet) Local name resolution and sharing the project on the local network Sharing just the http port of the local machine on the local network Using ddev share to share project (easiest) \u00b6 ddev share proxies the project via ngrok , and it's by far the easiest way to solve the problem of sharing your project with others on your team or around the world. It's built into ddev and \"just works\" for most people, but it does require a free or paid account on ngrok.com . All you do is run ddev share and then give the resultant URL to your collaborator or use it on your mobile device. Read the basic how-to from DrupalEasy or run ddev share -h for more. There are CMSs that make this a little harder, especially WordPress and Magento 2. Both of those only respond to a single base URL, and that URL is coded into the database, so it makes this a little harder. For both of these I recommend paying ngrok the $5/month for a basic plan so you can use a stable subdomain with ngrok. Setting up a stable subdomain with ngrok \u00b6 Get a paid token with at least the basic plan, and configure it. It will be in ~/.ngrok2/ngrok.yml as authtoken. Configure ngrok_args to use a stable subdomain. In .ddev/config.yaml , ngrok_args: --subdomain wp23 will result in ngrok always using \"wp23.ngrok.io\" as the URL, so it's not changing on you all the time. WordPress: Change the URL with wp search-replace \u00b6 WordPress only has the one base URL, but the wp command is built into DDEV-Local's web container. This set of steps assumes an ngrok subdomain of \"wp23\" and a starting URL of https://wordpress.ddev.site . Configure .ddev/config.yaml to use a custom subdomain: ngrok_args: --subdomain wp23 Make a backup of your database with ddev export-db or ddev shapshot Edit wp-config-ddev.php (or whatever your config is) to change WP_HOME, for example, define('WP_HOME', 'https://wp23.ngrok.io'); ddev wp search-replace https://wordpress.ddev.site https://wp23.ngrok.io (assuming your project is configured for https://wordpress.ddev.site and your ngrok_args are configured for the wp23 subdomain) Now ddev share Magento2: Change the URL with magento tool \u00b6 This set of steps assumes an ngrok subdomain \"mg2\" Configure .ddev/config.yaml to use a custom subdomain: ngrok_args: --subdomain mg2 Make a backup of your database. Edit your .ddev/config.yaml ddev ssh and bin/magento setup:store-config:set --base-url=\"https://mg2.ngrok.io/ ddev share and you'll see your project on mg2.ngrok.io Using nip.io and or your own name resolution and open up to the local network \u00b6 Another solution is to not use *.ddev.site as your project URLs, but to use DNS that you control (and that points to the host machine where your project lives). In general, you'll want to use http URLs with this approach, because it requires manual configuration of the client machine to get it to trust the development certificate that ddev uses (and configures with mkcert on the local machine). Use nip.io to point a domain name to your host. If your computer's IP address is 192.168.5.101, you can use a domain name like mysite.192.168.5.101.nip.io and that domain name will point to your computer. Now add that as an additional_fqdn to your project, ddev config --additional-fqdns=mysite.192.168.5.101.nip.io and ddev start . Now people in your internal network should be able to ping mysite.192.168.5.101.nip.io if your firewall allows it. (Note that if you have other convenient ways to create a DNS entry for this, you can use those instead of using nip.io.) Configure ~/.ddev/global_config.yaml to bind to all ports: ddev config global --router-bind-all-interfaces && ddev poweroff && ddev start Now mobile apps or other computers which are on your local network should be able to access your project. Use the http URL rather than the https URL because computers outside yours don't know how to trust the developer TLS certificate you're using. (You can use ddev describe to see the http URL, but it's typically the same as the https URL, but with \"http\" instead of \"https\".) Make sure your firewall allows access from your local network to the main interface you're using. In the example here you should be able to ping 192.168.5.101 and curl http://192.168.5.101 and get an answer in each case. If you're using WordPress or Magento 2 you'll need to change the base URL as described in the ddev share instructions above. Exposing just a port from the host and providing a direct URL \u00b6 DDEV's web container also exposes an HTTP port directly (in addition to the normal routing by name and via ddev_router). You can expose this port and it may be a useful approach in some situations. Configure the project host_webserver_port to a known port (that does not conflict with already configured ports). For example, using port 8080, ddev config --host-webserver-port=8080 --bind-all-interfaces . This will configure the host-bound port to 8080 and allow it to bind to all network interfaces so colleagues (or hackers) on your local network can access this project's ports. Make sure your firewall allows access to the port on your host machine. If you're using WordPress or Magento 2 you'll need to change the base URL as described in the ddev share instructions above. Each project on your computer must use different ports or you'll have port conflicts, and you can't typically use ports 80 or 443 because ddev-router is already using those for normal routing. If you don't want to run ddev-router at all you can actually omit it globally, ddev config global --omit-containers=ddev-router . This is a specialty thing to do, when you don't need the reverse proxy at all for anything, as for DrupalPod or other GitPod applications. Computers and mobile devices on your local network should now be able to access port 8080, on the (example) host address 192.168.5.23, so http://192.168.5.23:8080 You'll probably want to use the http URL; your coworker's browser will not trust the developer TLS certificate you're using.","title":"Sharing your project with others"},{"location":"users/topics/sharing/#sharing-your-project-with-others","text":"Even though DDEV is intended for local development on a single machine, not as a public server, there are a number of reasons you might want to expose your work in progress more broadly: Testing with a mobile device Sharing on a local network so that everybody on the local network can see your project Some CI applications There are at least three different ways to share a running DDEV-Local project outside the local developer machine: ddev share (using ngrok to share over the internet) Local name resolution and sharing the project on the local network Sharing just the http port of the local machine on the local network","title":"Sharing your project with others"},{"location":"users/topics/sharing/#using-ddev-share-to-share-project-easiest","text":"ddev share proxies the project via ngrok , and it's by far the easiest way to solve the problem of sharing your project with others on your team or around the world. It's built into ddev and \"just works\" for most people, but it does require a free or paid account on ngrok.com . All you do is run ddev share and then give the resultant URL to your collaborator or use it on your mobile device. Read the basic how-to from DrupalEasy or run ddev share -h for more. There are CMSs that make this a little harder, especially WordPress and Magento 2. Both of those only respond to a single base URL, and that URL is coded into the database, so it makes this a little harder. For both of these I recommend paying ngrok the $5/month for a basic plan so you can use a stable subdomain with ngrok.","title":"Using ddev share to share project (easiest)"},{"location":"users/topics/sharing/#setting-up-a-stable-subdomain-with-ngrok","text":"Get a paid token with at least the basic plan, and configure it. It will be in ~/.ngrok2/ngrok.yml as authtoken. Configure ngrok_args to use a stable subdomain. In .ddev/config.yaml , ngrok_args: --subdomain wp23 will result in ngrok always using \"wp23.ngrok.io\" as the URL, so it's not changing on you all the time.","title":"Setting up a stable subdomain with ngrok"},{"location":"users/topics/sharing/#wordpress-change-the-url-with-wp-search-replace","text":"WordPress only has the one base URL, but the wp command is built into DDEV-Local's web container. This set of steps assumes an ngrok subdomain of \"wp23\" and a starting URL of https://wordpress.ddev.site . Configure .ddev/config.yaml to use a custom subdomain: ngrok_args: --subdomain wp23 Make a backup of your database with ddev export-db or ddev shapshot Edit wp-config-ddev.php (or whatever your config is) to change WP_HOME, for example, define('WP_HOME', 'https://wp23.ngrok.io'); ddev wp search-replace https://wordpress.ddev.site https://wp23.ngrok.io (assuming your project is configured for https://wordpress.ddev.site and your ngrok_args are configured for the wp23 subdomain) Now ddev share","title":"WordPress: Change the URL with wp search-replace"},{"location":"users/topics/sharing/#magento2-change-the-url-with-magento-tool","text":"This set of steps assumes an ngrok subdomain \"mg2\" Configure .ddev/config.yaml to use a custom subdomain: ngrok_args: --subdomain mg2 Make a backup of your database. Edit your .ddev/config.yaml ddev ssh and bin/magento setup:store-config:set --base-url=\"https://mg2.ngrok.io/ ddev share and you'll see your project on mg2.ngrok.io","title":"Magento2: Change the URL with magento tool"},{"location":"users/topics/sharing/#using-nipio-and-or-your-own-name-resolution-and-open-up-to-the-local-network","text":"Another solution is to not use *.ddev.site as your project URLs, but to use DNS that you control (and that points to the host machine where your project lives). In general, you'll want to use http URLs with this approach, because it requires manual configuration of the client machine to get it to trust the development certificate that ddev uses (and configures with mkcert on the local machine). Use nip.io to point a domain name to your host. If your computer's IP address is 192.168.5.101, you can use a domain name like mysite.192.168.5.101.nip.io and that domain name will point to your computer. Now add that as an additional_fqdn to your project, ddev config --additional-fqdns=mysite.192.168.5.101.nip.io and ddev start . Now people in your internal network should be able to ping mysite.192.168.5.101.nip.io if your firewall allows it. (Note that if you have other convenient ways to create a DNS entry for this, you can use those instead of using nip.io.) Configure ~/.ddev/global_config.yaml to bind to all ports: ddev config global --router-bind-all-interfaces && ddev poweroff && ddev start Now mobile apps or other computers which are on your local network should be able to access your project. Use the http URL rather than the https URL because computers outside yours don't know how to trust the developer TLS certificate you're using. (You can use ddev describe to see the http URL, but it's typically the same as the https URL, but with \"http\" instead of \"https\".) Make sure your firewall allows access from your local network to the main interface you're using. In the example here you should be able to ping 192.168.5.101 and curl http://192.168.5.101 and get an answer in each case. If you're using WordPress or Magento 2 you'll need to change the base URL as described in the ddev share instructions above.","title":"Using nip.io and or your own name resolution and open up to the local network"},{"location":"users/topics/sharing/#exposing-just-a-port-from-the-host-and-providing-a-direct-url","text":"DDEV's web container also exposes an HTTP port directly (in addition to the normal routing by name and via ddev_router). You can expose this port and it may be a useful approach in some situations. Configure the project host_webserver_port to a known port (that does not conflict with already configured ports). For example, using port 8080, ddev config --host-webserver-port=8080 --bind-all-interfaces . This will configure the host-bound port to 8080 and allow it to bind to all network interfaces so colleagues (or hackers) on your local network can access this project's ports. Make sure your firewall allows access to the port on your host machine. If you're using WordPress or Magento 2 you'll need to change the base URL as described in the ddev share instructions above. Each project on your computer must use different ports or you'll have port conflicts, and you can't typically use ports 80 or 443 because ddev-router is already using those for normal routing. If you don't want to run ddev-router at all you can actually omit it globally, ddev config global --omit-containers=ddev-router . This is a specialty thing to do, when you don't need the reverse proxy at all for anything, as for DrupalPod or other GitPod applications. Computers and mobile devices on your local network should now be able to access port 8080, on the (example) host address 192.168.5.23, so http://192.168.5.23:8080 You'll probably want to use the http URL; your coworker's browser will not trust the developer TLS certificate you're using.","title":"Exposing just a port from the host and providing a direct URL"},{"location":"users/topics/webserver/","text":"Webserver-Specific Help and Techniques \u00b6 Apache Specifics \u00b6 TLS redirects \u00b6 It's a common practice to set up HTTP to TLS redirects in the .htaccess file, which leads to issues with the DDEV proxy setup. The TLS endpoint of a DDEV project is always the ddev-router container and requests are forwarded through plain HTTP to the project's webserver. This of course results in endless redirects and can never work. Therefore, you need to change the root .htaccess file so the Apache webserver of the project correctly handles these requests for your local development environment with DDEV. The following snippet should work for most scenarios and not just DDEV and could replace an existing redirect: # http:// -> https:// plain or behind proxy for Apache 2.2 and 2.4 # behind proxy RewriteCond %{HTTP:X-FORWARDED-PROTO} ^http$ RewriteRule (.*) https://%{HTTP_HOST}/$1 [R=301,L] # plain RewriteCond %{HTTP:X-FORWARDED-PROTO} ^$ RewriteCond %{REQUEST_SCHEME} ^http$ [NC,OR] RewriteCond %{HTTPS} off RewriteRule (.*) https://%{HTTP_HOST}/$1 [R=301,L]","title":"Webserver-Specific Help and Techniques"},{"location":"users/topics/webserver/#webserver-specific-help-and-techniques","text":"","title":"Webserver-Specific Help and Techniques"},{"location":"users/topics/webserver/#apache-specifics","text":"","title":"Apache Specifics"},{"location":"users/topics/webserver/#tls-redirects","text":"It's a common practice to set up HTTP to TLS redirects in the .htaccess file, which leads to issues with the DDEV proxy setup. The TLS endpoint of a DDEV project is always the ddev-router container and requests are forwarded through plain HTTP to the project's webserver. This of course results in endless redirects and can never work. Therefore, you need to change the root .htaccess file so the Apache webserver of the project correctly handles these requests for your local development environment with DDEV. The following snippet should work for most scenarios and not just DDEV and could replace an existing redirect: # http:// -> https:// plain or behind proxy for Apache 2.2 and 2.4 # behind proxy RewriteCond %{HTTP:X-FORWARDED-PROTO} ^http$ RewriteRule (.*) https://%{HTTP_HOST}/$1 [R=301,L] # plain RewriteCond %{HTTP:X-FORWARDED-PROTO} ^$ RewriteCond %{REQUEST_SCHEME} ^http$ [NC,OR] RewriteCond %{HTTPS} off RewriteRule (.*) https://%{HTTP_HOST}/$1 [R=301,L]","title":"TLS redirects"},{"location":"users/topics/whats_in_ddev_dir/","text":"What's all that stuff in the .ddev directory? \u00b6 It can be a little confusing trying to understand all the things that are in the project's .ddev directory, so here it is all on one place. Note that you may have some directories or files that are not listed here - they may be added from custom services. For example, if you see a solr directory, it probably pertains to a custom solr add-on service. apache directory: Apache configuration for those using webserver_type: apache-fpm . There are docs and the default configuration in there. See apache customization docs . commands subdirectories: Contains DDEV shell commands (both built-in and custom) that can run on the host or inside any container. See docs . config.yaml file: This is the basic configuration file for the project. Take a look at the comments below for suggestions about things you can do, or look in docs ). config.*.yaml files: You can add configuration here that overrides the config in the config.yaml . This is nice for situations where one developer's project needs one-off configuration. For example, you could turn on or off nfs-mount-enabled or mutagen-enabled or use a different database type. By default, these are gitignored, so will not get checked in. See docs db-build directory: Can be used to provide a custom Dockerfile for the database container. db_snapshots directory: This is where snapshots go when you ddev snapshot . If you don't need these backups, you can delete anything there at any time. See snapshot docs . docker-compose.*.yaml files: Advanced users can provide their own services or service overrides using docker-compose.*.yaml files. See custom compose files and additional services . Also see the many examples in ddev-contrib . homeadditions directory: Anything you put in the homeadditions directory (including both files and directories) will be copied into the web container on startup. This lets you easily override the default home directory contents ( .profile , .bashrc , .composer , .ssh ) or anything you want to put in there. It could also include scripts that you want to have easily available inside the container. (Note that you can do the same thing globally in ~/.ddev/homeadditions .) See homeadditions docs . mutagen directory: contains mutagen/mutagen.yml where you can override the default mutagen configuration. See mutagen docs . mysql directory: contains optional mysql or mariadb configuration. See mysql docs . nginx directory: (deprecated) can be used for add-on nginx snippets. nginx_full directory: Contains the nginx configuration used by the web container, which can be customized following the instructions there. See providing custom nginx configuration . postgres directory: contains postgres/postgresql.conf which can be edited if needed (and remove the #ddev-generated line at the top to take it over.) providers directory: Contains examples and implementations showing ways to configure DDEV so ddev pull can work. You can use ddev pull with hosting providers like Acquia or Platform.sh or Pantheon and also can use it with local files or custom database/files sources. See providers docs web-build directory: You can add a custom Dockerfile that adds things into the docker image used for your web container. See Customizing images . xhprof directory: Contains the xhprof_prepend.php file that can be used to customize xhprof behavior for different types of website. See xhprof profiling . Things not to look at or mess with :) \u00b6 The hidden files (that begin with a \".\" are not intended to be fiddled with, and are hidden for that reason, and most are regenerated (and thus overwritten) on every ddev start : .dbimageBuild directory: The generated Dockerfile used to customize the db container on first start. .ddev-docker-compose-base.yaml : The base docker-compose file used to describe a project. .ddev-docker-compose-full.yaml : This is the result of preprocessing .ddev-docker-compose-base.yaml using docker-compose config . Mostly it replaces environment variables with their values. .gitignore : The .gitignore is generated by DDEV and should generally not be edited or checked in. (It gitignores itself to make sure you don't check it in.) It's generated on every ddev start and will change as DDEV versions change, so if you check it in by accident it will always be showing changes that you don't need to see in git status . .global_commands : This is a temporary directory that is used to get global commands available inside a project. You shouldn't ever have to look there. .homeadditions : This is a temporary directory used to consolidate global homeadditions with project-level homeadditions . You shouldn't ever have to look here. .webimageBuild directory: The generated Dockerfile used to customize the web container on first start.","title":"What's all that stuff in the `.ddev` directory?"},{"location":"users/topics/whats_in_ddev_dir/#whats-all-that-stuff-in-the-ddev-directory","text":"It can be a little confusing trying to understand all the things that are in the project's .ddev directory, so here it is all on one place. Note that you may have some directories or files that are not listed here - they may be added from custom services. For example, if you see a solr directory, it probably pertains to a custom solr add-on service. apache directory: Apache configuration for those using webserver_type: apache-fpm . There are docs and the default configuration in there. See apache customization docs . commands subdirectories: Contains DDEV shell commands (both built-in and custom) that can run on the host or inside any container. See docs . config.yaml file: This is the basic configuration file for the project. Take a look at the comments below for suggestions about things you can do, or look in docs ). config.*.yaml files: You can add configuration here that overrides the config in the config.yaml . This is nice for situations where one developer's project needs one-off configuration. For example, you could turn on or off nfs-mount-enabled or mutagen-enabled or use a different database type. By default, these are gitignored, so will not get checked in. See docs db-build directory: Can be used to provide a custom Dockerfile for the database container. db_snapshots directory: This is where snapshots go when you ddev snapshot . If you don't need these backups, you can delete anything there at any time. See snapshot docs . docker-compose.*.yaml files: Advanced users can provide their own services or service overrides using docker-compose.*.yaml files. See custom compose files and additional services . Also see the many examples in ddev-contrib . homeadditions directory: Anything you put in the homeadditions directory (including both files and directories) will be copied into the web container on startup. This lets you easily override the default home directory contents ( .profile , .bashrc , .composer , .ssh ) or anything you want to put in there. It could also include scripts that you want to have easily available inside the container. (Note that you can do the same thing globally in ~/.ddev/homeadditions .) See homeadditions docs . mutagen directory: contains mutagen/mutagen.yml where you can override the default mutagen configuration. See mutagen docs . mysql directory: contains optional mysql or mariadb configuration. See mysql docs . nginx directory: (deprecated) can be used for add-on nginx snippets. nginx_full directory: Contains the nginx configuration used by the web container, which can be customized following the instructions there. See providing custom nginx configuration . postgres directory: contains postgres/postgresql.conf which can be edited if needed (and remove the #ddev-generated line at the top to take it over.) providers directory: Contains examples and implementations showing ways to configure DDEV so ddev pull can work. You can use ddev pull with hosting providers like Acquia or Platform.sh or Pantheon and also can use it with local files or custom database/files sources. See providers docs web-build directory: You can add a custom Dockerfile that adds things into the docker image used for your web container. See Customizing images . xhprof directory: Contains the xhprof_prepend.php file that can be used to customize xhprof behavior for different types of website. See xhprof profiling .","title":"What's all that stuff in the .ddev directory?"},{"location":"users/topics/whats_in_ddev_dir/#things-not-to-look-at-or-mess-with","text":"The hidden files (that begin with a \".\" are not intended to be fiddled with, and are hidden for that reason, and most are regenerated (and thus overwritten) on every ddev start : .dbimageBuild directory: The generated Dockerfile used to customize the db container on first start. .ddev-docker-compose-base.yaml : The base docker-compose file used to describe a project. .ddev-docker-compose-full.yaml : This is the result of preprocessing .ddev-docker-compose-base.yaml using docker-compose config . Mostly it replaces environment variables with their values. .gitignore : The .gitignore is generated by DDEV and should generally not be edited or checked in. (It gitignores itself to make sure you don't check it in.) It's generated on every ddev start and will change as DDEV versions change, so if you check it in by accident it will always be showing changes that you don't need to see in git status . .global_commands : This is a temporary directory that is used to get global commands available inside a project. You shouldn't ever have to look there. .homeadditions : This is a temporary directory used to consolidate global homeadditions with project-level homeadditions . You shouldn't ever have to look here. .webimageBuild directory: The generated Dockerfile used to customize the web container on first start.","title":"Things not to look at or mess with :)"}]}